{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7439e0-435f-402e-857f-9f30a7fa9d20",
   "metadata": {},
   "source": [
    "## **Importing the library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c1dccd-3e00-4216-a889-eab7884418b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80dea103-379c-4e63-a87d-0203c6f764a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETRIVING THE DATASETS\n",
    "df_test=pd.read_csv('/data/nmamit-interns/grp3/new/test.csv')\n",
    "df_train1=pd.read_csv('/data/nmamit-interns/grp3/new/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "307051a1-013e-4080-97e3-4f4be386aacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Wing sauce is like water. Pretty much a lot of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  \\\n",
       "0  2   \n",
       "1  1   \n",
       "2  1   \n",
       "3  2   \n",
       "4  1   \n",
       "\n",
       "  Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.  \n",
       "0  Been going to Dr. Goldberg for over 10 years. ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "1  I don't know what Dr. Goldberg was like before...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "2  I'm writing this review to give you a heads up...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "3  All the food is great here. But the best thing...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "4  Wing sauce is like water. Pretty much a lot of...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd41be86-9e71-4b0c-9611-39edf75971de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>Contrary to other reviews, I have zero complaints about the service or the prices. I have been getting tire service here for the past 5 years now, and compared to my experience with places like Pep Boys, these guys are experienced and know what they're doing. \\nAlso, this is one place that I do not feel like I am being taken advantage of, just because of my gender. Other auto mechanics have been notorious for capitalizing on my ignorance of cars, and have sucked my bank account dry. But here, my service and road coverage has all been well explained - and let up to me to decide. \\nAnd they just renovated the waiting room. It looks a lot better than it did in previous years.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Last summer I had an appointment to get new ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Friendly staff, same starbucks fair you get an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The food is good. Unfortunately the service is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Even when we didn't have a car Filene's Baseme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Picture Billy Joel's \\\"Piano Man\\\" DOUBLED mix...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2  \\\n",
       "0  1   \n",
       "1  2   \n",
       "2  1   \n",
       "3  2   \n",
       "4  2   \n",
       "\n",
       "  Contrary to other reviews, I have zero complaints about the service or the prices. I have been getting tire service here for the past 5 years now, and compared to my experience with places like Pep Boys, these guys are experienced and know what they're doing. \\nAlso, this is one place that I do not feel like I am being taken advantage of, just because of my gender. Other auto mechanics have been notorious for capitalizing on my ignorance of cars, and have sucked my bank account dry. But here, my service and road coverage has all been well explained - and let up to me to decide. \\nAnd they just renovated the waiting room. It looks a lot better than it did in previous years.  \n",
       "0  Last summer I had an appointment to get new ti...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "1  Friendly staff, same starbucks fair you get an...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "2  The food is good. Unfortunately the service is...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "3  Even when we didn't have a car Filene's Baseme...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "4  Picture Billy Joel's \\\"Piano Man\\\" DOUBLED mix...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5425742-32f3-4ded-a8ba-2ae6afaaa922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the columns names\n",
    "columns=['target','text']\n",
    "df_test=pd.read_csv('/data/nmamit-interns/grp3/new/test.csv',names=columns)\n",
    "df_train1=pd.read_csv('/data/nmamit-interns/grp3/new/train.csv',names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e833f0-325c-4f4d-abc6-a035019fa2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "## USING THE DEVICE\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a41155f5-bf31-4049-b85b-c79dd8ff2d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       1  Unfortunately, the frustration of being Dr. Go...\n",
       "1       2  Been going to Dr. Goldberg for over 10 years. ...\n",
       "2       1  I don't know what Dr. Goldberg was like before...\n",
       "3       1  I'm writing this review to give you a heads up...\n",
       "4       2  All the food is great here. But the best thing..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "497b3a79-96e7-4535-a0da-f734178c10e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Contrary to other reviews, I have zero complai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Last summer I had an appointment to get new ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Friendly staff, same starbucks fair you get an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The food is good. Unfortunately the service is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Even when we didn't have a car Filene's Baseme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       2  Contrary to other reviews, I have zero complai...\n",
       "1       1  Last summer I had an appointment to get new ti...\n",
       "2       2  Friendly staff, same starbucks fair you get an...\n",
       "3       1  The food is good. Unfortunately the service is...\n",
       "4       2  Even when we didn't have a car Filene's Baseme..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8589c12-4259-473e-a173-ef04105fc8b9",
   "metadata": {},
   "source": [
    "### **REDUCING THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f6d4053-0d1c-4b94-9835-800c3004435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "1    56000\n",
      "2    56000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# stratified sampling \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, _ = train_test_split(df_train1, test_size=0.8, stratify=df_train1['target'], random_state=42)\n",
    "\n",
    "print(df_train['target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645a488-4918-4ec8-b3b2-361248b6ae2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f370ba69-3693-4712-b5ed-09071ba88125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112000, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b238ef-608e-4567-9f29-20a2496265b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3604f2e7-77e3-49dd-9243-e997f57d9f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "2    19000\n",
      "1    19000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_test['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6055d586-0abd-4bd2-986b-86425cbbd7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5033d1e-7d23-4bac-a62f-0a9e36a9d919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38000 entries, 0 to 37999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   target  38000 non-null  int64 \n",
      " 1   text    38000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 593.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2e9e6-940d-44b6-9d05-1b2e575d7ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7f48c9c-4964-4f54-8833-124d4144d731",
   "metadata": {},
   "source": [
    "### *To check what does 1 and 2 represent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0392328-9ca9-4442-95b3-2ff6f05d0942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food was pretty good but the server was so bad it ruined our experience.  Everything you could imagine a server could do wrong happened...Better service would have bumped this review to a 3.5 or 4 star spot.\n"
     ]
    }
   ],
   "source": [
    "texts = df_train[df_train['target'] == 1]['text']\n",
    "text_2 = texts.iloc[0] if not texts.empty else None\n",
    "print(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4663e778-b69a-4f9a-b267-d0b53c5e98ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrary to other reviews, I have zero complaints about the service or the prices. I have been getting tire service here for the past 5 years now, and compared to my experience with places like Pep Boys, these guys are experienced and know what they're doing. \\nAlso, this is one place that I do not feel like I am being taken advantage of, just because of my gender. Other auto mechanics have been notorious for capitalizing on my ignorance of cars, and have sucked my bank account dry. But here, my service and road coverage has all been well explained - and let up to me to decide. \\nAnd they just renovated the waiting room. It looks a lot better than it did in previous years.\n"
     ]
    }
   ],
   "source": [
    "texts = df_test[df_test['target'] == 2]['text']\n",
    "text_1 = texts.iloc[0] if not texts.empty else None\n",
    "print(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a990528-3c1c-45d1-b921-e979ef6cff30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e64bb10-e647-462e-a863-33d46a6a7a6c",
   "metadata": {},
   "source": [
    "#### *2-->postivie 1--> negative*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f5fe21d-3554-4caa-8674-0f9a8e443411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the lable 1-->0 and 2-->1\n",
    "df_train.replace(1,0,inplace=True)\n",
    "df_train.replace(2,1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b168806c-9010-47b5-b74a-88e49f73f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.replace(1,0,inplace=True)\n",
    "df_test.replace(2,1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a182b3fa-f88e-4c8c-a21b-a06c5685e21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    56000\n",
       "1    56000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c99e1bb-82d7-42a9-834c-0848aedb155a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    19000\n",
       "0    19000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43e7c4-fa36-41e3-b4c8-375f5eef4718",
   "metadata": {},
   "source": [
    "### **CLEANING THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b0ba1bd-f624-4226-ab97-06c8f48cc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "  # Remove special characters and punctuation\n",
    "  text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "\n",
    "  # Remove single characters\n",
    "  text = re.sub(r\"\\b[a-zA-Z]\\b\", \" \", text)\n",
    "\n",
    "  # Remove HTML tags\n",
    "  text = re.sub(r\"<[^>]*>\", \" \", text)\n",
    "\n",
    "  # Lowercase the text\n",
    "  text = text.lower()\n",
    "\n",
    "  # Use regex to remove numbers\n",
    "  text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "  # Remove extra whitespace\n",
    "  text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "  # Trim leading and trailing spaces\n",
    "  text = text.strip()\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f097682d-9087-4a39-9bb0-857a9abd863b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>407494</th>\n",
       "      <td>0</td>\n",
       "      <td>the food was pretty good but the server was so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44351</th>\n",
       "      <td>0</td>\n",
       "      <td>horrible manager she told us we only needed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418933</th>\n",
       "      <td>1</td>\n",
       "      <td>love the black bean burger so much so came bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394896</th>\n",
       "      <td>0</td>\n",
       "      <td>off the beaten path and you can either park yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128149</th>\n",
       "      <td>1</td>\n",
       "      <td>awesome nyc pizza my second favorite nyc style...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target                                               text\n",
       "407494       0  the food was pretty good but the server was so...\n",
       "44351        0  horrible manager she told us we only needed to...\n",
       "418933       1  love the black bean burger so much so came bac...\n",
       "394896       0  off the beaten path and you can either park yo...\n",
       "128149       1  awesome nyc pizza my second favorite nyc style..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the cleaning function to the 'text' column\n",
    "df_train['text'] = df_train['text'].apply(clean_text)\n",
    "\n",
    "# Verify the changes\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e22ef10-a847-4e5c-89f1-47c861524e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>contrary to other reviews have zero complaints...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>last summer had an appointment to get new tire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>friendly staff same starbucks fair you get any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the food is good unfortunately the service is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>even when we didn have car filene basement was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       1  contrary to other reviews have zero complaints...\n",
       "1       0  last summer had an appointment to get new tire...\n",
       "2       1  friendly staff same starbucks fair you get any...\n",
       "3       0  the food is good unfortunately the service is ...\n",
       "4       1  even when we didn have car filene basement was..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Apply the cleaning function to the 'text' column\n",
    "df_test['text'] = df_test['text'].apply(clean_text)\n",
    "\n",
    "# Verify the changes\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdefbc9-d7f9-496b-8a51-9fa41b1c6443",
   "metadata": {},
   "source": [
    "### **Saving the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e44c3423-a161-4dd3-ac02-3c5399be58e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/data/nmamit-interns/grp3/new/df_train.pkl', 'wb') as f:\n",
    "    pickle.dump(df_train, f)\n",
    "\n",
    "with open('/data/nmamit-interns/grp3/new/df_test.pkl', 'wb') as f:\n",
    "    pickle.dump(df_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a23d5cc-4a9b-4d7e-b0d0-6f76bc460343",
   "metadata": {},
   "source": [
    "### **Loading the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19efdbb4-a8d6-47e2-8cc6-e5504af9e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/data/nmamit-interns/grp3/new/df_train.pkl','rb') as f:\n",
    "    df_train=pickle.load(f)\n",
    "\n",
    "with open('/data/nmamit-interns/grp3/new/df_test.pkl','rb') as f:\n",
    "    df_test=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d086ef26-b961-4b4a-9377-fa56393326db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check the length of the text\n",
    "text_lengths = df_train['text'].apply(len)\n",
    "max_length = text_lengths.max()\n",
    "min_length = text_lengths.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d91292-5f15-4151-9656-21fdb5e25451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of text: 4810\n",
      "Minimum length of text: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum length of text: {max_length}\")\n",
    "print(f\"Minimum length of text: {min_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c48ca4-2e51-457b-bc2c-65d30abc62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check the length of the text\n",
    "text_length = df_test['text'].apply(len)\n",
    "max_lengths = text_length.max()\n",
    "min_lengths = text_length.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65d447e-a7e7-40f6-b5b9-2724c0eb7d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of text: 4810\n",
      "Minimum length of text: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum length of text: {max_lengths}\")\n",
    "print(f\"Minimum length of text: {min_lengths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72da78c1-f176-4803-9f05-ad82899af15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPING THE TEXT COLUMN WITH LENGTH ZERO\n",
    "text_lengths=df_train['text'].apply(len)\n",
    "rows_to_remove=text_lengths[text_lengths==0].index\n",
    "df_train.drop(rows_to_remove,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b31783-52ae-4867-9c6b-67522da09c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111993, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9681a-ba55-4e52-97cc-e73fb8faff26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b418a725-5d23-4c24-84af-9e48d899cf8c",
   "metadata": {},
   "source": [
    "## **Training the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2759eacb-ea5f-4653-bb5c-71496ebf0825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71005a6b-2ecb-44bc-b212-8534cabcb0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE DATA\n",
    "X_train=df_train['text']\n",
    "y_train=df_train['target']\n",
    "X_test=df_test['text']\n",
    "y_test=df_test['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91beb46-7f29-484d-95fa-eab8cd07f5b3",
   "metadata": {},
   "source": [
    "#### **FEATURE EXTRACTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0167d13d-29dd-452b-a067-3b856b806b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prune text with TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def prune_text_with_tfidf(texts, max_features=1000):\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    x = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    pruned_texts = []\n",
    "    for i in range(x.shape[0]):\n",
    "        indices = x[i].indices\n",
    "        words = [feature_names[idx] for idx in indices]\n",
    "        pruned_texts.append(' '.join(words))\n",
    "    return pruned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0e255f2-e233-46a5-8351-71afdb56c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TFIDF pruning\n",
    "X_train_pruned = prune_text_with_tfidf(X_train.tolist())\n",
    "X_val_pruned = prune_text_with_tfidf(X_val.tolist())\n",
    "X_test_pruned = prune_text_with_tfidf(df_test['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43fbf819-d63a-45a3-996c-73f3e8795384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERTING TO THE HUGGING FACE DATASET\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "#Creating the dataframe with pruned texts\n",
    "df_train_pruned=pd.DataFrame({'text':X_train_pruned,'label':y_train})\n",
    "df_val_pruned=pd.DataFrame({'text':X_val_pruned,'label':y_val})\n",
    "df_test_pruned=pd.DataFrame({'text':X_test_pruned,'label':y_test})\n",
    "\n",
    "# Convert Pandas DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(df_train_pruned)\n",
    "val_dataset = Dataset.from_pandas(df_val_pruned)\n",
    "test_dataset = Dataset.from_pandas(df_test_pruned)\n",
    "\n",
    "print(train_dataset)\n",
    "print(val_dataset)\n",
    "print(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e00f26e-6839-4d2e-b84a-e06413bbebfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', '__index_level_0__'],\n",
      "    num_rows: 89594\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label', '__index_level_0__'],\n",
      "    num_rows: 22399\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 38000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#CONVERTING TO THE HUGGING FACE DATASET\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "#Creating the dataframe with pruned texts\n",
    "df_train_pruned=pd.DataFrame({'text':X_train,'label':y_train})\n",
    "df_val_pruned=pd.DataFrame({'text':X_val,'label':y_val})\n",
    "df_test_pruned=pd.DataFrame({'text':X_test,'label':y_test})\n",
    "\n",
    "# Convert Pandas DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(df_train_pruned)\n",
    "val_dataset = Dataset.from_pandas(df_val_pruned)\n",
    "test_dataset = Dataset.from_pandas(df_test_pruned)\n",
    "\n",
    "print(train_dataset)\n",
    "print(val_dataset)\n",
    "print(test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f37ea0-c6a8-4d6f-9861-a35d75558ac9",
   "metadata": {},
   "source": [
    "#### *COMPUTE METRICS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d04c63b6-a3ac-4efa-91ee-bf7dfb359c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49413e1e-5feb-4368-905c-f509cbf84184",
   "metadata": {},
   "source": [
    "## **BERT-base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e34fbb4b-d932-48f8-8aea-94cff0cf2d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a5218817634424a192681636eeba2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d11d9532384a39a2a77d6a94bcd806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00cc5a888fb47e09e2e7dfe14600a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "#adds the special tokens\n",
    "def tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "# Tokenizer for BERT\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "# Tokenize using BERT tokenizer\n",
    "tokenized_train_dataset_bert = train_dataset.map(lambda x: tokenize(x, bert_tokenizer), batched=True)\n",
    "tokenizd_val_dataset_bert = val_dataset.map(lambda x: tokenize(x, bert_tokenizer), batched=True)\n",
    "tokenized_test_dataset_bert = test_dataset.map(lambda x: tokenize(x, bert_tokenizer), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e3bcc9-37ae-47ae-a4bf-71e20f81fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure correct format\n",
    "tokenized_train_dataset_bert.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_val_dataset_bert.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_test_dataset_bert.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c31c2a2-f51c-4000-823f-9001f4a9fee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/shrishask/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33600' max='33600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33600/33600 3:41:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.315900</td>\n",
       "      <td>0.306921</td>\n",
       "      <td>0.896692</td>\n",
       "      <td>0.897556</td>\n",
       "      <td>0.900746</td>\n",
       "      <td>0.894389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.339796</td>\n",
       "      <td>0.897808</td>\n",
       "      <td>0.900973</td>\n",
       "      <td>0.883881</td>\n",
       "      <td>0.918740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.350154</td>\n",
       "      <td>0.902272</td>\n",
       "      <td>0.902793</td>\n",
       "      <td>0.908806</td>\n",
       "      <td>0.896859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 07:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Results: {'eval_loss': 0.34424889087677, 'eval_accuracy': 0.9043684210526316, 'eval_f1': 0.9037911680609976, 'eval_precision': 0.9092797783933518, 'eval_recall': 0.8983684210526316, 'eval_runtime': 463.7308, 'eval_samples_per_second': 81.944, 'eval_steps_per_second': 5.122, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Model for BERT\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import torch\n",
    "\n",
    "# Data collator for BERT\n",
    "data_collator_bert = DataCollatorWithPadding(tokenizer=bert_tokenizer)\n",
    "\n",
    "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "# Training arguments for BERT\n",
    "bert_training_args = TrainingArguments(\n",
    "    output_dir='/data/nmamit-interns/grp3/new/result/bert',\n",
    "    num_train_epochs=3, #larger epoch gets overfitted\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    #logging_dir='/data/nmamit-interns/grp3/new/logs/bert',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,  \n",
    "    lr_scheduler_type='linear'\n",
    ")\n",
    "\n",
    "\n",
    "# Trainer for BERT\n",
    "bert_trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=bert_training_args,\n",
    "    train_dataset=tokenized_train_dataset_bert,\n",
    "    eval_dataset=tokenizd_val_dataset_bert,\n",
    "    data_collator=data_collator_bert,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train  BERT\n",
    "bert_trainer.train()\n",
    "#evluation\n",
    "bert_results = bert_trainer.evaluate(tokenized_test_dataset_bert)\n",
    "print(\"BERT Results:\", bert_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc3373a9-2a88-4054-8b6a-b48e1ff5bc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/data/nmamit-interns/grp3/new/saved_models/bert_tokenizer/tokenizer_config.json',\n",
       " '/data/nmamit-interns/grp3/new/saved_models/bert_tokenizer/special_tokens_map.json',\n",
       " '/data/nmamit-interns/grp3/new/saved_models/bert_tokenizer/vocab.txt',\n",
       " '/data/nmamit-interns/grp3/new/saved_models/bert_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.save_pretrained('/data/nmamit-interns/grp3/new/saved_models/bert')\n",
    "bert_tokenizer.save_pretrained('/data/nmamit-interns/grp3/new/saved_models/bert_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86c9def4-0639-41d5-b887-5bb2d7708047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Load the BERT model\n",
    "loaded_bert_model = BertForSequenceClassification.from_pretrained('/data/nmamit-interns/grp3/new/saved_models/bert')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "loaded_bert_tokenizer = BertTokenizer.from_pretrained('/data/nmamit-interns/grp3/new/saved_models/bert_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9706f48e-da79-48e0-adde-c3e9f4517aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>contrary to other reviews have zero complaints...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>last summer had an appointment to get new tire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>friendly staff same starbucks fair you get any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the food is good unfortunately the service is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>even when we didn have car filene basement was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       1  contrary to other reviews have zero complaints...\n",
       "1       0  last summer had an appointment to get new tire...\n",
       "2       1  friendly staff same starbucks fair you get any...\n",
       "3       0  the food is good unfortunately the service is ...\n",
       "4       1  even when we didn have car filene basement was..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2095a1-1674-4b1c-ad60-af963e8fdcd7",
   "metadata": {},
   "source": [
    "#### *CONFUSION MATRIX / CLASSIFICATION REPORT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e54c3a4-a128-46c3-985b-e97832ffb549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[17594  1406]\n",
      " [ 1593 17407]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     19000\n",
      "           1       0.93      0.92      0.92     19000\n",
      "\n",
      "    accuracy                           0.92     38000\n",
      "   macro avg       0.92      0.92      0.92     38000\n",
      "weighted avg       0.92      0.92      0.92     38000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the BERT model\n",
    "loaded_bert_model = BertForSequenceClassification.from_pretrained('/data/nmamit-interns/grp3/new/saved_models/bert')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "loaded_bert_tokenizer = BertTokenizer.from_pretrained('/data/nmamit-interns/grp3/new/saved_models/bert_tokenizer')\n",
    "\n",
    "# Load your test data\n",
    "test_texts = df_test['text'].tolist()  \n",
    "test_labels = df_test['target'].tolist()  \n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "loaded_bert_model.to(device)\n",
    "\n",
    "# Function to get predictions in batches\n",
    "def get_predictions_in_batches(model, tokenizer, texts, batch_size=32):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_logits = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        encodings = tokenizer(batch_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "        encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        all_logits.extend(logits.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_logits)\n",
    "\n",
    "# Get predictions\n",
    "predictions, logits = get_predictions_in_batches(loaded_bert_model, loaded_bert_tokenizer, test_texts)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c75f5f-14a8-43d2-b594-8b094878667c",
   "metadata": {},
   "source": [
    "### *ROC and AUC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51307dfd-83d4-4368-b202-3c83bc1741b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate ROC curve and AUC\n",
    "if len(np.unique(test_labels)) == 2:\n",
    "    fpr, tpr, _ = roc_curve(test_labels, logits[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ROC curve is only applicable for binary classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a871d438-b15b-4904-9be6-c53d0a87f1f2",
   "metadata": {},
   "source": [
    "### *PREDICTION*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6723ef29-d1c5-4ac3-a190-c6eedf2c1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Function to predict a single sample\n",
    "def predict_single_sample(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load tokenizer and model (using the provided variable names)\n",
    "    tokenizer = loaded_bert_tokenizer\n",
    "    model = loaded_bert_model.to(device)\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to the same device as the model\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    prediction = torch.argmax(logits, dim=-1).item()\n",
    "    return \"1\" if prediction == 1 else \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2db99c29-7958-49bf-899b-532152ef53d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: ve heard all the hype and wanted to try it tonight was my second attempt here first time new girl on the grill apologized to me at minutes at walked not even an acknowledgement from the wait staff tonight the waiter seemed mad that didn know what wanted to order after explained that never been there he brought me menu and then proceeded to ignore me for minutes walked again no more tries here maybe doing something wrong haha\n",
      "Actual prediction:0\n",
      "Example prediction : 0\n"
     ]
    }
   ],
   "source": [
    " # Example usage for a single test sample\n",
    "example_text = df_test['text'].iloc[98]\n",
    "example_target = df_test['target'].iloc[98]\n",
    "prediction = predict_single_sample(example_text)\n",
    "print(f\"Input text: {example_text}\")\n",
    "print(f\"Actual prediction:{example_target}\")\n",
    "print(f\"Example prediction : {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2a29e-e44c-4c17-b7d7-8ff740a8ea75",
   "metadata": {},
   "source": [
    "## **DistilRoBERTa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd7a46c3-598b-419e-b71e-aa87bda07a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c1817ac76f4aaf9e94012680eac95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e1458c4d96443e8f74a1f8ba810acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7803ad3435354ad4aab423de34919fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shrishask/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67197' max='67197' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67197/67197 2:49:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.417537</td>\n",
       "      <td>0.894370</td>\n",
       "      <td>0.893901</td>\n",
       "      <td>0.908900</td>\n",
       "      <td>0.879389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.459877</td>\n",
       "      <td>0.893522</td>\n",
       "      <td>0.898090</td>\n",
       "      <td>0.870743</td>\n",
       "      <td>0.927210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>0.399492</td>\n",
       "      <td>0.899415</td>\n",
       "      <td>0.900517</td>\n",
       "      <td>0.901352</td>\n",
       "      <td>0.899682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 05:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilRoBERTa Results: {'eval_loss': 0.3809416592121124, 'eval_accuracy': 0.9037894736842105, 'eval_f1': 0.9037641484601211, 'eval_precision': 0.9040021063717746, 'eval_recall': 0.9035263157894737, 'eval_runtime': 344.2087, 'eval_samples_per_second': 110.398, 'eval_steps_per_second': 6.9, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Tokenizer for DistilRoBERTa\n",
    "distilroberta_tokenizer = AutoTokenizer.from_pretrained('ProtectAI/distilroberta-base-rejection-v1')\n",
    "\n",
    "# Function to tokenize batch with special tokens\n",
    "def tokenize(batch):\n",
    "    return distilroberta_tokenizer(batch['text'], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Tokenize using DistilRoBERTa tokenizer\n",
    "tokenized_train_dataset_distilroberta = train_dataset.map(lambda x: tokenize(x), batched=True)\n",
    "tokenized_val_dataset_distilroberta = val_dataset.map(lambda x: tokenize(x), batched=True)\n",
    "tokenized_test_dataset_distilroberta = test_dataset.map(lambda x: tokenize(x), batched=True)\n",
    "\n",
    "# Model for DistilRoBERTa\n",
    "distilroberta_model = AutoModelForSequenceClassification.from_pretrained('ProtectAI/distilroberta-base-rejection-v1')\n",
    "distilroberta_model.to(device)  # Move model to device\n",
    "\n",
    "# Data collator for DistilRoBERTa\n",
    "data_collator_distilroberta = DataCollatorWithPadding(tokenizer=distilroberta_tokenizer)\n",
    "\n",
    "# Training arguments for DistilRoBERTa\n",
    "distilroberta_training_args = TrainingArguments(\n",
    "    output_dir='/data/nmamit-interns/grp3/new/result/distilroberta',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5, \n",
    "    lr_scheduler_type='linear'\n",
    ")\n",
    "\n",
    "# Trainer for DistilRoBERTa\n",
    "distilroberta_trainer = Trainer(\n",
    "    model=distilroberta_model,\n",
    "    args=distilroberta_training_args,\n",
    "    train_dataset=tokenized_train_dataset_distilroberta,\n",
    "    eval_dataset=tokenized_val_dataset_distilroberta,\n",
    "    data_collator=data_collator_distilroberta,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train and evaluate DistilRoBERTa\n",
    "distilroberta_trainer.train()\n",
    "distilroberta_results = distilroberta_trainer.evaluate(tokenized_test_dataset_distilroberta)\n",
    "print(\"DistilRoBERTa Results:\", distilroberta_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35ab7a95-542f-46eb-83bc-d96ca4146cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/data/nmamit-interns/grp3/new/distilroberta_tokenizer/tokenizer_config.json',\n",
       " '/data/nmamit-interns/grp3/new/distilroberta_tokenizer/special_tokens_map.json',\n",
       " '/data/nmamit-interns/grp3/new/distilroberta_tokenizer/vocab.json',\n",
       " '/data/nmamit-interns/grp3/new/distilroberta_tokenizer/merges.txt',\n",
       " '/data/nmamit-interns/grp3/new/distilroberta_tokenizer/added_tokens.json',\n",
       " '/data/nmamit-interns/grp3/new/distilroberta_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model\n",
    "distilroberta_model.save_pretrained('/data/nmamit-interns/grp3/new/distilroberta_model')\n",
    "distilroberta_tokenizer.save_pretrained('/data/nmamit-interns/grp3/new/distilroberta_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6be6ddd-b813-4f74-ad33-3c9b72625afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "loaded_distilroberta_model = AutoModelForSequenceClassification.from_pretrained('/data/nmamit-interns/grp3/new/distilroberta_model')\n",
    "loaded_distilroberta_tokenizer = AutoTokenizer.from_pretrained('/data/nmamit-interns/grp3/new/distilroberta_tokenizer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a310117-bf57-489d-900b-14e2991642d2",
   "metadata": {},
   "source": [
    "### *FINE TUNING THE MODEL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "001523da-a331-4e59-95f2-ce6545018556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b679bdec2ae34c7ea437059f113b7c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3927b7cb6d410e9f1b00f90d9a610a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c28b8800e954d16911cc735a014f8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shrishask/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22400' max='22400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22400/22400 1:58:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.317241</td>\n",
       "      <td>0.893076</td>\n",
       "      <td>0.897802</td>\n",
       "      <td>0.869350</td>\n",
       "      <td>0.928181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.323531</td>\n",
       "      <td>0.898522</td>\n",
       "      <td>0.900747</td>\n",
       "      <td>0.891675</td>\n",
       "      <td>0.910005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 05:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.3106069266796112, 'eval_accuracy': 0.9017631578947368, 'eval_f1': 0.9027839266647569, 'eval_precision': 0.893499664931182, 'eval_recall': 0.9122631578947369, 'eval_runtime': 343.8653, 'eval_samples_per_second': 110.508, 'eval_steps_per_second': 6.907, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to tokenize batch with special tokens using loaded tokenizer\n",
    "def tokenize(batch):\n",
    "    return loaded_distilroberta_tokenizer(batch['text'], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=loaded_distilroberta_tokenizer)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/data/nmamit-interns/grp3/new/result/distilroberta_finetuned',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type='linear'\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=loaded_distilroberta_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics  \n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "eval_results = trainer.evaluate(eval_dataset=tokenized_test_dataset)\n",
    "print(\"Evaluation Results:\", eval_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c63ca-6409-437a-b9f3-241276f70099",
   "metadata": {},
   "source": [
    "### *CONFUSION MATRIX / CLASSIFICATION REPORT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2115741-9f1e-4859-95df-9fcd05006c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[17287  1713]\n",
      " [ 1543 17457]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91     19000\n",
      "           1       0.91      0.92      0.91     19000\n",
      "\n",
      "    accuracy                           0.91     38000\n",
      "   macro avg       0.91      0.91      0.91     38000\n",
      "weighted avg       0.91      0.91      0.91     38000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    " \n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the BERT model\n",
    "loaded_bert_model = AutoModelForSequenceClassification.from_pretrained('/data/nmamit-interns/grp3/new/distilroberta_model')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "loaded_bert_tokenizer =  AutoTokenizer.from_pretrained('/data/nmamit-interns/grp3/new/distilroberta_tokenizer')\n",
    "\n",
    "# Load your test data\n",
    "test_texts = df_test['text'].tolist()  \n",
    "test_labels = df_test['target'].tolist()  \n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "loaded_bert_model.to(device)\n",
    "\n",
    "# Function to get predictions in batches\n",
    "def get_predictions_in_batches(model, tokenizer, texts, batch_size=32):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_logits = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        encodings = tokenizer(batch_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "        encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        all_logits.extend(logits.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_logits)\n",
    "\n",
    "# Get predictions\n",
    "predictions, logits = get_predictions_in_batches(loaded_bert_model, loaded_bert_tokenizer, test_texts)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363997a6-91ae-4a86-b874-d5870451f805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6c7631-140a-4146-96c7-c4ab5c8db8f9",
   "metadata": {},
   "source": [
    "### *ROC and AUC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9807d46b-0ac0-4860-88ec-c2e8ca2ce339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABEs0lEQVR4nO3dd3gU1frA8e+bHkIIJCBKBymhSBGkiECkSLX9LFguXr16JSCIiIoXG3ZRBEGaXPTitYDXBgoiikqx0SQUqaEH6SUQQvr5/TGTsIRks4FsJpu8n+fZZ2d22ruTzbwz58ycI8YYlFJKqfz4OR2AUkqpkk0ThVJKKbc0USillHJLE4VSSim3NFEopZRySxOFUkoptzRRqEIRkT9FJMbpOEoKERklIjMc2vZMEXnJiW0XNRG5W0S+u8Bl9TfpZZoofJiI7BKRMyKSJCIH7ANHeW9u0xjT1Biz2JvbyCYiwSLyqojssb/nNhF5XESkOLafRzwxIpLg+pkx5hVjzANe2p6IyMMiskFETotIgoh8KiJXeGN7F0pERovIhxezDmPMR8aY6zzY1nnJsTh/k2WVJgrfd70xpjzQEmgF/MvZcApPRALymfQp0A3oA4QDA4AHgQleiEFEpKT9P0wAhgEPA5FAQ2AO0LeoN+Tmb+B1Tm5becgYoy8ffQG7gO4u468D813G2wO/AieAtUCMy7RI4D/AX8BxYI7LtH5AnL3cr0Dz3NsEqgFngEiXaa2AI0CgPf4PYJO9/oVAbZd5DfAQsA3Ymcd36wakADVzfd4OyATq2+OLgVeBFUAiMDdXTO72wWLgZeAX+7vUB+6zYz4F7AAG2vOG2fNkAUn2qxowGvjQnqeO/b3+Duyx98VTLtsLBd6398cm4AkgIZ+/bQP7e7Z18/efCUwG5tvxLgcud5k+AdgLnARWA51cpo0GPgM+tKc/ALQFfrP31X5gEhDkskxT4HvgGHAQGAX0AtKAdHufrLXnjQDetdezD3gJ8Len3Wvv8/H2ul6yP/vZni72tEP233Qd0AzrJCHd3l4S8HXu/wPA345ru71PVpPrN6SvCzjWOB2Avi7ij3fuP0gNYD0wwR6vDhzFOhv3A3rY41Xs6fOBT4BKQCDQxf78SvsftJ39T/d3ezvBeWzzR+CfLvG8AUyzh28C4oHGQADwNPCry7zGPuhEAqF5fLfXgCX5fO/dnD2AL7YPRM2wDuafc/bAXdA+WIx1QG9qxxiIdbZ+uX2w6gIkA1fa88eQ68BO3oni31hJoQWQCjR2/U72Pq+BdQDML1HEArsL+PvPxDrQtrXj/wiY7TL9b0CUPW0EcAAIcYk73f47+dnxtsZKrAH2d9kEPGLPH4510B8BhNjj7XLvA5dtzwHesf8ml2Al8uy/2b1ABjDU3lYo5yaKnlgH+Ir236ExcJnLd37Jzf/B41j/B43sZVsAUU7/r/r6y/EA9HURfzzrHyQJ68zJAD8AFe1pI4EPcs2/EOvAfxnWmXGlPNY5FXgx12dbOJtIXP8pHwB+tIcF6+y1sz2+ALjfZR1+WAfd2va4Abq6+W4zXA96uab9jn2mjnWwf81lWhOsM05/d/vAZdkXCtjHc4Bh9nAMniWKGi7TVwB32MM7gJ4u0x7IvT6XaU8BvxcQ20xghst4H2Czm/mPAy1c4l5awPofAb60h+8E1uQzX84+sMerYiXIUJfP7gR+sofvBfbkWse9nE0UXYGtWEnLL4/v7C5RbAFuvNj/LX2d+yppZbKq8G4yxoRjHcSigcr257WB20TkRPYLuAYrSdQEjhljjuexvtrAiFzL1cQqZsntM6CDiFQDOmMdJJe5rGeCyzqOYSWT6i7L73XzvY7YseblMnt6XuvZjXVlUBn3+yDPGESkt4j8LiLH7Pn7cHafeuqAy3AykH2DQbVc23P3/Y+S//f3ZFuIyAgR2SQiifZ3ieDc75L7uzcUkXn2jREngVdc5q+JVZzjidpYf4P9Lvv9Hawrizy37coY8yNWsddk4KCITBeRCh5uuzBxKg9poigljDFLsM62xtof7cU6m67o8gozxrxmT4sUkYp5rGov8HKu5coZY2blsc0TwHfA7cBdwCxjn9bZ6xmYaz2hxphfXVfh5istAtqJSE3XD0WkLdbB4EeXj13nqYVVpHKkgH1wXgwiEoxVdDUWqGqMqQh8g5XgCorXE/uxipzyiju3H4AaItLmQjYkIp2wrqhux7pyrIhV3u96x1ju7zMV2Aw0MMZUwCrrz55/L1aRXF5yr2cv1hVFZZf9XsEY09TNMueu0JiJxpjWWMWCDbGKlApcroA41QXSRFG6vAX0EJGWWJWU14tITxHxF5EQ+/bOGsaY/VhFQ1NEpJKIBIpIZ3sd/wZiRaSdfSdQmIj0FZHwfLb5MXAPcIs9nG0a8C8RaQogIhEicpunX8QYswjrYPm5iDS1v0N7rHL4qcaYbS6z/01EmohIOeAF4DNjTKa7fZDPZoOAYOAwkCEivQHXWzYPAlEiEuHp98jlf1j7pJKIVAeG5Dej/f2mALPsmIPs+O8QkSc92FY4Vj3AYSBARJ4FCjorD8eq2E4SkWhgkMu0ecClIvKIfdtyuIi0s6cdBOpk3zVm/76+A94UkQoi4icil4tIFw/iRkSusn9/gcBprJsaMl22Vc/N4jOAF0Wkgf37bS4iUZ5sV+VPE0UpYow5DPwXeMYYsxe4Eeus8DDWmdbjnP2bD8A6896MVXn9iL2OVcA/sS79j2NVSN/rZrNfYd2hc9AYs9Ylli+BMcBsuxhjA9C7kF/pFuAn4FusupgPse6kGZprvg+wrqYOYFW0PmzHUNA+OIcx5pS97P+wvvtd9vfLnr4ZmAXssItU8iqOc+cFIAHYiXXF9BnWmXd+HuZsEcwJrCKVm4GvPdjWQqyTga1YxXEpuC/qAngM6zufwjph+CR7gr1vegDXY+3nbcC19uRP7fejIvKHPXwPVuLdiLUvP8OzojSwEtq/7eV2YxXDZV8pvws0sff/nDyWHYf19/sOK+m9i1VZri6CnC0pUMr3iMhirIpUR56OvhgiMgirotujM22lnKJXFEoVExG5TEQ62kUxjbBuNf3S6biUKog+EalU8QnCuvunLlZR0mysegilSjQtelJKKeWWFj0ppZRyy+eKnipXrmzq1KnjdBhKKeVTVq9efcQYU+VClvW5RFGnTh1WrVrldBhKKeVTRGT3hS6rRU9KKaXc0kShlFLKLU0USiml3NJEoZRSyi1NFEoppdzSRKGUUsotryUKEXlPRA6JyIZ8pouITBSReBFZJyJXeisWpZRSF86bz1HMxGoi+b/5TO+N1Tx1A6z+mafa70qpksAYMFmAsYbzenc3Lec9n3VkZWD1i5S9Lnub1sC5wznTPJjP28tmplrjEpBr2VzD5zWPlN80Dz53O63g5dPSsrgYXksUxpilIlLHzSw3Av+1e0T7XUQqishldqcnSjnHZEF6MqSftl4mE7Iy7fcM691kQloSZKZYy2RlnPs6tRdCIs/Om7286/CJ7RBW1frnzsoAk2FNyx7OTIXMNHv+jPNjOLgKopqdG5PrdjLT4EQ8hNeyvpPJtN+z8hi3hzPddY+hfNGEZe2YsfziCmycfDK7Oud2pJJgf3ZeohCRB4EHAWrVqlUswakSIivDOlinJkJGCmScgdQTZ1/pydbBLeU4nDkMwRHWeEYqZJy23rPSrIPm0T+tg7f4W/McXgthdl86WenWPGknHfyyF2DfsoLnObXnIjYgIOL+3e08fvlPTztl/W3Da5LT42rOOrOHXWMg72l5flaIdRU0f17TjvwJUY3BLyjX/K7rzf25u2kefH6By7dIqsDGr127Ky88JxNF7j0A+fSHa4yZDkwHaNOmjTZ3W9KlJUHKMThz1DrjTk2EpH3WQSPnoH/Gek85Bsc2WWezfgFwcDWUr25NTzlW9LEl7jx3/HQ+F7B+ARAUAYFh4B9oFTP4+Vufi7/18guA41uhSgtrPr8Ae3rAudP8/F2WyTV8cg9ERp9d1nV5v0AICD67LdftZq8nMxWCK+ax7uz5/c6uS/zsefwAv3PHxe/s/Dnvef2LqpJu795E5s3byqBBVwEQcwvE33OcevWev+B1OpkoEji3c/kawF8OxaLyYrIg+bB1kD+52zqopiaePZtPOQapJ+2D/wnrjN0v0Do7vxhJ+84dD6pgnekHV7TOPgPLQWhlCK5kH8iDwT/o7HbDa1mfBYRAQDlrml+gPU+Gtax/sH0QDrDXEXR2voAQ+2CqlO/IyMhi4sTlPPvsT5w+nU6zZpfQqVNtAOrWrXRR63YyUXwFDBGR2ViV2IlaP1GMUo5D0l/W69gmKwlkpFjFNzu/Af8QSD5oV0QWQvbBunx1CAq3yuFrdLLXIxDZ2CoeCiwHAaHWwT40ypoWVhUCy1ufB1WAwFDrQK9ntkq5tXx5AgMHzmPt2oMA3HJLY+rVu7jk4MpriUJEZgExQGURSQCeAwIBjDHTgG+APkA8kAzc561YyqyMVDi60arQPBFvnfEf3QQnd3lerBNc0bpaqH2ddfAvdwkElbcO8CGREGKf1QeFu4yX14O7UsXg+PEzjBr1A++8sxpjoE6dikya1Ju+fRsW6Xa8edfTnQVMN8BD3tp+mZFyHI5tgSPrrauB5ENWOfyR9eeXx7sKKAcVakHYpRBWzSpuCa0CkY2gfA2IqGslhsDQ4vsuSqlCef75JUybtpqAAD8ee6wDzzzThXLlAot8Oz7XH0WZdWofHFgOxzbDiR1waA0kbrfqDNyJqAuVGloVplHNILIhRFwO5avpWb9SPigjI4uAAKsO7emnO7Nz5wlefrkrzZpd3J1N7miiKGmMsa4KDq6Cw+us930/W5/lxT/YSgTlq1tl/1XbWEkgqolVHxAQXLzxK6W8IiUlgzFjfmbOnC0sX/4AQUH+VK5cjrlz7/D6tjVROOn0Qdi72Ko7iJ9jfZa4E9KTzp83OAIim1hXCBUvh1rdrKuEcpfolYFSpdwPP+xg0KD5bNtm1S0uXBjP9dc3Krbta6IoTse2wq6FsHmW9eRuUkLe8wWUsx7mqdLCulqo18+6QtCEoFSZcvBgEiNGfMdHH60HoHHjykyd2pcuXeoUaxyaKLwl/Qwc3QCbP7GSwva55zePEBAC1TtZxUWVGljPCFzSyn56WJOCUmXZhx+uY+jQBZw4kUJISADPPtuZESOuJijIv9hj0URRVLIyYf9y2PCedUvq4Tjr6eLc6t8EtbpDtfb2U7v6J1BKnS8ry3DiRAq9etVn8uQ+RfpcRGHpUepindwDK16DLZ+c/2xCZDRUuxoq1IaaXaHqldaDZkoplUtSUhq//baXHj0uB2DAgOZUqxZOt251EYdLGDRRXIik/bDja/jzffjr17OfV6gDda6Dmtdar7CqjoWolPIdc+ZsZujQBRw+fJoNGwZTv34kIkL37vWcDg3QRFE4h+Jg2ZNWhXQ28YMGt8KVw6BaB61bUEp5bPfuEzz88Ld89dUWANq0qUZqaobDUZ1PE4UnjsfD9w/C3p+scf9g6/bUen2h4e1QrrKz8SmlfEp6eiZvvfU7o0cvITk5nfDwIF55pRuDBrXB37/kNUipicIdkwUbP4RFgyAj2bpttcnfoP2zEF7d6eiUUj7q4YcXMG3aagBuv70p48f3pFq1cIejyp8miryYLFj/HqwcYzWmB1AzBnp/qAlCKXXRHnmkPUuW7GbcuJ706lXf6XAKpIkit2NbYP5dcOgPazzsMujwLDR/UPsoUEoVmjGGDz9cxzffxPPxx/+HiNCoUWU2bBiMn59v1GlqonC171f4X4zVp0K5S6Djy1ZRU0CI05EppXzQli1HGDRoPj/9tAuwbnnt06cBgM8kCdBEcVb8XJh/p5UkqrSE23+0+lZQSqlCOnMmnVdf/ZkxY34hLS2TqKhQ3nzzOnr3LvnFTHnRRAGwdppVYQ1WBz03fqkPximlLsiiRTuIjZ3H9u3HAbj//laMGdOdqCjfPaZootj25dkkceUw6PKm1eG8UkpdgF9/3cv27cdp2rQK06b145prajkd0kUr24li44ew4B5ruPWjEPOms/EopXxOZmYW8fHHaNTIep5q5MiOVK5cjgceuNKRBvy8oezexrPpI/j274CBFrHQ+XWnI1JK+Zg1a/Zz9dXvcc01/+HYMasR0ODgAAYPvqrUJAkoq4li+9ew4O/W8xKtH4VuU7S4SSnlsVOnUhk+/FvatPk3K1bsIzjYn+3bjxW8oI8qe0VP69+F7x6whpvdD13GavtMSimPGGP44otNDBv2Lfv2ncLPTxg+vD3PPx9DeHjp7Xa4bCWKVW/Ckses4ZYPQde3NUkopTz2yCPfMnHiCgCuuqoa77zTj1atLnM4Ku8rO0VPWz6FJY9bw03u0SShlCq0m29uTEREMJMn9+G33+4vE0kCysoVxbGt8O09gIHWIyBmrNMRKaV8wM8/7+Gnn3byzDNdAIiJqcOePcOpUKH0FjPlpfQnisw0WPA3yEixHqbr8obTESmlSrijR5MZOXIR7767BoBu3epx9dU1AcpckoCykCh+fQ4OrLQa9+vzgRY3KaXyZYzhv/9dy2OPfc+RI8kEBvrx5JPX0KrVpU6H5qjSnSh2fW/1Z43AdTOshv6UUioPmzYdZtCg+SxZshuAa6+tw5QpfYmO1o7JSm+iSD0J8++whlsOhnp9nI1HKVWijRv3G0uW7KZKlXKMG9eTu+++AtESCKA0J4r1MyDlGETUg64TnY5GKVUCJSamEBFhdSPw6qvdCQsL4tlnuxAZGepwZCVL6bw99vQB+PVZa7jTa9rhkFLqHH/9dYr+/T+jfft3SUvLBKBy5XK89VYvTRJ5KJ1H0CWPQfppqNEFGt7qdDRKqRIiMzOLt99eTnT0JP73vz/ZsyeRP/7Y73RYJV7pK3ra85PV4J9fgFWBrWWMSilg9eq/GDhwHqtXW4nhhhsa8fbbvalVK8LhyEo+r15RiEgvEdkiIvEi8mQe0yNE5GsRWSsif4rIfRe90cWPWu9XPAiVfLM3KaVU0Ro9ejFt285g9er91KxZgTlz+jN37h2aJDzktSsKEfEHJgM9gARgpYh8ZYzZ6DLbQ8BGY8z1IlIF2CIiHxlj0i5oo/t+hcNx1vA1L19E9Eqp0qRevUqIwIgRHRg9Ooby5YOcDsmneLPoqS0Qb4zZASAis4EbAddEYYBwse5BKw8cAzIueIu/jbbeWw2FkIoXvBqllG/bseM4K1fuo3//ZgAMGNCcdu2q53QupArHm4miOrDXZTwBaJdrnknAV8BfQDjQ3xiTlXtFIvIg8CBArVr5dCt4bCvs/h4CQqH90xcdvFLK96SlZTJ27K+8+OJSjDG0bl2N+vUjERFNEhfBm3UUedUim1zjPYE4oBrQEpgkIhXOW8iY6caYNsaYNlWqVMl7aytetd4vv0GfwFaqDFq6dDctW07jqad+JCUlg1tvbVIm22XyBm9eUSQANV3Ga2BdObi6D3jNGGOAeBHZCUQDKwq9tT9nWu/RdxY+UqWUzzpyJJnHH/+emTPjAGjQIJKpU/vSrVs9ZwMrRbyZKFYCDUSkLrAPuAO4K9c8e4BuwDIRqQo0AnYUekupJ88OV+90YdEqpXxSbOw8Pv98E8HB/owa1YknnuhISEjpu/PfSV7bm8aYDBEZAiwE/IH3jDF/ikisPX0a8CIwU0TWYxVVjTTGHCn0xuK/tN5DoiA0smi+gFKqxMrKMvj5WaXbL7/clTNnMnjrrZ40aBDlcGSlk1fTrjHmG+CbXJ9Ncxn+C7juojd0YJX13ui2i16VUqrkSk5O58UXlxAXd5Bvvrkrp5J6/vzchRWqKPn+9VlWJsRNsoYb3OJsLEopr5k/fytDhixg164TiMCKFfto166G02GVCb6fKHbMs97LV4Na3ZyNRSlV5BISTjJs2Ld88cUmAFq0qMq0af00SRQj308U+3+33gPKabtOSpUyU6asZOTIRSQlpREWFsiLL17L0KHtCAgone2ZllS+nyh22lUgXcY6G4dSqsgdOZJMUlIaN98czYQJvahZU9tmcoJvJwqTBYfXWcPVOjobi1Lqop04kcLmzUdo394qVho5siNt21anVy9t4NNJvn39dmL72eFy+ni+Ur7KGMPs2Rto3HgyN9wwi2PHzgAQHBygSaIE8O1EsX+59V79GmfjUEpdsPj4Y/Tq9RF33vk5Bw4k0aBBFImJKU6HpVz4dtHToTjrvVJDR8NQShVeamoGr7/+Cy+/vIzU1EwqVQrh9dd78I9/tMp5mE6VDB4nChEJM8ac9mYwhfbXz9a71k8o5XP69/+MuXO3AHDPPS14440eXHJJmMNRqbwUWPQkIleLyEZgkz3eQkSmeD0yTxzZYL2Xv8zZOJRShfbII+2Jjq7Mjz/ew/vv36RJogTzpI5iPFZz4EcBjDFrgc7eDMpjgeWt94oNnI1DKeVWVpZhxow/GDFiYc5nMTF12LBhENdeW9fByJQnPCp6MsbslXMfZsv0TjiFkHwYkg9ayaKiNiesVEm1fv1BYmPn8+uvVj9m99zTghYtLgXA39+376cpKzxJFHtF5GrAiEgQ8DB2MZSjTsRb7xXrg+iPTamS5vTpNJ5/fgnjxv1GZqbh0kvL89ZbPWnevKrToalC8iRRxAITsLo2TQC+AwZ7MyiPHF5rvVfSYielSpqvv97CkCEL2LMnERF46KGrePnlrkREhDgdmroAniSKRsaYu10/EJGOwC/eCclD2+w+KKq2djQMpdT55szZzJ49ibRqdSnvvNOPq66q7nRI6iJ4kijeBq704LPiddDugyK8lqNhKKUgIyOLfftOUrt2RQDGjOlBq1aXERvbRhvwKwXyTRQi0gG4GqgiIo+6TKqA1WOds7LrJfSKQilH/f57ArGx80hNzWTt2liCgvypXLkcQ4a0dTo0VUTcpfogoDxWMgl3eZ0EbvV+aG6knYIzdo+pWkehlCOOHz/DoEHzuPrqd1m79iApKRns2nXC6bCUF+R7RWGMWQIsEZGZxpjdxRhTwY5vs94r1tc+KJQqZsYYZs3awPDhCzl06DQBAX48/vjVPP10Z8qVC3Q6POUFntRRJIvIG0BTIOeWBWNMV69FVZCU49Z78iHHQlCqrLr77i+YNctqFaFTp1pMndqXpk0vcTgq5U2e1DJ9BGwG6gLPA7uAlV6MqWDHt1rvNa91NAylyqJeveoTFRXKe+/dwOLF92qSKAM8uaKIMsa8KyLDXIqjlng7MLdST1jvmamOhqFUWbBo0Q62bz/GwIFtABgwoDn9+jUkMjLU4chUcfEkUaTb7/tFpC/wF+Bsr+Y7F1jv9fo6GoZSpdnBg0k8+uh3fPzxeoKD/enevR6XXx6JiGiSKGM8SRQviUgEMALr+YkKwCPeDKpAAfaPNCjc0TCUKo2ysgzTp6/myScXkZiYSkhIAM8+21n7qy7DCkwUxph59mAicC3kPJntnNP7rffKzR0NQ6nSZu3aAwwcOI/ly/cB0Lt3fSZN6kO9epUcjkw5yd0Dd/7A7VhtPH1rjNkgIv2AUUAo0Kp4QsxDdh1FsJ7hKFWUnnhiEcuX76NatXAmTOjFLbc0RvQW9DLP3RXFu0BNYAUwUUR2Ax2AJ40xc4ohtvxl3x4bomc5Sl0MYwzJyemEhQUBMHFiL6ZNW8Xzz19LhQrBDkenSgp3iaIN0NwYkyUiIcARoL4x5kDxhOZGRrL1rnUUSl2w3btPMHToAk6fTmfRogGICI0aVWb8+F5Oh6ZKGHeJIs0YkwVgjEkRka0lIkmYLOvlHwR+Hnf5rZSypadnMn787zz//BKSk9MJDw9i27ZjNGwY5XRoqoRyd6SNFpF19rAAl9vjAhhjjDM1yVn23boB5RzZvFK+7Jdf9hAbO58NG6xWDfr3b8q4cT2pVk2vzlX+3CWKxsUWRWFkJ4rIRs7GoZSPGTr0GyZNshpVqFevEpMn96FXr/oOR6V8gbtGAUtWQ4DZMtOs96AKzsahlI+pUiWMwEA/Ro7syKhRnQgN1Qb8lGe82qOIiPQSkS0iEi8iT+YzT4yIxInIn4VqGiT5YJHFqVRptHnzEb77bnvO+MiRHVm3bhAvvthVk4QqFK/VBtvPYUwGemD1tb1SRL4yxmx0maciMAXoZYzZIyIFty6WkWK9X6qdoiiVlzNn0nnllWWMGfMLFSuGsHnzECIjQwkODiA6urLT4Skf5FGiEJFQoJYxZksh1t0WiDfG7LDXMRu4EdjoMs9dwBfGmD0AxpiC2w3P7tku6a9ChKJU2fDdd9sZPHg+27dbzxrdcEMj7bJFXbQCi55E5HogDvjWHm8pIl95sO7qwF6X8QT7M1cNgUoislhEVovIPQWv1lhvlzj3YLhSJc3+/ae4447P6NnzQ7ZvP07TplVYtuw+Zsy4gUqVtAE/dXE8uaIYjXV1sBjAGBMnInU8WC6v8xiTx/ZbA92wmgX5TUR+N8ZsPWdFIg8CDwI0rRlmL6k/fqWy/d///Y/ff08gNDSA0aNjGD68PYGBzndtr0oHTyqzM4wxiRew7gSsJkCy1cBqojz3PN8aY04bY44AS4EWuVdkjJlujGljjGkTEmx3spdx5gJCUqr0MObseddrr3WjX7+GbNz4EE880VGThCpSniSKDSJyF+AvIg1E5G3gVw+WWwk0EJG6IhIE3AHkLrKaC3QSkQARKQe0Aza5X639z1GhtgchKFX6nDqVyvDh3zJw4Lycz7p0qcPXX99JnToVnQtMlVqeJIqhWP1lpwIfYzU3/khBCxljMoAhwEKsg///jDF/ikisiMTa82zCqvtYh9X44AxjzAa3K87KsN7DLvUgdKVKD2MMn3++kcaNJ/PWW8v5z3/i2LXrhNNhqTJAXC9f85xBpJUxZk0xxVOgNpeHm1WDk+DWRVC7m9PhKFUsdu48zpAhC/jmm20AtG1bnWnT+tKq1WUOR6Z8hYisNsa0uZBlPanMHicilwGfArONMX9eyIaKTHZi89cmkFXpZ4zh9dd/4fnnl3DmTAYREcG8+mo3HnywNf7+Xn1eVqkcnvRwd62IXIrVidF0EakAfGKMecnr0eUl/bT1HqCJQpV+IsLWrUc5cyaDO+9sxrhxPbn00vJOh6XKmAKLns6ZWeQK4AmgvzEmyGtRudGmTohZNTQV/rYKqrZ2IgSlvOrIkWQOHEiiWbNLcsbXrNlPjx6XOxyZ8mUXU/TkyQN3jUVktIhsACZh3fFU40I2VqS0UUBVyhhjmDkzjujoSdx226ekpWUCULlyOU0SylGe1FH8B5gFXGeMKQHtZthXQNppkSpFNm06TGzsfJYutRptbtHiUo4fP0PVqlrMpJznSR1F++IIxGPZRWWiiUL5vuTkdF5+eSlvvPEr6elZVKlSjnHjenL33Vcg2kiTKiHyPdqKyP+MMbeLyHrObXrD2R7u9IpClRLGGLp2fZ/ly/cBMHBga159tZu2zaRKHHdH22H2e7/iCMRjWVa5rSYK5etEhMGDryI5OZ133ulHhw41C15IKQfkW5ltjNlvDw42xux2fQGDiye8PCOz3jRRKB+TmZnF228vZ9y433I+GzCgOatXP6hJQpVonjyx0yOPz3oXdSCFFhjmdARKeWzVqr9o124GDz/8LaNG/cBff50CrKsKbcBPlXTu6igGYV051BORdS6TwoFfvB2YewJ+2pWjKvkSE1N4+ukfmTx5JcZAzZoVePvt3lSrFu50aEp5zF35zcfAAuBVwLW/61PGmGNejaogASFot12qJDPG8OmnG3nkkW/Zvz8Jf39h+PD2PPdcDOXLO/KsqlIXzF2iMMaYXSLyUO4JIhLpaLLQviiUD3jnndXs359E+/Y1mDatLy1aaIvHyjcVdEXRD1iNVYPsegpvgHpejMu9UO0gXpU8qakZnDiRQtWq5RERpkzpw+LFu/jnP1vj56dXwMp35ZsojDH97Pe6xReOhwLKOR2BUudYsmQXsbHzqVYtnEWLBiAiNGpUmUaN9KRG+T5P2nrqKCJh9vDfRGSciNTyfmhu6K2xqoQ4fPg09947h5iY99m8+Qh79yZy8OBpp8NSqkh5cnvsVCBZRFpgtRy7G/jAq1EVRO94Ug7LyjK8++4fREdP5v331xIc7M/zz8ewbt0gbQZclTqenJpnGGOMiNwITDDGvCsif/d2YG7pFYVykDGGnj0/ZNGiHQB0716PKVP60KBBlMORKeUdnhxxT4nIv4ABQCcR8QecPaU/tsnRzauyTUTo1KkW69cfZPz4ntxxRzNtwE+Vap70mX0pcBew0hizzK6fiDHG/Lc4AsytTU0xq8Z2hv5LnNi8KqPmz99KenoWN90UDVh3OJ05k0HFiiEOR6aUZ7zaZ7Yx5oCIfARcJSL9gBVOJYkcAdq6pioeCQknGTbsW774YhOVK5ejc+faREaGEhwcQHCwFoGqssGTu55uB1YAt2H1m71cRG71dmBundzj6OZV6ZeRkcX48b/RuPFkvvhiE2FhgYwadQ0VKmhf7ars8eSU6CngKmPMIQARqQIsAj7zZmBuRUY7tmlV+q1YsY+BA+cRF3cAgJtvjmbChF7UrBnhcGRKOcOTROGXnSRsR/HstlrvCdLbD5V3ZGUZ7rtvLhs3HqZWrQgmTerN9dc3cjospRzlSaL4VkQWYvWbDdAf+MZ7IXlAn6NQRcgYQ2pqJiEhAfj5CZMn92HBgm08+2wXwsK0AT+lPKnMflxE/g+4Bqu9p+nGmC+9Hpk7mihUEYmPP8bgwfOpWbMC7757IwAxMXWIianjbGBKlSDu+qNoAIwFLgfWA48ZY/YVV2Duub+lV6mCpKZmMGbML7zyyjJSUzOJjAzl9deTiYrSdsSUys1dXcN7wDzgFqwWZN8ulog8kXyo4HmUysePP+6kefNpPPfcYlJTM/n731uwefNDmiSUyoe7oqdwY8y/7eEtIvJHcQTkkUoNnY5A+aDMzCzuu28uH3xgddjYqFEU06b102ImpQrgLlGEiEgrzvZDEeo6boxxLnGIszddKd/k7+9HQIAfISEBPP10Jx577Gp9aE4pD+TbhIeI/ORmOWOM6eqdkNxrU1PMqo//BZ1ecWLzysesX3+QlJQMrrqqOgBHjyZz4kQKl18e6XBkShUvrzThYYy59sJD8jK9olAFOH06jdGjFzN+/O80aBDF2rWxBAX5ExVVTusilCok37zu1kSh3Pjqqy0MHbqAPXsSEYHu3euSnp5JUJC/06Ep5ZO8esQVkV4iskVE4kXkSTfzXSUimR63IaWJQuVhz55EbrppNjfeOJs9exK58srLWLHin7z9dh99cE6pi+C1Kwq734rJQA8gAVgpIl8ZYzbmMd8YYKHnK9dEoc6VmZlFTMxMdu48QXh4EC+91JXBg68iIEB/K0pdrAIThVg9stwN1DPGvGD3R3GpMWZFAYu2BeKNMTvs9cwGbgQ25ppvKPA5cJXHUWuiUDZjDCKCv78fo0fH8PXXW3nrrZ5Ur17B6dCUKjU8OeJOAToAd9rjp7CuFApSHdjrMp5gf5ZDRKoDNwPT3K1IRB4UkVUissr6QBNFWXf8+BliY+fxyivLcj4bMKA5n356myYJpYqYJ0VP7YwxV4rIGgBjzHER8aTAN6++IXPfi/sWMNIYk+muK0ljzHRgOli3x+a9alUWGGP4+OP1PProdxw6dJrw8CCGDGlLRESIdkeqlJd4kijS7XoEAzn9UWR5sFwCUNNlvAbwV6552gCz7X/wykAfEckwxsxxu2a9oiiTtm49yuDB8/nhh50AdOpUi6lT+xIRod2RKuVNniSKicCXwCUi8jJwK/C0B8utBBqISF1gH3AHVt/bOYwxdbOHRWQmMK/AJAGaKMqYjIwsXnppKa+++jNpaZlERYXyxhs9uPfelnoVoVQx8KSZ8Y9EZDXQDavM5yZjzCYPlssQkSFYdzP5A+8ZY/4UkVh7utt6Cbc0UZQp/v7CsmV7SEvL5B//aMmYMT2oXFkfmlOquOTbhEfODNZdTucxxjjScXWbmmJW/fcRuHa8E5tXxeTgwSRSUjKoXbsiANu2HWX//iQ6d67tbGBK+SivNOHhYj5W/YQAIUBdYAvQ9EI2WCQqXu7YppV3ZWUZpk9fzZNPLqJNm2p8//0ARIQGDaJo0CDK6fCUKpM8KXq6wnVcRK4EBnotIo9ouXRpFBd3gNjYeSxfbvWPFRTkT1JSGuHhwQ5HplTZVugns40xf4iI5w/HeYNWYJYqp06l8txzi5kwYTlZWYZq1cKZMKEXt9zSWCurlSoBPHky+1GXUT/gSuCw1yLyiB48Sou0tEyuvHI68fHH8PMThg1rxwsvXEuFCnoVoVRJ4ckVRbjLcAZWncXn3gnHQ3rXU6kRFOTPgAHN+frrrUyb1pfWras5HZJSKhe3icJ+0K68MebxYorHM1oc4bPS0zMZP/53atWK4I47mgHw5JPX8NRTnfD31xMApUqifBOFiATYz0JcWZwBeUYThS/65Zc9xMbOZ8OGQ1SpUo5+/RpSvnyQ9hOhVAnn7opiBVZ9RJyIfAV8CpzOnmiM+cLLsbmhicKXHDt2hpEjv2fGjDUA1KtXiSlT+lC+vPYRoZQv8KSOIhI4CnTl7PMUBnAuUWgdhU8wxvDBB+sYMeI7jhxJJjDQj5EjOzJqVCdCQwOdDk8p5SF3ieIS+46nDZxNENncP87tbVpH4RPS07N49dWfOXIkmS5dajN1al8aN67idFhKqUJylyj8gfJ41lx4MdNEUVKdOZNOWlomEREhBAX5M316P3bsOM4997TQZyKU8lHuEsV+Y8wLxRZJYegBp0RauDCewYO/ISamNu++eyMAnTrVplMnbZ9JKV/mLlGU3KOx1lGUKPv3n2L48IV88smfAISFBZKcnE65cloPoVRp4O6I263Yoii0kpvDypLMzCwmTVpBdPRkPvnkT0JDAxgzpjurVz+oSUKpUiTfKwpjzLHiDKRQtOjJcSkpGXTu/B9WrrQ6LezXryFvv92bOnUqOhuYUqrIFbpRwJJBE4XTQkICaNbsEvbvT2LixF7cdFO0VlYrVUr5ZqLQOopiZ4zhiy82UbVqea65xurLaty4nvj7izYDrlQp55uJQq8oitXOnccZMmQB33yzjejoysTFDSQ4OICKFUOcDk0pVQx8M1FoEUexSEvL5M03f+XFF5dy5kwGERHBDBvWjoAAvaJTqizxzUShVxRet2zZbmJj57Nxo9X1yF13XcGbb17HpZeWdzgypVRx89FEobzpzJl0br31Uw4dOk39+pFMmdKHHj20n3KlyirfTBTppwueRxWKMYbMTENAgB+hoYGMG3cdW7ce5V//6kRIiG/+TJRSRcM3jwChUU5HUKps3HiY2Nh59OhRj2ee6QLA3Xc3dzgqpVRJ4aO1klpHURSSk9MZNeoHWrSYxrJle5gxYw2pqRlOh6WUKmF884pCXbQFC7bx0EPfsHPnCQAGDmzNq692IzhYfxJKqXPpUaGMOX06jXvvnctnn20EoHnzqkyb1pcOHWo6HJlSqqTyzUShz1FcsHLlAjl27AxhYYE8/3wMw4a11+cilFJu+WaiUIWyatVfVKwYQv36kYgIM2Zcj7+/H7VqRTgdmlLKB/joqaReUXgiMTGFoUO/oW3bfxMbOw9jrI4J69atpElCKeUxvaIohYwx/O9/f/LIIws5cCAJf3/hyisvIyMji8BAf6fDU0r5GN9MFFpHka/t24/x0EPfsHDhdgA6dKjBtGn9aN68qsORKaV8lW8mCpWnU6dSadPm35w4kULFiiGMGdOdBx64Ej8/TaxKqQvn1UQhIr2ACYA/MMMY81qu6XcDI+3RJGCQMWatB2su2kBLifDwYIYPb098/DHGjr2OSy4JczokpVQp4LVEISL+wGSgB5AArBSRr4wxG11m2wl0McYcF5HewHSgnbdiKm0OHz7N449/T7dudRkwoAUAzzzTWXuaU0oVKW/e9dQWiDfG7DDGpAGzgRtdZzDG/GqMOW6P/g7U8GjNZfxAmJVlmDHjDxo1msT776/lqad+JD09E0CThFKqyHkzUVQH9rqMJ9if5ed+YEFeE0TkQRFZJSKrijA+n7RhwyE6d/4P//zn1xw/nkL37vX44Yd79G4mpZTXeLOOIq9TW5PnjCLXYiWKa/KaboyZjlUsRZuaYspiHcWZM+mMHr2YceN+JyMji6pVwxg/vid33NFMryKUUl7lzUSRALg2IFQD+Cv3TCLSHJgB9DbGHPViPD7Nz0/46qutZGZmMXhwG15+uZv2Wa2UKhbeTBQrgQYiUhfYB9wB3OU6g4jUAr4ABhhjtnq+6rJxBp2QcJJy5QKJjAwlODiAmTOtKp527TyrylFKqaLgtToKY0wGMARYCGwC/meM+VNEYkUk1p7tWSAKmCIicVoHYcnIyGL8+N9o3Hgyjz/+Xc7n7drV0CShlCp2Xn2OwhjzDfBNrs+muQw/ADxQ6BWX4jL55csTGDhwHmvXHgQgMTGVjIwsbeFVKeUYfTK7hDhxIoVRo35g2rRVGAO1a0cwaVIf+vVr6HRoSqkyzkcTRem6ojh+/AxNmkzhwIEkAgL8GDGiA88805mwsCCnQ1NKKV9NFKVLpUqh9O5dn61bjzJ1al+uuEIb8FNKlRy+mSh8vI4iNTWDMWN+oUuX2nTpUgeASZP6EBISoA34KaVKHN9MFD7sxx93MmjQfLZuPUrjxpVZv34Q/v5+lCsX6HRoSimVJx9NFL531n3o0GlGjPiODz9cB0B0dGWmTOmLv7/ezaSUKtl8NFH4juwG/EaOXMSJEymEhATw9NOdePzxjgQFaftMSqmSzzcThQ/VUSQmpvDUUz9y4kQKPXtezuTJfbj88kinw1JKKY/5ZqIo4U6fTiMgwI/g4AAqVQpl2rS+ZGYabrutiTbgp5TyOT5aQF5yD7ZffbWFJk2m8Prrv+R8dsstTbj99qaaJJRSPslHE0XJs2dPIjfdNJsbb5zNnj2JLFy4naysPFtVV0opn6KJ4iKlp2cyduyvNG48mblztxAeHsSECb1YsuRefSZCKVUq+GYdRQkpwjlyJJlu3f7LunVWA3633daE8eN7Ur16BYcjU0qpouObiaKEiIoKpXLlctStW5FJk/rQp08Dp0NSJUh6ejoJCQmkpKQ4HYoqQ0JCQqhRowaBgUX3EK+PJgpnriiMMXz00Xratq1Ow4ZRiAgffngzEREh+mS1Ok9CQgLh4eHUqVNHb2RQxcIYw9GjR0lISKBu3bpFtl6to/DQli1H6N79AwYM+JLBg+djjFVRfdll4ZokVJ5SUlKIiorSJKGKjYgQFRVV5FexekVRgJSUDF59dRmvvfYLaWmZREWF8re/NS+27SvfpklCFTdv/OZ8NFEUj0WLdjBo0Hzi448B8I9/tOT113sQFVXO4ciUUqr4+GbRUzGcpR08mES/fh8TH3+MJk2qsHTpvbz77o2aJJRP8ff3p2XLljRr1ozrr7+eEydO5Ez7888/6dq1Kw0bNqRBgwa8+OKLOUWqAAsWLKBNmzY0btyY6OhoHnvsMQe+gXtr1qzhgQcK35tycUlNTaV///7Ur1+fdu3asWvXrjzn++STT2jevDlNmzbliSeeyPl8+PDhtGzZkpYtW9KwYUMqVqwIwOHDh+nVq1cxfAObMcanXq1rYEzCz8YbMjOzTFZWVs74mDE/m1dfXWZSUzO8sj1Vum3cuNHpEExYWFjO8D333GNeeuklY4wxycnJpl69embhwoXGGGNOnz5tevXqZSZNmmSMMWb9+vWmXr16ZtOmTcYYY9LT083kyZOLNLb09PSLXsett95q4uLiinWbhTF58mQzcOBAY4wxs2bNMrfffvt58xw5csTUrFnTHDp0yBhj/Z0WLVp03nwTJ0409913X874vffea37+Oe9jYV6/PWCVucDjro8WPRX9FUVc3AFiY+fx0ENXMWBACwCeeKJjkW9HlVFveukqeITnT/936NCBdeusZu4//vhjOnbsyHXXXQdAuXLlmDRpEjExMTz00EO8/vrrPPXUU0RHRwMQEBDA4MGDz1tnUlISQ4cOZdWqVYgIzz33HLfccgvly5cnKSkJgM8++4x58+Yxc+ZM7r33XiIjI1mzZg0tW7bkyy+/JC4uLudMuX79+vzyyy/4+fkRGxvLnj17AHjrrbfo2PHc/8dTp06xbt06WrSw/l9XrFjBI488wpkzZwgNDeU///kPjRo1YubMmcyfP5+UlBROnz7N119/zdChQ1m/fj0ZGRmMHj2aG2+8kV27djFgwABOnz4NwKRJk7j66qs93r95mTt3LqNHjwbg1ltvZciQIRhjzqlH2LFjBw0bNqRKlSoAdO/enc8//5xu3bqds65Zs2bx/PPP54zfdNNNfPTRR+ftF2/w0URRdE6dSuW55xYzYcJysrIMqamZ/O1vzbUSUpUqmZmZ/PDDD9x///2AVezUunXrc+a5/PLLSUpK4uTJk2zYsIERI0YUuN4XX3yRiIgI1q9fD8Dx48cLXGbr1q0sWrQIf39/srKy+PLLL7nvvvtYvnw5derUoWrVqtx1110MHz6ca665hj179tCzZ082bdp0znpWrVpFs2bNcsajo6NZunQpAQEBLFq0iFGjRvH5558D8Ntvv7Fu3ToiIyMZNWoUXbt25b333uPEiRO0bduW7t27c8kll/D9998TEhLCtm3buPPOO1m1atV58Xfq1IlTp06d9/nYsWPp3r37OZ/t27ePmjVrAlayjYiI4OjRo1SuXDlnnvr167N582Z27dpFjRo1mDNnDmlpaeesZ/fu3ezcuZOuXbvmfNamTRuefvrpAvd3UfDNRFEEB3FjDHPmbObhh78lIeEkfn7CsGHteOGFazVJqKJXiDP/onTmzBlatmzJrl27aN26NT169AA476zWVWF+/4sWLWL27Nk545UqVSpwmdtuuw1/f6svlv79+/PCCy9w3333MXv2bPr375+z3o0bN+Ysc/LkSU6dOkV4eHjOZ/v37885CwdITEzk73//O9u2bUNESE9Pz5nWo0cPIiOt5v2/++47vvrqK8aOHQtYtzHv2bOHatWqMWTIEOLi4vD392fr1q15xr9s2bICv2M2Y87/u+fev5UqVWLq1Kn0798fPz8/rr76anbs2HHOPLNnz+bWW2/N2W8Al1xyCX/99ZfHsVwM30wUF+nIkWTuu28u8+ZZP4Q2barxzjv9uPLKyxyOTKmiFRoaSlxcHImJifTr14/Jkyfz8MMP07RpU5YuXXrOvDt27KB8+fKEh4fTtGlTVq9enVOsk5/8Eo7rZ7nv6Q8LC8sZ7tChA/Hx8Rw+fJg5c+bknCFnZWXx22+/ERoa6va7ua77mWee4dprr+XLL79k165dxMTE5LlNYwyff/45jRo1Omd9o0ePpmrVqqxdu5asrCxCQkLy3G5hrihq1KjB3r17qVGjBhkZGSQmJuYkLFfXX389119/PQDTp08/JyGAlSgmT558zmcpKSlu909R8s27ni6yjiI8PIj4+GNUqBDMpEm9+f33+zVJqFItIiKCiRMnMnbsWNLT07n77rv5+eefWbRoEWBdeTz88MM5d9w8/vjjvPLKKzln1VlZWYwbN+689V533XVMmjQpZzy76Klq1aps2rQpp2gpPyLCzTffzKOPPkrjxo2JiorKc71xcXHnLdu4cWPi4+NzxhMTE6levToAM2fOzHebPXv25O23384521+zZk3O8pdddhl+fn588MEHZGZm5rn8smXLiIuLO++VO0kA3HDDDbz//vuAVVfTtWvXPBProUOHAGv/TZky5Zw7ubZs2cLx48fp0KHDOcts3br1nKI3b/LRRFF4v/yyh6NHkwEIDg5g9uxb2Lz5IR56qK32W63KhFatWtGiRQtmz55NaGgoc+fO5aWXXqJRo0ZcccUVXHXVVQwZMgSA5s2b89Zbb3HnnXfSuHFjmjVrxv79+89b59NPP83x48dp1qwZLVq04KeffgLgtddeo1+/fnTt2pXLLnN/Eta/f38+/PDDnGIngIkTJ7Jq1SqaN29OkyZNmDZt2nnLRUdHk5iYmHN2/8QTT/Cvf/2Ljh075nuQB+vKIz09nebNm9OsWTOeeeYZAAYPHsz7779P+/bt2bp16zlXIRfq/vvv5+jRo9SvX59x48bx2muv5Uxr2bJlzvCwYcNo0qQJHTt25Mknn6Rhw4Y502bNmsUdd9xxXoL56aef6Nu370XH6AnJqwytJGtTU8yqFb/DZe08mv/o0WSefHIRM2as4f77WzFjxg1ejlApy6ZNm2jcuLHTYZRq48ePJzw8vEQ/S+EtnTt3Zu7cuXnWC+X12xOR1caYNheyrVJ7Km2M4f3344iOnsyMGWsIDPSjWrXwPCuXlFK+adCgQQQHBzsdRrE7fPgwjz76qEc3DxQFH63Mdl9HsXnzEWJj57FkyW4AYmLqMHVqX6KjK7tdTinlW0JCQhgwYIDTYRS7KlWqcNNNNxXb9nw0UeQvIeEkLVpMIy0tk8qVy/Hmm9cxYIA+F6Gc4e42VKW8wRulJr6ZKNz849WoUYEBA5rj5ye89lp3IiOL5/YxpXILCQnh6NGj2tS4KjbG7o8iv1t7L5RvJgoX+/efYvjwhcTGtiEmpg4A06dfr/1VK8fVqFGDhIQEDh8+7HQoqgzJ7uGuKPloohAyM7OYOnUVTz31IydPphIff4yVK/+JiGiSUCVCYGBgkfYyppRTvHrXk4j0EpEtIhIvIk/mMV1EZKI9fZ2IXOnJev9Yl0j79u8ydOgCTp5M5frrG/L557fr5b1SSnmB164oRMQfmAz0ABKAlSLylTFmo8tsvYEG9qsdMNV+z9feExW4qvfPZGVZ9RFvv92bG29spElCKaW8xJtXFG2BeGPMDmNMGjAbuDHXPDcC/7WbS/8dqCgibh/jPJYciojw6KPt2bTpIW66KVqThFJKeZE36yiqA3tdxhM4/2ohr3mqA+e0FSAiDwIP2qOp8NyGceMgj6ZnyprKwBGngyghdF+cpfviLN0XZzUqeJa8eTNR5HWan/sGX0/mwRgzHZgOICKrLvQx9NJG98VZui/O0n1xlu6Ls0Tk/M41POTNoqcEoKbLeA0gd+PpnsyjlFLKQd5MFCuBBiJSV0SCgDuAr3LN8xVwj333U3sg0RhzfhOVSimlHOO1oidjTIaIDAEWAv7Ae8aYP0Uk1p4+DfgG6APEA8nAfR6serqXQvZFui/O0n1xlu6Ls3RfnHXB+8LnmhlXSilVvEptM+NKKaWKhiYKpZRSbpXYROGt5j98kQf74m57H6wTkV9FpIUTcRaHgvaFy3xXiUimiNxanPEVJ0/2hYjEiEiciPwpIkuKO8bi4sH/SISIfC0ia+194Ul9qM8RkfdE5JCIbMhn+oUdN40xJe6FVfm9HagHBAFrgSa55ukDLMB6FqM9sNzpuB3cF1cDlezh3mV5X7jM9yPWzRK3Oh23g7+LisBGoJY9fonTcTu4L0YBY+zhKsAxIMjp2L2wLzoDVwIb8pl+QcfNknpF4ZXmP3xUgfvCGPOrMea4Pfo71vMopZEnvwuAocDnwKHiDK6YebIv7gK+MMbsATDGlNb94cm+MEC4WO39lMdKFBnFG6b3GWOWYn23/FzQcbOkJor8mvYo7DylQWG/5/1YZwylUYH7QkSqAzcD04oxLid48rtoCFQSkcUislpE7im26IqXJ/tiEtAY64He9cAwY0xW8YRXolzQcbOk9kdRZM1/lAIef08RuRYrUVzj1Yic48m+eAsYaYzJLOWNRXqyLwKA1kA3IBT4TUR+N8Zs9XZwxcyTfdETiAO6ApcD34vIMmPMSS/HVtJc0HGzpCYKbf7jLI++p4g0B2YAvY0xR4sptuLmyb5oA8y2k0RloI+IZBhj5hRLhMXH0/+RI8aY08BpEVkKtABKW6LwZF/cB7xmrIL6eBHZCUQDK4onxBLjgo6bJbXoSZv/OKvAfSEitYAvgAGl8GzRVYH7whhT1xhTxxhTB/gMGFwKkwR49j8yF+gkIgEiUg6r9eZNxRxncfBkX+zBurJCRKpitaS6o1ijLBku6LhZIq8ojPea//A5Hu6LZ4EoYIp9Jp1hSmGLmR7uizLBk31hjNkkIt8C64AsYIYxJs/bJn2Zh7+LF4GZIrIeq/hlpDGm1DU/LiKzgBigsogkAM8BgXBxx01twkMppZRbJbXoSSmlVAmhiUIppZRbmiiUUkq5pYlCKaWUW5oolFJKuaWJQpVIdsuvcS6vOm7mTSqC7c0UkZ32tv4QkQ4XsI4ZItLEHh6Va9qvFxujvZ7s/bLBbg21YgHztxSRPkWxbVV26e2xqkQSkSRjTPmintfNOmYC84wxn4nIdcBYY0zzi1jfRcdU0HpF5H1gqzHmZTfz3wu0McYMKepYVNmhVxTKJ4hIeRH5wT7bXy8i57UaKyKXichSlzPuTvbn14nIb/ayn4pIQQfwpUB9e9lH7XVtEJFH7M/CRGS+3bfBBhHpb3++WETaiMhrQKgdx0f2tCT7/RPXM3z7SuYWEfEXkTdEZKVY/QQM9GC3/IbdoJuItBWrL5I19nsj+ynlF4D+diz97djfs7ezJq/9qNR5nG4/XV/6yusFZGI14hYHfInVikAFe1plrCdLs6+Ik+z3EcBT9rA/EG7PuxQIsz8fCTybx/ZmYvddAdwGLMdqUG89EIbVNPWfQCvgFuDfLstG2O+Lsc7ec2JymSc7xpuB9+3hIKyWPEOBB4Gn7c+DgVVA3TziTHL5fp8CvezxCkCAPdwd+NwevheY5LL8K8Df7OGKWO0+hTn999ZXyX6VyCY8lALOGGNaZo+ISCDwioh0xmqOojpQFTjgssxK4D173jnGmDgR6QI0AX6xmzcJwjoTz8sbIvI0cBirFd5uwJfGalQPEfkC6AR8C4wVkTFYxVXLCvG9FgATRSQY6AUsNcacsYu7msvZHvkigAbAzlzLh4pIHFAHWA187zL/+yLSAKs10MB8tn8dcIOIPGaPhwC1KJ1tQKkioolC+Yq7sXoma22MSReRXVgHuRzGmKV2IukLfCAibwDHge+NMXd6sI3HjTGfZY+ISPe8ZjLGbBWR1lht5rwqIt8ZY17w5EsYY1JEZDFWs9f9gVnZmwOGGmMWFrCKM8aYliISAcwDHgImYrVl9JMx5ma74n9xPssLcIsxZosn8SoFWkehfEcEcMhOEtcCtXPPICK17Xn+DbyL1SXk70BHEcmucygnIg093OZS4CZ7mTCsYqNlIlINSDbGfAiMtbeTW7p9ZZOX2ViNsXXCasgO+31Q9jIi0tDeZp6MMYnAw8Bj9jIRwD578r0us57CKoLLthAYKvbllYi0ym8bSmXTRKF8xUdAGxFZhXV1sTmPeWKAOBFZg1WPMMEYcxjrwDlLRNZhJY5oTzZojPkDq+5iBVadxQxjzBrgCmCFXQT0FPBSHotPB9ZlV2bn8h1W38aLjNV1J1h9iWwE/hCRDcA7FHDFb8eyFqtZ7dexrm5+waq/yPYT0CS7MhvryiPQjm2DPa6UW3p7rFJKKbf0ikIppZRbmiiUUkq5pYlCKaWUW5oolFJKuaWJQimllFuaKJRSSrmliUIppZRb/w/NY/0XmWCAjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate ROC curve and AUC\n",
    "if len(np.unique(test_labels)) == 2:\n",
    "    fpr, tpr, _ = roc_curve(test_labels, logits[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ROC curve is only applicable for binary classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f670fc6b-1fa0-4473-836d-7bb3229b45ef",
   "metadata": {},
   "source": [
    "### **PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ca3d149-ba9b-4353-b5f5-0c7ff983082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Function to predict a single sample\n",
    "def predict_single_sample(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load tokenizer and model (using the provided variable names)\n",
    "    tokenizer = loaded_distilroberta_tokenizer\n",
    "    model = loaded_distilroberta_model.to(device)\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to the same device as the model\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    prediction = torch.argmax(logits, dim=-1).item()\n",
    "    return \"1\" if prediction == 1 else \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bf7a42c-001d-4089-9169-96e587fbd9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: last summer had an appointment to get new tires and had to wait super long time also went in this week for them to fix minor problem with tire they put on they fixed it for free and the very next morning had the same issue called to complain and the manager didn even apologize so frustrated never going back they seem overpriced too\n",
      "Actual prediction:0\n",
      "Example prediction : 0\n"
     ]
    }
   ],
   "source": [
    " # Example usage for a single test sample\n",
    "example_text = df_test['text'].iloc[1]\n",
    "example_target = df_test['target'].iloc[1]\n",
    "prediction = predict_single_sample(example_text)\n",
    "print(f\"Input text: {example_text}\")\n",
    "print(f\"Actual prediction:{example_target}\")\n",
    "print(f\"Example prediction : {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486f82c-a1b1-4c19-83d1-bc95710a4af7",
   "metadata": {},
   "source": [
    "## **RoBERTa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd51ff36-2494-45e6-881d-93ebc3692d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88777744fad4615a6f3f28da6c69139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047bb398adeb434a961ee5c2904df87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d49c870a097476f8ae65826cc1d653a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "# Function to tokenize the dataset using the provided tokenizer\n",
    "def tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "# Tokenizer for RoBERTa\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenize using RoBERTa tokenizer\n",
    "tokenized_train_dataset_roberta = train_dataset.map(lambda x: tokenize(x, roberta_tokenizer), batched=True)\n",
    "tokenized_val_dataset_roberta = val_dataset.map(lambda x: tokenize(x, roberta_tokenizer), batched=True)\n",
    "tokenized_test_dataset_roberta = test_dataset.map(lambda x: tokenize(x, roberta_tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e6cfde7-d753-4ffb-92e7-7e40d7ea280d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/shrishask/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33600' max='33600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33600/33600 1:37:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.292165</td>\n",
       "      <td>0.894460</td>\n",
       "      <td>0.897369</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.911858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.330296</td>\n",
       "      <td>0.896022</td>\n",
       "      <td>0.899556</td>\n",
       "      <td>0.879862</td>\n",
       "      <td>0.920152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.331033</td>\n",
       "      <td>0.899415</td>\n",
       "      <td>0.901826</td>\n",
       "      <td>0.890917</td>\n",
       "      <td>0.913005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 05:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa Results: {'eval_loss': 0.31900325417518616, 'eval_accuracy': 0.9038947368421053, 'eval_f1': 0.9053346466898232, 'eval_precision': 0.8919705792215752, 'eval_recall': 0.9191052631578948, 'eval_runtime': 303.3237, 'eval_samples_per_second': 125.279, 'eval_steps_per_second': 7.83, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Data collator for RoBERTa\n",
    "data_collator_roberta = DataCollatorWithPadding(tokenizer=roberta_tokenizer)\n",
    "\n",
    "# Model for RoBERTa\n",
    "roberta_model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "# Training arguments for RoBERTa\n",
    "roberta_training_args = TrainingArguments(\n",
    "    output_dir='/data/nmamit-interns/grp3/new/result/roberta',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type='linear'\n",
    ")\n",
    "\n",
    "# Trainer for RoBERTa\n",
    "roberta_trainer = Trainer(\n",
    "    model=roberta_model,\n",
    "    args=roberta_training_args,\n",
    "    train_dataset=tokenized_train_dataset_roberta,\n",
    "    eval_dataset=tokenized_val_dataset_roberta,\n",
    "    data_collator=data_collator_roberta,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train RoBERTa\n",
    "roberta_trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "# Evaluate RoBERTa\n",
    "roberta_results = roberta_trainer.evaluate(tokenized_test_dataset_roberta)\n",
    "print(\"RoBERTa Results:\", roberta_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79265c19-24de-4854-8c62-b873dd116881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/data/nmamit-interns/grp3/new/roberta_tokenizer/tokenizer_config.json',\n",
       " '/data/nmamit-interns/grp3/new/roberta_tokenizer/special_tokens_map.json',\n",
       " '/data/nmamit-interns/grp3/new/roberta_tokenizer/vocab.json',\n",
       " '/data/nmamit-interns/grp3/new/roberta_tokenizer/merges.txt',\n",
       " '/data/nmamit-interns/grp3/new/roberta_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saved reberta model \n",
    "roberta_model.save_pretrained('/data/nmamit-interns/grp3/new/roberta_model')\n",
    "roberta_tokenizer.save_pretrained('/data/nmamit-interns/grp3/new/roberta_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd9f205d-5c7f-454d-ae82-841d9df8a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "# Load the BERT model\n",
    "loaded_roberta_model =  RobertaForSequenceClassification.from_pretrained('/data/nmamit-interns/grp3/new/roberta_model')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "loaded_roberta_tokenizer = RobertaTokenizer.from_pretrained('/data/nmamit-interns/grp3/new/roberta_tokenizer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddef94e-f6a4-41b1-b508-553c154846db",
   "metadata": {},
   "source": [
    "#### *CONFUSION MATRIX / CLASSIFICATION REPORT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5638a318-ac7e-4ee7-8728-a82849140aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[17802  1198]\n",
      " [ 1509 17491]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     19000\n",
      "           1       0.94      0.92      0.93     19000\n",
      "\n",
      "    accuracy                           0.93     38000\n",
      "   macro avg       0.93      0.93      0.93     38000\n",
      "weighted avg       0.93      0.93      0.93     38000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    " \n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the BERT model\n",
    "loaded_roberta_model =  RobertaForSequenceClassification.from_pretrained('/data/nmamit-interns/grp3/new/roberta_model')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "loaded_roberta_tokenizer = RobertaTokenizer.from_pretrained('/data/nmamit-interns/grp3/new/roberta_tokenizer')\n",
    "\n",
    "# Load your test data\n",
    "test_texts = df_test['text'].tolist()  \n",
    "test_labels = df_test['target'].tolist()  \n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "loaded_roberta_model.to(device)\n",
    "\n",
    "# Function to get predictions in batches\n",
    "def get_predictions_in_batches(model, tokenizer, texts, batch_size=32):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_logits = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        encodings = tokenizer(batch_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "        encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        all_logits.extend(logits.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_logits)\n",
    "\n",
    "# Get predictions\n",
    "predictions, logits = get_predictions_in_batches(loaded_roberta_model, loaded_roberta_tokenizer, test_texts)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf268d-e2f9-4257-a0d8-fcf845908772",
   "metadata": {},
   "source": [
    "### *ROC and AUC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01ffcb9b-1818-4474-8b8a-499a9dbb27dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABEZElEQVR4nO3dd3gVZfbA8e9JDxBCCaB0kA5SNBRFFCmCiO1nwbK4uLoSEGyouNiwiwUsNBFdXBu7NlAQUVSKiiBIryIiBOklEEjP+f0xk3AJ4eYScnNzk/N5nvtMe2fm3EnunJl3Zt4RVcUYY4w5mZBAB2CMMaZks0RhjDHGK0sUxhhjvLJEYYwxxitLFMYYY7yyRGGMMcYrSxTmlIjIGhHpGug4SgoRGSEikwO07iki8nQg1l3URORmEfm6kPPa/6SfWaIIYiKyRURSRCRZRHa6O44K/lynqrZU1bn+XEcOEYkUkedEZKv7PX8TkQdERIpj/fnE01VEEj3Hqeqzqnq7n9YnInKXiKwWkSMikigiH4nI2f5YX2GJyEgRee90lqGq76vqJT6s64TkWJz/k2WVJYrgd7mqVgDaAu2AfwU2nFMnImEnmfQR0B3oA8QA/YE7gFf9EIOISEn7PbwK3A3cBVQBmgDTgMuKekVe/gZ+F8h1Gx+pqn2C9ANsAXp4DL8AzPQY7gT8BBwEVgBdPaZVAf4N/AUcAKZ5TOsLLHfn+wlonXedQE0gBajiMa0dsBcId4f/Aaxzlz8bqOdRVoE7gd+AP/L5bt2BVKBOnvEdgSygkTs8F3gOWAwkAdPzxORtG8wFngF+dL9LI+BWN+bDwGZgoFu2vFsmG0h2PzWBkcB7bpn67vf6O7DV3RYPe6wvGnjH3R7rgAeBxJP8bRu737ODl7//FGAcMNONdxFwlsf0V4FtwCFgKdDFY9pI4GPgPXf67UAHYKG7rXYAY4EIj3laAt8A+4FdwAigN5AOZLjbZIVbNhZ4y13OduBpINSdNsDd5mPcZT3tjvvBnS7utN3u33Ql0ArnICHDXV8y8EXe3wEQ6sb1u7tNlpLnf8g+hdjXBDoA+5zGH+/4H0htYBXwqjtcC9iHczQeAvR0h6u502cC/wUqA+HARe74c9wfaEf3R/d3dz2R+azzO+CfHvG8CEx0+68CNgHNgTDgEeAnj7Lq7nSqANH5fLfngXkn+d5/cmwHPtfdEbXC2Zl/wrEdd0HbYC7ODr2lG2M4ztH6We7O6iLgKHCOW74reXbs5J8o3sRJCm2ANKC553dyt3ltnB3gyRJFAvBnAX//KTg72g5u/O8DUz2m/w2o6k4bBuwEojziznD/TiFuvOfiJNYw97usA+5xy8fg7PSHAVHucMe828Bj3dOAN9y/SXWcRJ7zNxsAZAJD3XVFc3yi6IWzg6/k/h2aA2d6fOenvfwOHsD5HTR1520DVA30bzXYPwEPwD6n8cdzfiDJOEdOCnwLVHKnDQfezVN+Ns6O/0ycI+PK+SxzAvBUnnEbOJZIPH+UtwPfuf2Cc/R6oTs8C7jNYxkhODvdeu6wAt28fLfJnju9PNN+xj1Sx9nZP+8xrQXOEWeot23gMe+TBWzjacDdbn9XfEsUtT2mLwZucPs3A708pt2ed3ke0x4Gfi4gtinAZI/hPsB6L+UPAG084p5fwPLvAT5z+28Elp2kXO42cIdr4CTIaI9xNwLfu/0DgK15ljGAY4miG7ARJ2mF5POdvSWKDcCVp/vbss/xn5JWJ2tO3VWqGoOzE2sGxLnj6wHXicjBnA9wAU6SqAPsV9UD+SyvHjAsz3x1cKpZ8voYOE9EagIX4uwkF3gs51WPZezHSSa1PObf5uV77XVjzc+Z7vT8lvMnzplBHN63Qb4xiMilIvKziOx3y/fh2Db11U6P/qNAzg0GNfOsz9v338fJv78v60JEhonIOhFJcr9LLMd/l7zfvYmIzHBvjDgEPOtRvg5OdY4v6uH8DXZ4bPc3cM4s8l23J1X9DqfaaxywS0QmiUhFH9d9KnEaH1miKCVUdR7O0dZL7qhtOEfTlTw+5VX1eXdaFRGplM+itgHP5JmvnKp+mM86DwJfA9cDNwEfqntY5y5nYJ7lRKvqT56L8PKV5gAdRaSO50gR6YCzM/jOY7Rnmbo4VSp7C9gGJ8QgIpE4VVcvATVUtRLwJU6CKyheX+zAqXLKL+68vgVqi0h8YVYkIl1wzqiuxzlzrIRT3+95x1je7zMBWA80VtWKOHX9OeW34VTJ5SfvcrbhnFHEeWz3iqra0ss8xy9Q9TVVPRenWrAJTpVSgfMVEKcpJEsUpcsrQE8RaYtzkfJyEeklIqEiEuXe3llbVXfgVA2NF5HKIhIuIhe6y3gTSBCRju6dQOVF5DIRiTnJOj8AbgGucftzTAT+JSItAUQkVkSu8/WLqOocnJ3lJyLS0v0OnXDq4Seo6m8exf8mIi1EpBzwJPCxqmZ52wYnWW0EEAnsATJF5FLA85bNXUBVEYn19Xvk8T+cbVJZRGoBQ05W0P1+44EP3Zgj3PhvEJGHfFhXDM51gD1AmIg8BhR0VB6Dc2E7WUSaAYM8ps0AzhCRe9zblmNEpKM7bRdQP+euMff/62vgZRGpKCIhInKWiFzkQ9yISHv3/y8cOIJzU0OWx7oaepl9MvCUiDR2/39bi0hVX9ZrTs4SRSmiqnuA/wCPquo24Eqco8I9OEdaD3Dsb94f58h7Pc7F63vcZSwB/olz6n8A54L0AC+r/RznDp1dqrrCI5bPgFHAVLcaYzVw6Sl+pWuA74GvcK7FvIdzJ83QPOXexTmb2olzofUuN4aCtsFxVPWwO+//cL77Te73y5m+HvgQ2OxWqeRXHefNk0Ai8AfOGdPHOEfeJ3MXx6pgDuJUqVwNfOHDumbjHAxsxKmOS8V7VRfA/Tjf+TDOAcN/cya426YncDnOdv4NuNid/JHb3Sciv7r9t+Ak3rU42/JjfKtKAyehvenO9ydONVzOmfJbQAt3+0/LZ97ROH+/r3GS3ls4F8vNaZBjNQXGBB8RmYtzITUgT0efDhEZhHOh26cjbWMCxc4ojCkmInKmiHR2q2Ka4txq+lmg4zKmIPZEpDHFJwLn7p8GOFVJU3GuQxhTolnVkzHGGK+s6skYY4xXQVf1FBcXp/Xr1w90GMYYE1SWLl26V1WrFWbeoEsU9evXZ8mSJYEOwxhjgoqI/FnYea3qyRhjjFeWKIwxxnhlicIYY4xXliiMMcZ4ZYnCGGOMV5YojDHGeOW3RCEib4vIbhFZfZLpIiKvicgmEVkpIuf4KxZjjDGF58/nKKbgNJH8n5NMvxSneerGOO9nnuB2jTH+oAqa7Xzw6NdsyM50x+U06ZPTn/Ph2HC+ZTi18idbBgrZWW48HBuXX/8JzQ8V9bQ85bxNK4plnGyat3h9XEZ6ejanw2+JQlXni0h9L0WuBP7jvhHtZxGpJCJnui89MaZwVJ2dTHaG88lMhaz0Y8PZGZCVAemHQELccW75rHQ4ugsiYpxxWRmgbvfgJih/xvHL2LsSKtY/foer2aBZJ44j29kB7v4V4lo5/bll3X7PcdkZsHsZVG3psbwst4zHcFYGpO5zYs5JBOSsN09iMGXSqws6MnnR6VXYBPLJ7Foc/yKVRHfcCYlCRO4A7gCoW7dusQRnioDqsZ11xhFn53x0j7uzTYfMNDi8DcLLQ1YqJG93dtAhYc60rDTIPAqZKc4ydix0dsx//eR0PXf+qfm9/ruEOnQKD8juW+NbufTDvpWTEECcbs4HcbZzeAVn20vO20/FLesxLF7G5TdcUPncfo9hCYGQiDxxe77BVXybJnnK+TqtKJZRmHi9Tiv8MtokV2TtF9U5HYFMFHm3MpzksEdVJwGTAOLj4+3QyJ8y0+DoTkhLcna+6Ych7aCzo89Khf0bILKSs9Pft9bZuexfC+XOcI66M444O/6ju3D+xEX850r+y+ke2nLyMhIKoeEQ4n5S9zuJJTQcJMzpZmVAyh7n6D5nXEi4k6iO7oaqzY/NHxLmLDM5Eaq2OH78kV1QuZG7w/XY+UoIhISeOE5CnG0aHXdsekios3wJOdYNCT32XcKijp+eX/nQCI8df8ixHe5xiSG/n5wpbbZtS2LGjI0MGtQegK7XwKZbDtCw4ROFXmYgE0Uix79cvjbwV4BiKZ1yqiWO7HSOYjNTIGWvkwR2L3N2ulGVnYSQnOiUy84o3LoO/n6sPyPZ7VFnhxoWBWHREFHRSSwHNkKtCyA0EsIi4eBmOCMeQqOcBBQd53xCIyG8HISVc8tGAQIxddxp5Y9PCCHhzvLEbuYzZU9mZjavvbaIxx77niNHMmjVqjpdutQDoEGDyqe17EAmis+BISIyFecidpJdn/BRdiYc2uoc0R/Z6dR7h4Q7O/vkv2DHz86ONmUfp3xEHxJ2bEcdEQuR7s49spKzsw+LctZZrbWzs5YQqFDLmRZV2akyiI6DiApuVUaoP7aAMcbDokWJDBw4gxUrdgFwzTXNadjw9JKDJ78lChH5EOgKxIlIIvA4EA6gqhOBL4E+wCbgKHCrv2IJKtmZsH+9c4R+ONGpYjn0pzPuwAaIrOxW6xQgZa/TjariXgNIh+iqUKuLs0MPr+Csq2JdqNQIKtSE8jXdag6rojAmGBw4kMKIEd/yxhtLUYX69SsxduylXHZZkyJdjz/verqxgOkK3Omv9Zdo2VlOldChrbBnJWz4r3MHy+GtcOA37/PmJImQcOcunAo1oYZTF8mZHZ1qmeg4iIx1umFR/v0uxpiAeeKJeUycuJSwsBDuv/88Hn30IsqVCy/y9QTd+yiCTuoBJxnsXeVcCN65GPascO7oOZkKtZ2Lk3Uuhtj6zoXYmNrO2US5ak43PLq4voExpgTJzMwmLMy5DvfIIxfyxx8HeeaZbrRqdXp3NnljiaIoZWfC7uXONYJN0yFps/PJT1QV52g/IhZa/M2p9qlxjlMNFF6uWMM2xpR8qamZjBr1A9OmbWDRotuJiAglLq4c06ff4Pd1W6I4HZmpztnB5pmwbS5sX3BimZyqn6Y3QJVmzu2YNTtDVKViDNQYE8y+/XYzgwbN5Lff9gMwe/YmLr+8abGt3xLFqdr1K6x9F/76EXb+kn+Zpv2g5nlQrY1zG2iIbWZjzKnbtSuZYcO+5v33VwHQvHkcEyZcxkUX1S/WOGwP5ovDibD637ByknMLqqeYus51g/j74YwOENvA7hoyxpy2995bydChszh4MJWoqDAee+xChg07n4iI4r/l3BKFN9t/hJ+fhj+/ce5KAufaQuP/gybXwhkdrQrJGOMX2dnKwYOp9O7diHHj+hTpcxGnyhJFXqrwxyz4bqjHhWiBhpdBu7ugbjerSjLGFLnk5HQWLtxGz55nAdC/f2tq1oyhe/cGSIBrKWyPl0OzYc1/YMlLxzfE1v5BOPc+KF8jcLEZY0q1adPWM3ToLPbsOcLq1YNp1KgKIkKPHg0DHRpgicKR9AfM+vuxu5aiq0HrOyB+mPMUszHG+MGffx7krru+4vPPNwAQH1+TtLTMAuYqfmU7UWg2LB4FPz3uNIYnIdB1DJz9T3ugzRjjNxkZWbzyys+MHDmPo0cziImJ4NlnuzNoUDyhoSWvUcuymyjSk2HG9c71CIDmN8MFz0HFOt7nM8aY03TXXbOYOHEpANdf35IxY3pRs2ZMgKM6ubKbKL4b6iSJiIrQ5304q2+gIzLGlBH33NOJefP+ZPToXvTu3SjQ4RSo7CUKVZh7L6yZAgj835dQq3OgozLGlFKqynvvreTLLzfxwQf/h4jQtGkcq1cPJiQkOJ65KluJQhVm3wpr3nGGe4y3JGGM8ZsNG/YyaNBMvv9+C+Dc8tqnT2OAoEkSUNYSxcInnSQRGgG934Fm/m9MyxhT9qSkZPDccz8watSPpKdnUbVqNC+/fAmXXlryq5nyU3YSxbKxsHCk03/+k5YkjDF+MWfOZhISZvD77wcAuO22dowa1YOqVYO3VeiykSj+/Na5eA3Q4V/QYXhg4zHGlFo//bSN338/QMuW1Zg4sS8XXFA30CGdttKfKDJTYc5Ap79NAnR5NrDxGGNKlaysbDZt2k/TpnEADB/embi4ctx++zkBacDPH0rekx1Fbe69zvunY+o6D9MZY0wRWbZsB+ef/zYXXPBv9u9PASAyMozBg9uXmiQBpT1R/DkHVkx0+nuMt/dHG2OKxOHDadx771fEx7/J4sXbiYwM5fff9wc6LL8pvVVPmg0zb3L6m93ktP5qjDGnQVX59NN13H33V2zffpiQEOHeezvxxBNdiYmJDHR4flN6E8X84ZCyx2kSvMeEQEdjjCkF7rnnK157bTEA7dvX5I03+tKu3ZkBjsr/SmfVU/JfTnPhAN1eh8iKgY3HGFMqXH11c2JjIxk3rg8LF95WJpIElMYzClX4+nanv/ZFzp1OxhhTCD/8sJXvv/+DRx+9CICuXeuzdeu9VKxYequZ8lP6EsXmGU5jf6ERcPErgY7GGBOE9u07yvDhc3jrrWUAdO/ekPPPd1qWLmtJAkpjoljq3gLb6TGo3jagoRhjgouq8p//rOD++79h796jhIeH8NBDF9Cu3RmBDi2gSleiOPg7bPseQsKh9cBAR2OMCSLr1u1h0KCZzJv3JwAXX1yf8eMvo1mzuABHFnilK1EseMjpNuwL5eyPa4zx3ejRC5k370+qVSvH6NG9uPnmsxEJnhZe/al0JYrNM5xuvR6BjcMYExSSklKJjXUexH3uuR6ULx/BY49dRJUq9ipkT6Xn9th96512nQCa9gtsLMaYEu2vvw7Tr9/HdOr0FunpWQDExZXjlVd6W5LIR+lJFIvdxv7qdofoqoGNxRhTImVlZfP664to1mws//vfGrZuTeLXX3cEOqwSr/RUPaU6bb9TtWVg4zDGlEhLl/7FwIEzWLrUSQxXXNGU11+/lLp1YwMcWcnn1zMKEektIhtEZJOIPJTP9FgR+UJEVojIGhG5tVArSj147PqEvWvCGJPHyJFz6dBhMkuX7qBOnYpMm9aP6dNvsCThI7+dUYhIKDAO6AkkAr+IyOequtaj2J3AWlW9XESqARtE5H1VTT+llf0xy+lWqAUVahZF+MaYUqRhw8qIwLBh5zFyZFcqVIgIdEhBxZ9VTx2ATaq6GUBEpgJXAp6JQoEYce5BqwDsBzJPeU3bvne6Z3Y8rYCNMaXD5s0H+OWX7fTr1wqA/v1b07FjrdyXC5lT489EUQvY5jGcCOTdk48FPgf+AmKAfqqanXdBInIHcAdA3br5vFZwy1dOt/ZFpx20MSZ4padn8dJLP/HUU/NRVc49tyaNGlVBRCxJnAZ/XqPI70kVzTPcC1gO1ATaAmNF5ISmXlV1kqrGq2p8tWrVjp+Ysh8Ob3NW1/LvRRC2MSYYzZ//J23bTuThh78jNTWTa69tUSbbZfIHf55RJAJ1PIZr45w5eLoVeF5VFdgkIn8AzYDFPq9l02dOt2JdiLQLU8aUNXv3HuWBB75hypTlADRuXIUJEy6je/eGgQ2sFPFnovgFaCwiDYDtwA3ATXnKbAW6AwtEpAbQFNh8Smv5aaTTbXfXaQVrjAlOCQkz+OSTdURGhjJiRBcefLAzUVGl587/ksBvW1NVM0VkCDAbCAXeVtU1IpLgTp8IPAVMEZFVOFVVw1V17ymtKDnR6dbpWmSxG2NKtuxsJSTEqd1+5plupKRk8sorvWjc2B629Qdxan2CR3x8vC5ZssQZSD0A46o4/fdlgZSeB82NMSc6ejSDp56ax/Llu/jyy5us0b5TICJLVTW+MPMG9/nZrl+dbki4JQljSrmZMzcyZMgstmw5iAgsXrydjh1rBzqsMiG4E8X2H5xuhVqBjcMY4zeJiYe4++6v+PTTdQC0aVODiRP7WpIoRsGdKFLcyxn1egY2DmOMX4wf/wvDh88hOTmd8uXDeeqpixk6tCNhYVaDUJyCO1HsdO+ibXJNYOMwxvjF3r1HSU5O5+qrm/Hqq72pU8dugQ+E0pEoqrUNaBjGmKJx8GAq69fvpVMnp1pp+PDOdOhQi969GwU4srIteM/f0pKO9ZerHrg4jDGnTVWZOnU1zZuP44orPmT//hQAIiPDLEmUAMGbKA5uOtZvt8gZE7Q2bdpP797vc+ONn7BzZzKNG1clKSk10GEZD8Fb9ZS0xelGV/NazBhTMqWlZfLCCz/yzDMLSEvLonLlKF54oSf/+Ee73IfpTMngc6IQkfKqesSfwZySnDue4loFNg5jTKH06/cx06dvAOCWW9rw4os9qV69fICjMvkpsOpJRM4XkbXAOne4jYiM93tkBdmz0ulWrBfYOIwxhXLPPZ1o1iyO7767hXfeucqSRAnmyzWKMTjNge8DUNUVwIX+DMonmuV0I05oldwYU8JkZyuTJ//KsGGzc8d17Vqf1asHcfHFDQIYmfGFT1VPqrotT5sqWf4J5xT8+Y3TrR34nGWMOblVq3aRkDCTn35y3mN2yy1taNPmDABCQ4P3fpqyxJdEsU1EzgdURCKAu3CroQIqI9npRlUJbBzGmHwdOZLOE0/MY/TohWRlKWecUYFXXulF69Y1Ah2aOUW+JIoE4FWcV5smAl8Dg/0ZlE/SDztda+fJmBLniy82MGTILLZuTUIE7ryzPc88043Y2KhAh2YKwZdE0VRVb/YcISKdgR/9E5IPsjMhK83pj7GGwYwpaaZNW8/WrUm0a3cGb7zRl/bt7YAumPmSKF4HzvFhXPFJ/gs0G6KqQni5gIVhjHFkZmazffsh6tWrBMCoUT1p1+5MEhLirQG/UuCkiUJEzgPOB6qJyH0ekyrivLEucPY7916Tuj+gYRhj4OefE0lImEFaWhYrViQQERFKXFw5hgzpEOjQTBHxluojgAo4ySTG43MIuNb/oXmRdsDpVmsd0DCMKcsOHEhh0KAZnH/+W6xYsYvU1Ey2bDkY6LCMH5z0jEJV5wHzRGSKqv5ZjDEVbNs8p1uzc2DjMKYMUlU+/HA19947m927jxAWFsIDD5zPI49cSLly4YEOz/iBL9cojorIi0BLIPeWBVXt5reoCrJnudONqBCwEIwpq26++VM+/HA1AF261GXChMto2dJacC7NfLnK9D6wHmgAPAFsAX7xY0wFy7lGYe+hMKbY9e7diKpVo3n77SuYO3eAJYkywJcziqqq+paI3O1RHTXP34F5l+10zuwY2DCMKQPmzNnM77/vZ+DAeAD6929N375NqFIlOsCRmeLiS6LIcLs7ROQy4C8ggA8vKKS6F7NjrY0YY/xl165k7rvvaz74YBWRkaH06NGQs86qgohYkihjfEkUT4tILDAM5/mJisA9/gzKq+xMpxtVxV5YZIwfZGcrkyYt5aGH5pCUlEZUVBiPPXahva+6DCswUajqDLc3CbgYcp/MDoycRGEvLDKmyK1YsZOBA2ewaNF2AC69tBFjx/ahYcPKAY7MBJK3B+5Cgetx2nj6SlVXi0hfYAQQDbQrnhDzyHZrwsIiA7J6Y0qzBx+cw6JF26lZM4ZXX+3NNdc0R+zMvczzdkbxFlAHWAy8JiJ/AucBD6nqtGKILX/qdiPsNNiY06WqHD2aQfnyEQC89lpvJk5cwhNPXEzFinYwZhzeEkU80FpVs0UkCtgLNFLVncUT2sm4dzxFVgpoFMYEuz//PMjQobM4ciSDOXP6IyI0bRrHmDG9Ax2aKWG8JYp0Vc0GUNVUEdkY+CQBZKU73TBrrtiYwsjIyGLMmJ954ol5HD2aQUxMBL/9tp8mTaoGOjRTQnlLFM1ExH0xNQKc5Q4LoKoamIaWcupLk7cHZPXGBLMff9xKQsJMVq/eDUC/fi0ZPboXNWvGBDgyU5J5SxTNiy2KU5GR4nTPaB/YOIwJMkOHfsnYsU6jCg0bVmbcuD707t0owFGZYOCtUcCS1RBgjhC31ZG0gwENw5hgU61aecLDQxg+vDMjRnQhOtoa8DO+8esbRUSkt4hsEJFNIvLQScp0FZHlIrLGp6ZB1L3tqXpg7s41JlisX7+Xr7/+PXd4+PDOrFw5iKee6mZJwpwSX57MLhT3OYxxQE+cd23/IiKfq+pajzKVgPFAb1XdKiIFty6W88BdmL3Zzpj8pKRk8OyzCxg16kcqVYpi/fohVKkSTWRkGM2axQU6PBOEfEoUIhIN1FXVDaew7A7AJlXd7C5jKnAlsNajzE3Ap6q6FUBVdxe4VM1yutF2h4YxeX399e8MHjyT33932kO74oqm1tKNOW0FVj2JyOXAcuArd7itiHzuw7JrAds8hhPdcZ6aAJVFZK6ILBWRWwpcamaq0w0v70MIxpQNO3Yc5oYbPqZXr/f4/fcDtGxZjQULbmXy5CuoXNka8DOnx5czipE4ZwdzAVR1uYjU92G+/I5jNM9wGHAu0B2nWZCFIvKzqm48bkEidwB3ALStnROyHSYZk+P//u9//PxzItHRYYwc2ZV77+1EeHhgX21vSg9fLmZnqmpSIZadiNMESI7aOE2U5y3zlaoeUdW9wHygTd4FqeokVY1X1fjQMPciXDl7WYop21SPHXc9/3x3+vZtwtq1d/Lgg50tSZgi5UuiWC0iNwGhItJYRF4HfvJhvl+AxiLSQEQigBuAvFVW04EuIhImIuWAjsA6r0vNaRTQqp5MGXX4cBr33vsVAwfOyB130UX1+eKLG6lfv1LgAjOlli+JYijO+7LTgA9wmhu/p6CZVDUTGALMxtn5/09V14hIgogkuGXW4Vz7WInT+OBkVV1dwIKdriUKU8aoKp98spbmzcfxyiuL+Pe/l7Nly8FAh2XKAPE8fc23gEg7VV1WTPEUKL5OiC65R+HuFGvvyZQZf/xxgCFDZvHll78B0KFDLSZOvIx27c4McGQmWIjIUlWNL8y8vlzMHi0iZwIfAVNVdU1hVlR0FCQUQq0JZFP6qSovvPAjTzwxj5SUTGJjI3nuue7ccce5hIb69XlZY3L58oa7i0XkDJyXGE0SkYrAf1X1ab9HdzIRFew1qKZMEBE2btxHSkomN97YitGje3HGGRUCHZYpYwqsejqusMjZwINAP1WN8FtUXsTXEV3yr2owuOBn84wJRnv3HmXnzmRataqeO7xs2Q569jwrwJGZYHY6VU++PHDXXERGishqYCzOHU+1C7OyIhPit5ZHjAkYVWXKlOU0azaW6677iPR0pxWCuLhyliRMQPmyx/038CFwiarmfQ4iMCxRmFJm3bo9JCTMZP58p9HmNm3O4MCBFGrUsGomE3i+XKPoVByBnBJLFKaUOHo0g2eemc+LL/5ERkY21aqVY/ToXtx889mIXYczJcRJ97gi8j9VvV5EVnF80xuBfcMdOHc9GRPkVJVu3d5h0SLnbY0DB57Lc891t7aZTInj7dD8brfbtzgCOSV2pGVKARFh8OD2HD2awRtv9OW88+oUPJMxAeDLA3ejVHV4QeOKS3wd0SX3AMN8v1vLmJIgKyub8eN/ISMjm/vuOw9wzioyM7OtbSbjd3696wnnxUN5XVqYlRUZe1+2CTJLlvxFx46Tueuurxgx4lv++usw4JxVWJIwJZ23axSDgMFAQxFZ6TEpBvjR34F5FWKvcTTBISkplUce+Y5x435BFerUqcjrr19KzZoxgQ7NGJ95u0bxATALeA7wfN/1YVXd79eoCmJ3PZkSTlX56KO13HPPV+zYkUxoqHDvvZ14/PGuVKgQkGdVjSk0b3tcVdUtInJn3gkiUiWgycIShQkCb7yxlB07kunUqTYTJ15GmzZnBDokYwqloDOKvsBSnNtjPW81UqChH+PyTixRmJInLS2TgwdTqVGjAiLC+PF9mDt3C//857mEhNideiZ4nXSPq6p93W6D4gvHR9ZyrClh5s3bQkLCTGrWjGHOnP6ICE2bxtG0aVygQzPmtPnS1lNnESnv9v9NREaLSF3/h+aFvYfClBB79hxhwIBpdO36DuvX72XbtiR27ToS6LCMKVK+3B47ATgqIm1wWo79E3jXr1EVxJ7MNgGWna289davNGs2jnfeWUFkZChPPNGVlSsHWTPgptTxpbI/U1VVRK4EXlXVt0Tk7/4OzKsQSxQmcFSVXr3eY86czQD06NGQ8eP70Lhx1QBHZox/+JIoDovIv4D+QBcRCQUC+yCDnVGYABIRunSpy6pVuxgzphc33NDKGvAzpZovVU/9gDTgH6q6E6gFvOjXqApiicIUs5kzNzJt2vrc4eHDO7N+/RBuvNFaeTWlny/NjO8UkfeB9iLSF1isqv/xf2heWNWTKSaJiYe4++6v+PTTdcTFlePCC+tRpUo0kZFhREbabdqmbPDlrqfrgcXAdTjvzV4kItf6OzDvQVmiMP6VmZnNmDELad58HJ9+uo7y5cMZMeICKla0W7NN2ePLIdHDQHtV3Q0gItWAOcDH/gzMK0sUxo8WL97OwIEzWL58JwBXX92MV1/tTZ06sQGOzJjA8CVRhOQkCdc+fLu24T/Z6QFdvSm9srOVW2+dztq1e6hbN5axYy/l8subBjosYwLKl0TxlYjMxnlvNjgXt7/0X0g+SDsU0NWb0kVVSUvLIioqjJAQYdy4Psya9RuPPXYR5ctbA37G+HIx+wER+T/gApz2niap6md+j8ybSmcFdPWm9Ni0aT+DB8+kTp2KvPXWlQB07Vqfrl3rBzYwY0oQb++jaAy8BJwFrALuV9XtxRWYV9Z6rDlNaWmZjBr1I88+u4C0tCyqVInmhReOUrVquUCHZkyJ4+1aw9vADOAanBZkXy+WiHxhicKchu+++4PWrSfy+ONzSUvL4u9/b8P69XdakjDmJLztcWNU9U23f4OI/FocAfnE7noyhZCVlc2tt07n3XedFzY2bVqViRP7WjWTMQXwliiiRKQdx95DEe05rKqBSxx2RmEKITQ0hLCwEKKiwnjkkS7cf//59tCcMT4QVc1/gsj3XuZTVe3mn5C8i68juuTTF6H9/YFYvQkyq1btIjU1k/btawGwb99RDh5M5ayzqgQ4MmOKl4gsVdX4wszr7cVFFxc+JD87siPQEZgS7siRdEaOnMuYMT/TuHFVVqxIICIilKpVy9m1CGNOUXCed8cG7i2spuT7/PMNDB06i61bkxCBHj0akJGRRUSEXdsypjD8+oS1iPQWkQ0isklEHvJSrr2IZPnchpQE9sFwUzJt3ZrEVVdN5corp7J1axLnnHMmixf/k9df72MPzhlzGvx2RuG+t2Ic0BNIBH4Rkc9VdW0+5UYBs09h4UUYqSkNsrKy6dp1Cn/8cZCYmAiefrobgwe3JyzMDiqMOV0FJgpxGtu/GWioqk+678s+Q1UXFzBrB2CTqm52lzMVuBJYm6fcUOAToL3PUdsZhXGpKiJCaGgII0d25YsvNvLKK72oVatioEMzptTwZY87HjgPuNEdPoxzplCQWsA2j+FEd1wuEakFXA1M9LYgEblDRJaIyBLfwzal2YEDKSQkzODZZxfkjuvfvzUffXSdJQljipgvVU8dVfUcEVkGoKoHRMSXCt/86ofy3ov7CjBcVbO8vSVMVScBk8C5PdaqnsouVeWDD1Zx331fs3v3EWJiIhgypAOxsVH2pjlj/MSXRJHhXkdQyH0fRbYP8yUCdTyGawN/5SkTD0x1f+BxQB8RyVTVaV6XbFVPZdLGjfsYPHgm3377BwBdutRlwoTLiI2NCnBkxpRuviSK14DPgOoi8gxwLfCID/P9AjQWkQbAduAG4CbPAqraIKdfRKYAMwpMEmCJoozJzMzm6afn89xzP5CenkXVqtG8+GJPBgxoa2cRxhQDX5oZf19ElgLdcaqTrlLVdT7MlykiQ3DuZgoF3lbVNSKS4E73el3CO9s5lCWhocKCBVtJT8/iH/9oy6hRPYmLs4fmjCkuJ23CI7eAc5fTCVR1q18iKkB8HdEls9+FFn8LxOpNMdm1K5nU1Ezq1asEwG+/7WPHjmQuvLBeYAMzJkj5pQkPDzNxrk8IEAU0ADYALQuzwiJhVU+lVna2MmnSUh56aA7x8TX55pv+iAiNG1elceOqgQ7PmDLJl6qnsz2HReQcYKDfIvKJVT2VRsuX7yQhYQaLFjnvx4qICCU5OZ2YmMgAR2ZM2XbKT2ar6q8i4vvDcf5gZxSlyuHDaTz++FxefXUR2dlKzZoxvPpqb665prldrDamBPDlyez7PAZDgHOAPX6LyBeWKEqN9PQszjlnEps27SckRLj77o48+eTFVKxoZxHGlBS+nFHEePRn4lyz+MQ/4fjIjjJLjYiIUPr3b80XX2xk4sTLOPfcmoEOyRiTh9dE4T5oV0FVHyimeHyTlhToCEwhZWRkMWbMz9StG8sNN7QC4KGHLuDhh7sQGmpnisaURCdNFCIS5j4LcU5xBuSTctUDHYEphB9/3EpCwkxWr95NtWrl6Nu3CRUqRNh7Iowp4bydUSzGuR6xXEQ+Bz4CjuRMVNVP/RybKSX2709h+PBvmDx5GQANG1Zm/Pg+VKhg74gwJhj4co2iCrAP6Max5ykUCGCisGsUwUBVeffdlQwb9jV79x4lPDyE4cM7M2JEF6KjwwMdnjHGR94SRXX3jqfVHEsQObw/zm0MkJGRzXPP/cDevUe56KJ6TJhwGc2bVwt0WMaYU+QtUYQCFfCtuXBjAEhJySA9PYvY2CgiIkKZNKkvmzcf4JZb2tgzEcYEKW+JYoeqPllskZwK2+GUSLNnb2Lw4C/p2rUeb711JQBdutSjSxdrn8mYYOYtUdje2Phkx47D3HvvbP773zUAlC8fztGjGZQrZ9chjCkNvN243r3YojBBKSsrm7FjF9Os2Tj++981REeHMWpUD5YuvcOShDGlyEnPKFR1f3EGcmrsZCfQUlMzufDCf/PLL85LC/v2bcLrr19K/fqVAhuYMabInXKjgMYAREWF0apVdXbsSOa113pz1VXN7GK1MaVUcCYK2yEVO1Xl00/XUaNGBS64wHmX1ejRvQgNFWsG3JhSLjgThSlWf/xxgCFDZvHll7/RrFkcy5cPJDIyjEqVogIdmjGmGFiiMCeVnp7Fyy//xFNPzSclJZPY2EjuvrsjYWHWeJ8xZUmQJgqrevK3BQv+JCFhJmvXOq8euemms3n55Us444wKAY7MGFPcgjRRGH9KScng2ms/YvfuIzRqVIXx4/vQs+dZgQ7LGBMgligM4FyszspSwsJCiI4OZ/ToS9i4cR//+lcXoqLs38SYsiw49wB211ORWrt2DwkJM+jZsyGPPnoRADff3DrAURljSgq7KlmGHT2awYgR39KmzUQWLNjK5MnLSEvLDHRYxpgSJjjPKOxi9mmbNes37rzzS/744yAAAweey3PPdScyMkj/JYwxfmN7hTLmyJF0BgyYzscfrwWgdesaTJx4GeedVyfAkRljSipLFGVMuXLh7N+fQvny4TzxRFfuvruTPRdhjPEqSBOFVT2diiVL/qJSpSgaNaqCiDB58uWEhoZQt25soEMzxgQBO5QsxZKSUhk69Es6dHiThIQZqDovJmzQoLIlCWOMz4L0jMJ4o6r8739ruOee2ezcmUxoqHDOOWeSmZlNeHhooMMzxgSZ4EwU9hzFSf3++37uvPNLZs/+HYDzzqvNxIl9ad26RoAjM8YEq+BMFCZfhw+nER//JgcPplKpUhSjRvXg9tvPISTEEqsxpvD8mihEpDfwKhAKTFbV5/NMvxkY7g4mA4NUdYUPSy7aQEuJmJhI7r23E5s27eelly6hevXygQ7JGFMK+C1RiEgoMA7oCSQCv4jI56q61qPYH8BFqnpARC4FJgEd/RVTabNnzxEeeOAbundvQP/+bQB49NEL7U1zxpgi5c+7njoAm1R1s6qmA1OBKz0LqOpPqnrAHfwZqO3HeEqN7Gxl8uRfadp0LO+8s4KHH/6OjIwsAEsSxpgi589EUQvY5jGc6I47mduAWflNEJE7RGSJiCxxRxRVjEFn9erdXHjhv/nnP7/gwIFUevRoyLff3mJ3Mxlj/Maf1yjy25trvgVFLsZJFBfkN11VJ+FUSxFfR/JdRmmXkpLByJFzGT36ZzIzs6lRozxjxvTihhta2VmEMcav/JkoEgHPBoRqA3/lLSQirYHJwKWqus+P8QS1kBDh8883kpWVzeDB8TzzTHd7Z7Uxplj4M1H8AjQWkQbAduAG4CbPAiJSF/gU6K+qG31fdNk4gk5MPES5cuFUqRJNZGQYU6Y4l3g6drRLOcaY4uO3axSqmgkMAWYD64D/qeoaEUkQkQS32GNAVWC8iCzPvQZRxmVmZjNmzEKaNx/HAw98nTu+Y8faliSMMcXOr89RqOqXwJd5xk306L8duP2UF1yK6+QXLUpk4MAZrFixC4CkpDQyM7OthVdjTMDYk9klxMGDqYwY8S0TJy5BFerVi2Xs2D707dsk0KEZY8o4SxQlwIEDKbRoMZ6dO5MJCwth2LDzePTRCylfPiLQoRljTLAmitJV9VS5cjSXXtqIjRv3MWHCZZx9tjXgZ4wpOYI0UQS3tLRMRo36kYsuqsdFF9UHYOzYPkRFhVkDfsaYEscSRTH77rs/GDRoJhs37qN58zhWrRpEaGgI5cqFBzo0Y4zJV3AmiiC862n37iMMG/Y17723EoBmzeIYP/4yQkPtbiZjTMkWnIkiiOQ04Dd8+BwOHkwlKiqMRx7pwgMPdCYiwtpnMsaUfEGaKILnjCIpKZWHH/6OgwdT6dXrLMaN68NZZ1UJdFjGGOOzIE0UJduRI+mEhYUQGRlG5crRTJx4GVlZynXXtbAG/IwxQccqyIvY559voEWL8bzwwo+54665pgXXX9/SkoQxJigFaaIoeTvcrVuTuOqqqVx55VS2bk1i9uzfyc4uky2iG2NKmSBNFCVHRkYWL730E82bj2P69A3ExETw6qu9mTdvgD0TYYwpFewaxWnYu/co3bv/h5UrnQb8rruuBWPG9KJWrYoBjswYY4pOcCaKElLXX7VqNHFx5WjQoBJjx/ahT5/GgQ7JlCAZGRkkJiaSmpoa6FBMGRIVFUXt2rUJDy+6h3iDM1EEiKry/vur6NChFk2aVEVEeO+9q4mNjbInq80JEhMTiYmJoX79+nYjgykWqsq+fftITEykQYMGRbbcIL1GUfw/ug0b9tKjx7v07/8ZgwfPRNW5UH3mmTGWJEy+UlNTqVq1qiUJU2xEhKpVqxb5WaydURQgNTWT555bwPPP/0h6ehZVq0bzt7+1DnRYJkhYkjDFzR//c5YovJgzZzODBs1k06b9APzjH2154YWeVK1aLsCRGWNM8QnOqqdiOErbtSuZvn0/YNOm/bRoUY358wfw1ltXWpIwQSU0NJS2bdvSqlUrLr/8cg4ePJg7bc2aNXTr1o0mTZrQuHFjnnrqqdwqVYBZs2YRHx9P8+bNadasGffff38AvoF3y5Yt4/bbT/1tysUlLS2Nfv360ahRIzp27MiWLVvyLfff//6X1q1b07JlSx588MHc8Vu3buXiiy+mXbt2tG7dmi+/dN4svWfPHnr37l0cX8GhqkH1Obc2qtt/Un/IysrW7Ozs3OFRo37Q555boGlpmX5Znynd1q5dG+gQtHz58rn9t9xyiz799NOqqnr06FFt2LChzp49W1VVjxw5or1799axY8eqquqqVau0YcOGum7dOlVVzcjI0HHjxhVpbBkZGae9jGuvvVaXL19erOs8FePGjdOBAweqquqHH36o119//Qll9u7dq3Xq1NHdu3erqvN3mjNnjqqq/vOf/9Tx48erquqaNWu0Xr16ufMNGDBAf/jhh3zXm9//HrBEC7nftaon1/LlO0lImMGdd7anf/82ADz4YOcAR2VKjZf9dBY8zPen/8877zxWrnSauf/ggw/o3Lkzl1xyCQDlypVj7NixdO3alTvvvJMXXniBhx9+mGbNmgEQFhbG4MGDT1hmcnIyQ4cOZcmSJYgIjz/+ONdccw0VKlQgOTkZgI8//pgZM2YwZcoUBgwYQJUqVVi2bBlt27bls88+Y/ny5VSqVAmARo0a8eOPPxISEkJCQgJbt24F4JVXXqFz5+N/j4cPH2blypW0aeP8XhcvXsw999xDSkoK0dHR/Pvf/6Zp06ZMmTKFmTNnkpqaypEjR/jiiy8YOnQoq1atIjMzk5EjR3LllVeyZcsW+vfvz5EjRwAYO3Ys559/vs/bNz/Tp09n5MiRAFx77bUMGTIEVT3uOsLmzZtp0qQJ1apVA6BHjx588skndO/eHRHh0KFDACQlJVGzZs3c+a666iref//9E7aLPwRpoii6H93hw2k8/vhcXn11EdnZSlpaFn/7W2u7CGlKlaysLL799ltuu+02wKl2Ovfcc48rc9ZZZ5GcnMyhQ4dYvXo1w4YNK3C5Tz31FLGxsaxatQqAAwcOFDjPxo0bmTNnDqGhoWRnZ/PZZ59x6623smjRIurXr0+NGjW46aabuPfee7ngggvYunUrvXr1Yt26dcctZ8mSJbRq1Sp3uFmzZsyfP5+wsDDmzJnDiBEj+OSTTwBYuHAhK1eupEqVKowYMYJu3brx9ttvc/DgQTp06ECPHj2oXr0633zzDVFRUfz222/ceOONLFmy5IT4u3TpwuHDh08Y/9JLL9GjR4/jxm3fvp06deoATrKNjY1l3759xMXF5ZZp1KgR69evZ8uWLdSuXZtp06aRnp4OwMiRI7nkkkt4/fXXOXLkCHPmzMmdLz4+nkceeaTA7V0UgjRRnD5VZdq09dx111ckJh4iJES4++6OPPnkxZYkTNE7hSP/opSSkkLbtm3ZsmUL5557Lj179gQ44ajW06n8/8+ZM4epU6fmDleuXLnAea677jpCQ513sfTr148nn3ySW2+9lalTp9KvX7/c5a5duzZ3nkOHDnH48GFiYmJyx+3YsSP3KBycI+6///3v/Pbbb4gIGRkZudN69uxJlSpO8/5ff/01n3/+OS+99BLg3Ma8detWatasyZAhQ1i+fDmhoaFs3Lgx3/gXLFhQ4HfMoXri3z3v9q1cuTITJkygX79+hISEcP7557N582YAPvzwQwYMGMCwYcNYuHAh/fv3Z/Xq1YSEhFC9enX++usvn2M5HcGZKE5zR75371FuvXU6M2Y4/wjx8TV5442+nHPOmUURnTElRnR0NMuXLycpKYm+ffsybtw47rrrLlq2bMn8+fOPK7t582YqVKhATEwMLVu2ZOnSpbnVOidzsoTjOS7vPf3ly5fP7T/vvPPYtGkTe/bsYdq0ablHyNnZ2SxcuJDo6Giv381z2Y8++igXX3wxn332GVu2bKFr1675rlNV+eSTT2jatOlxyxs5ciQ1atRgxYoVZGdnExUVle96T+WMonbt2mzbto3atWuTmZlJUlJSbsLydPnll3P55ZcDMGnSpNxE+tZbb/HVV1/lbqvU1FT27t1L9erVSU1N9bp9ilJw3vV0mmJiIti0aT8VK0Yyduyl/PzzbZYkTKkWGxvLa6+9xksvvURGRgY333wzP/zwQ25VRkpKCnfddVfuHTcPPPAAzz77bO5RdXZ2NqNHjz5huZdccgljx47NHc6peqpRowbr1q3LrVo6GRHh6quv5r777qN58+ZUrVo13+UuX778hHmbN2/Opk2bcoeTkpKoVasWAFOmTDnpOnv16sXrr7+ee7S/bNmy3PnPPPNMQkJCePfdd8nKysp3/gULFrB8+fITPnmTBMAVV1zBO++8AzjXarp165ZvYt29ezfgbL/x48fn3slVt25dvv32WwDWrVtHampq7lnUxo0bj6t686cykyh+/HEr+/YdBSAyMoypU69h/fo7ufPODvbealMmtGvXjjZt2jB16lSio6OZPn06Tz/9NE2bNuXss8+mffv2DBkyBIDWrVvzyiuvcOONN9K8eXNatWrFjh07TljmI488woEDB2jVqhVt2rTh+++/B+D555+nb9++dOvWjTPP9H4Q1q9fP957773caieA1157jSVLltC6dWtatGjBxIkTT5ivWbNmJCUl5R7dP/jgg/zrX/+ic+fOJ93Jg3PmkZGRQevWrWnVqhWPPvooAIMHD+add96hU6dObNy48bizkMK67bbb2LdvH40aNWL06NE8//zzudPatm2b23/33XfTokULOnfuzEMPPUSTJk0AePnll3nzzTdp06YNN954I1OmTMlNNN9//z2XXXbZacfoC8mvDq0ki68jumTxIjizg0/l9+07ykMPzWHy5GXcdls7Jk++ws8RGuNYt24dzZs3D3QYpdqYMWOIiYkp0c9S+MuFF17I9OnT870ulN//nogsVdX4wqyr1B5KqyrvvLOcZs3GMXnyMsLDQ6hZMybfi0vGmOA0aNAgIiMjAx1GsduzZw/33XefTzcPFIXgvJhdgPXr95KQMIN58/4EoGvX+kyYcBnNmsUVMKcxJphERUXRv3//QIdR7KpVq8ZVV11VbOsLzkTh5a6nxMRDtGkzkfT0LOLiyvHyy5fQv789F2ECw9ttqMb4gz9qTYIzUXhRu3ZF+vdvTUiI8PzzPahSpXhuHzMmr6ioKPbt22dNjZtio+77KE52a29hBWmiOPaj27HjMPfeO5uEhHi6dq0PwKRJl9v7qk3A1a5dm8TERPbs2RPoUEwZkvOGu6IUpIkCsrKymTBhCQ8//B2HDqWxadN+fvnln4iIJQlTIoSHhxfpW8aMCRS/3vUkIr1FZIOIbBKRh/KZLiLymjt9pYic48tyf12ZRKdObzF06CwOHUrj8sub8Mkn19vpvTHG+IHfzihEJBQYB/QEEoFfRORzVV3rUexSoLH76QhMcLsnte1gRdpf+gPZ2c71iNdfv5Qrr2xqScIYY/zEn2cUHYBNqrpZVdOBqcCVecpcCfzHbS79Z6CSiHh9jHP/0WhEhPvu68S6dXdy1VXNLEkYY4wf+fMaRS1gm8dwIieeLeRXphZwXFsBInIHcIc7mAaPrx49GvJpeqasiQP2BjqIEsK2xTG2LY6xbXFM04KL5M+fiSK/w/y8N/j6UgZVnQRMAhCRJYV9DL20sW1xjG2LY2xbHGPb4hgROfHlGj7yZ9VTIlDHY7g2kLfxdF/KGGOMCSB/JopfgMYi0kBEIoAbgM/zlPkcuMW9+6kTkKSqJzZRaYwxJmD8VvWkqpkiMgSYDYQCb6vqGhFJcKdPBL4E+gCbgKPArT4sepKfQg5Gti2OsW1xjG2LY2xbHFPobRF0zYwbY4wpXqW2mXFjjDFFwxKFMcYYr0psovBX8x/ByIdtcbO7DVaKyE8i0iYQcRaHgraFR7n2IpIlItcWZ3zFyZdtISJdRWS5iKwRkXnFHWNx8eE3EisiX4jICndb+HI9NOiIyNsisltEVp9keuH2m6pa4j44F79/BxoCEcAKoEWeMn2AWTjPYnQCFgU67gBui/OBym7/pWV5W3iU+w7nZolrAx13AP8vKgFrgbrucPVAxx3AbTECGOX2VwP2AxGBjt0P2+JC4Bxg9UmmF2q/WVLPKPzS/EeQKnBbqOpPqnrAHfwZ53mU0siX/wuAocAnwO7iDK6Y+bItbgI+VdWtAKpaWreHL9tCgRhx2vupgJMoMos3TP9T1fk43+1kCrXfLKmJ4mRNe5xqmdLgVL/nbThHDKVRgdtCRGoBVwMTizGuQPDl/6IJUFlE5orIUhG5pdiiK16+bIuxQHOcB3pXAXeranbxhFeiFGq/WVLfR1FkzX+UAj5/TxG5GCdRXODXiALHl23xCjBcVbNKeWORvmyLMOBcoDsQDSwUkZ9VdaO/gytmvmyLXsByoBtwFvCNiCxQ1UN+jq2kKdR+s6QmCmv+4xifvqeItAYmA5eq6r5iiq24+bIt4oGpbpKIA/qISKaqTiuWCIuPr7+Rvap6BDgiIvOBNkBpSxS+bItbgefVqajfJCJ/AM2AxcUTYolRqP1mSa16suY/jilwW4hIXeBToH8pPFr0VOC2UNUGqlpfVesDHwODS2GSAN9+I9OBLiISJiLlcFpvXlfMcRYHX7bFVpwzK0SkBk5LqpuLNcqSoVD7zRJ5RqH+a/4j6Pi4LR4DqgLj3SPpTC2FLWb6uC3KBF+2haquE5GvgJVANjBZVfO9bTKY+fh/8RQwRURW4VS/DFfVUtf8uIh8CHQF4kQkEXgcCIfT229aEx7GGGO8KqlVT8YYY0oISxTGGGO8skRhjDHGK0sUxhhjvLJEYYwxxitLFKZEclt+Xe7xqe+lbHIRrG+KiPzhrutXETmvEMuYLCIt3P4Reab9dLoxusvJ2S6r3dZQKxVQvq2I9CmKdZuyy26PNSWSiCSraoWiLutlGVOAGar6sYhcArykqq1PY3mnHVNByxWRd4CNqvqMl/IDgHhVHVLUsZiyw84oTFAQkQoi8q17tL9KRE5oNVZEzhSR+R5H3F3c8ZeIyEJ33o9EpKAd+HygkTvvfe6yVovIPe648iIy0323wWoR6eeOnysi8SLyPBDtxvG+Oy3Z7f7X8wjfPZO5RkRCReRFEflFnPcEDPRhsyzEbdBNRDqI8y6SZW63qfuU8pNAPzeWfm7sb7vrWZbfdjTmBIFuP90+9snvA2ThNOK2HPgMpxWBiu60OJwnS3POiJPd7jDgYbc/FIhxy84HyrvjhwOP5bO+KbjvrgCuAxbhNKi3CiiP0zT1GqAdcA3wpse8sW53Ls7Re25MHmVyYrwaeMftj8BpyTMauAN4xB0fCSwBGuQTZ7LH9/sI6O0OVwTC3P4ewCdu/wBgrMf8zwJ/c/sr4bT7VD7Qf2/7lOxPiWzCwxggRVXb5gyISDjwrIhciNMcRS2gBrDTY55fgLfdstNUdbmIXAS0AH50mzeJwDkSz8+LIvIIsAenFd7uwGfqNKqHiHwKdAG+Al4SkVE41VULTuF7zQJeE5FIoDcwX1VT3Oqu1nLsjXyxQGPgjzzzR4vIcqA+sBT4xqP8OyLSGKc10PCTrP8S4AoRud8djgLqUjrbgDJFxBKFCRY347yZ7FxVzRCRLTg7uVyqOt9NJJcB74rIi8AB4BtVvdGHdTygqh/nDIhIj/wKqepGETkXp82c50Tka1V90pcvoaqpIjIXp9nrfsCHOasDhqrq7AIWkaKqbUUkFpgB3Am8htOW0feqerV74X/uSeYX4BpV3eBLvMaAXaMwwSMW2O0miYuBenkLiEg9t8ybwFs4r4T8GegsIjnXHMqJSBMf1zkfuMqdpzxOtdECEakJHFXV94CX3PXkleGe2eRnKk5jbF1wGrLD7Q7KmUdEmrjrzJeqJgF3Afe788QC293JAzyKHsapgssxGxgq7umViLQ72TqMyWGJwgSL94F4EVmCc3axPp8yXYHlIrIM5zrCq6q6B2fH+aGIrMRJHM18WaGq/opz7WIxzjWLyaq6DDgbWOxWAT0MPJ3P7JOAlTkXs/P4GufdxnPUeXUnOO8SWQv8KiKrgTco4IzfjWUFTrPaL+Cc3fyIc/0ix/dAi5yL2ThnHuFubKvdYWO8sttjjTHGeGVnFMYYY7yyRGGMMcYrSxTGGGO8skRhjDHGK0sUxhhjvLJEYYwxxitLFMYYY7z6f5NX2ldrxNgnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate ROC curve and AUC\n",
    "if len(np.unique(test_labels)) == 2:\n",
    "    fpr, tpr, _ = roc_curve(test_labels, logits[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ROC curve is only applicable for binary classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b5e3a-2780-4d35-b951-e9ac8f51d463",
   "metadata": {},
   "source": [
    "### **PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24667468-8cda-4e60-9ec0-4a07131ffd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Function to predict a single sample\n",
    "def predict_single_sample(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load tokenizer and model (using the provided variable names)\n",
    "    tokenizer = loaded_roberta_tokenizer\n",
    "    model = loaded_roberta_model.to(device)\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to the same device as the model\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    prediction = torch.argmax(logits, dim=-1).item()\n",
    "    return \"1\" if prediction == 1 else \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f58d609-d3a9-4259-acf3-193ebd9aec0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: contrary to other reviews have zero complaints about the service or the prices have been getting tire service here for the past years now and compared to my experience with places like pep boys these guys are experienced and know what they re doing nalso this is one place that do not feel like am being taken advantage of just because of my gender other auto mechanics have been notorious for capitalizing on my ignorance of cars and have sucked my bank account dry but here my service and road coverage has all been well explained and let up to me to decide nand they just renovated the waiting room it looks lot better than it did in previous years\n",
      "Actual prediction:1\n",
      "Example prediction : 0\n"
     ]
    }
   ],
   "source": [
    " # Example usage for a single test sample\n",
    "example_text = df_test['text'].iloc[0]\n",
    "example_target = df_test['target'].iloc[0]\n",
    "prediction = predict_single_sample(example_text)\n",
    "print(f\"Input text: {example_text}\")\n",
    "print(f\"Actual prediction:{example_target}\")\n",
    "print(f\"Example prediction : {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9d4c088-d2fb-4c06-97a7-1fb041df356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False predictions saved to 'false_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Function to predict all samples from the test dataset and identify false predictions\n",
    "def get_false_predictions(df_test, model, tokenizer):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    false_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for index, row in df_test.iterrows():\n",
    "            text = row['text']\n",
    "            actual_label = row['target']\n",
    "            \n",
    "            # Tokenize the text\n",
    "            inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "            input_ids = inputs['input_ids'].to(device)\n",
    "            attention_mask = inputs['attention_mask'].to(device)\n",
    "            \n",
    "            # Make predictions\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predicted_label = torch.argmax(logits, dim=1).item()\n",
    "            \n",
    "            if predicted_label != actual_label:\n",
    "                decoded_text = tokenizer.decode(input_ids.squeeze().cpu(), skip_special_tokens=True)\n",
    "                false_predictions.append({\n",
    "                    'text': decoded_text,\n",
    "                    'predicted_label': predicted_label,\n",
    "                    'actual_label': actual_label\n",
    "                })\n",
    "    \n",
    "    return false_predictions\n",
    "\n",
    "# Get false predictions\n",
    "false_predictions = get_false_predictions(df_test, loaded_roberta_model, loaded_roberta_tokenizer)\n",
    "\n",
    "# Create a DataFrame and save to CSV\n",
    "false_predictions_df = pd.DataFrame(false_predictions)\n",
    "false_predictions_df.to_csv('/data/nmamit-interns/grp3/new/wrong_predictions.csv', index=False)\n",
    "\n",
    "print(\"False predictions saved to 'false_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2daf4-d717-418d-98ca-b045742a5af1",
   "metadata": {},
   "source": [
    "### **DistilBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f1383ee-2397-43b8-a74f-ece202b8d35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c61e009c9a48b3ac65fa8d194f3be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac84552bc404dc3aa792dde5393338a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aba642e61f48158aaf20355a62fc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "# Function to tokenize the dataset using the provided tokenizer\n",
    "def tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Tokenizer for DistilBERT\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize using DistilBERT tokenizer\n",
    "tokenized_train_dataset_distilbert = train_dataset.map(lambda x: tokenize(x, distilbert_tokenizer), batched=True)\n",
    "tokenized_val_dataset_distilbert = val_dataset.map(lambda x: tokenize(x, distilbert_tokenizer), batched=True)\n",
    "tokenized_test_dataset_distilbert = test_dataset.map(lambda x: tokenize(x, distilbert_tokenizer), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72cd3f73-a521-476a-a1e0-9f831d8bd0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/shrishask/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33600' max='33600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33600/33600 1:54:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.276200</td>\n",
       "      <td>0.289463</td>\n",
       "      <td>0.893522</td>\n",
       "      <td>0.890501</td>\n",
       "      <td>0.928305</td>\n",
       "      <td>0.855656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.290552</td>\n",
       "      <td>0.899103</td>\n",
       "      <td>0.901850</td>\n",
       "      <td>0.888043</td>\n",
       "      <td>0.916093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.325209</td>\n",
       "      <td>0.900710</td>\n",
       "      <td>0.902078</td>\n",
       "      <td>0.900334</td>\n",
       "      <td>0.903829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 03:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT Results: {'eval_loss': 0.3132319450378418, 'eval_accuracy': 0.9029736842105263, 'eval_f1': 0.9035548928823668, 'eval_precision': 0.8981746320661501, 'eval_recall': 0.909, 'eval_runtime': 219.4082, 'eval_samples_per_second': 173.193, 'eval_steps_per_second': 10.825, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data collator for DistilBERT\n",
    "data_collator_distilbert = DataCollatorWithPadding(tokenizer=distilbert_tokenizer)\n",
    "\n",
    "# Model for DistilBERT\n",
    "distilbert_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Training arguments for DistilBERT with limited checkpointing\n",
    "distilbert_training_args = TrainingArguments(\n",
    "    output_dir='/data/nmamit-interns/grp3/new/result/distilbert',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type='linear',\n",
    ")\n",
    "\n",
    "# Trainer for DistilBERT\n",
    "distilbert_trainer = Trainer(\n",
    "    model=distilbert_model,\n",
    "    args=distilbert_training_args,\n",
    "    train_dataset=tokenized_train_dataset_distilbert,\n",
    "    eval_dataset=tokenized_val_dataset_distilbert,\n",
    "    data_collator=data_collator_distilbert,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train DistilBERT and automatically resume from the latest checkpoint if available\n",
    "distilbert_trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "# Evaluate DistilBERT\n",
    "distilbert_results = distilbert_trainer.evaluate(tokenized_test_dataset_distilbert)\n",
    "print(\"DistilBERT Results:\", distilbert_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dceea2c-dbc5-4fa4-9a2f-457b545f8a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/data/nmamit-interns/grp3/new/distilbert_tokenizer/tokenizer_config.json',\n",
       " '/data/nmamit-interns/grp3/new/distilbert_tokenizer/special_tokens_map.json',\n",
       " '/data/nmamit-interns/grp3/new/distilbert_tokenizer/vocab.txt',\n",
       " '/data/nmamit-interns/grp3/new/distilbert_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_model.save_pretrained('/data/nmamit-interns/grp3/new/distilbert_model')\n",
    "distilbert_tokenizer.save_pretrained('/data/nmamit-interns/grp3/new/distilbert_tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430c89a-6636-4f5b-aa93-3059543cdd27",
   "metadata": {},
   "source": [
    "#### *CONFUSION MATRIX / CLASSIFICATION REPORT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb3811cb-799b-401b-8751-44212d5d155f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[17461  1539]\n",
      " [ 1449 17551]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     19000\n",
      "           1       0.92      0.92      0.92     19000\n",
      "\n",
      "    accuracy                           0.92     38000\n",
      "   macro avg       0.92      0.92      0.92     38000\n",
      "weighted avg       0.92      0.92      0.92     38000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    " \n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the BERT model\n",
    "loaded_distilbert_model =  DistilBertForSequenceClassification.from_pretrained('/data/nmamit-interns/grp3/new/distilbert_model')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "loaded_distilbert_tokenizer = DistilBertTokenizer.from_pretrained('/data/nmamit-interns/grp3/new/distilbert_tokenizer')\n",
    "\n",
    "# Load your test data\n",
    "test_texts = df_test['text'].tolist()  \n",
    "test_labels = df_test['target'].tolist()  \n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "loaded_distilbert_model.to(device)\n",
    "\n",
    "# Function to get predictions in batches\n",
    "def get_predictions_in_batches(model, tokenizer, texts, batch_size=32):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_logits = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        encodings = tokenizer(batch_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "        encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        all_logits.extend(logits.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_logits)\n",
    "\n",
    "# Get predictions\n",
    "predictions, logits = get_predictions_in_batches(loaded_distilbert_model, loaded_distilbert_tokenizer, test_texts)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd91fd5-d7ea-42b2-a55d-e72bb5a4bbd2",
   "metadata": {},
   "source": [
    "### *ROC and AUC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb989d5e-551a-437f-8528-8c7dc419d5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate ROC curve and AUC\n",
    "if len(np.unique(test_labels)) == 2:\n",
    "    fpr, tpr, _ = roc_curve(test_labels, logits[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ROC curve is only applicable for binary classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f3b31-52cf-4b04-86e5-236598f216d9",
   "metadata": {},
   "source": [
    "### **PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0eef823-6a35-48ae-a670-5b6d95681795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Function to predict a single sample\n",
    "def predict_single_sample(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load tokenizer and model (using the provided variable names)\n",
    "    tokenizer = loaded_distilbert_tokenizer\n",
    "    model = loaded_distilbert_model.to(device)\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to the same device as the model\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    prediction = torch.argmax(logits, dim=-1).item()\n",
    "    return \"1\" if prediction == 1 else \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8809f0f2-bf3a-43c0-93c2-1ec24acb93ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: ve heard all the hype and wanted to try it tonight was my second attempt here first time new girl on the grill apologized to me at minutes at walked not even an acknowledgement from the wait staff tonight the waiter seemed mad that didn know what wanted to order after explained that never been there he brought me menu and then proceeded to ignore me for minutes walked again no more tries here maybe doing something wrong haha\n",
      "Actual prediction:0\n",
      "Example prediction : 0\n"
     ]
    }
   ],
   "source": [
    " # Example usage for a single test sample\n",
    "example_text = df_test['text'].iloc[98]\n",
    "example_target = df_test['target'].iloc[98]\n",
    "prediction = predict_single_sample(example_text)\n",
    "print(f\"Input text: {example_text}\")\n",
    "print(f\"Actual prediction:{example_target}\")\n",
    "print(f\"Example prediction : {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846f4e5-24bb-492e-a839-e7150f042d18",
   "metadata": {},
   "source": [
    "## **AlBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3f26677-6783-43e6-b0de-2410f4313d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d1bf3f93694b1abb1fcad65c482e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bb9ba1e8464676b0d2f0ff0833eebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ff0868a82e48fbbe562f597b31957d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/shrishask/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33600' max='33600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33600/33600 1:11:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>0.344576</td>\n",
       "      <td>0.887093</td>\n",
       "      <td>0.889006</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>0.893594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0.351147</td>\n",
       "      <td>0.891692</td>\n",
       "      <td>0.893839</td>\n",
       "      <td>0.886699</td>\n",
       "      <td>0.901094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.296600</td>\n",
       "      <td>0.321257</td>\n",
       "      <td>0.893611</td>\n",
       "      <td>0.894018</td>\n",
       "      <td>0.901354</td>\n",
       "      <td>0.886801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 02:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALBERT Results: {'eval_loss': 0.30608633160591125, 'eval_accuracy': 0.8998421052631579, 'eval_f1': 0.8996678441503664, 'eval_precision': 0.9012358719763388, 'eval_recall': 0.8981052631578947, 'eval_runtime': 170.957, 'eval_samples_per_second': 222.278, 'eval_steps_per_second': 13.892, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "# Function to tokenize the dataset using the provided tokenizer\n",
    "def tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Tokenizer for ALBERT\n",
    "albert_tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "\n",
    "# Tokenize using ALBERT tokenizer\n",
    "tokenized_train_dataset_albert = train_dataset.map(lambda x: tokenize(x, albert_tokenizer), batched=True)\n",
    "tokenized_val_dataset_albert = val_dataset.map(lambda x: tokenize(x, albert_tokenizer), batched=True)\n",
    "tokenized_test_dataset_albert = test_dataset.map(lambda x: tokenize(x, albert_tokenizer), batched=True)\n",
    "\n",
    "# Data collator for ALBERT\n",
    "data_collator_albert = DataCollatorWithPadding(tokenizer=albert_tokenizer)\n",
    "\n",
    "# Model for ALBERT\n",
    "albert_model = AlbertForSequenceClassification.from_pretrained('albert-base-v2')\n",
    "\n",
    "# Training arguments for ALBERT with limited checkpointing\n",
    "albert_training_args = TrainingArguments(\n",
    "    output_dir='/data/nmamit-interns/grp3/new/result/albert',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type='linear',\n",
    ")\n",
    "\n",
    "# Trainer for ALBERT\n",
    "albert_trainer = Trainer(\n",
    "    model=albert_model,\n",
    "    args=albert_training_args,\n",
    "    train_dataset=tokenized_train_dataset_albert,\n",
    "    eval_dataset=tokenized_val_dataset_albert,\n",
    "    data_collator=data_collator_albert,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train ALBERT \n",
    "albert_trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "# Evaluate ALBERT\n",
    "albert_results = albert_trainer.evaluate(tokenized_test_dataset_albert)\n",
    "print(\"ALBERT Results:\", albert_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85392fd8-16b6-46ff-b62b-bbcaeef06eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/data/nmamit-interns/grp3/new/albert_tokenizer/tokenizer_config.json',\n",
       " '/data/nmamit-interns/grp3/new/albert_tokenizer/special_tokens_map.json',\n",
       " '/data/nmamit-interns/grp3/new/albert_tokenizer/spiece.model',\n",
       " '/data/nmamit-interns/grp3/new/albert_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SAVING THE MODEL\n",
    "albert_model.save_pretrained('/data/nmamit-interns/grp3/new/albert_model')\n",
    "albert_tokenizer.save_pretrained('/data/nmamit-interns/grp3/new/albert_tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a788648-83e0-47ff-a8ea-03d8e3d88633",
   "metadata": {},
   "source": [
    "#### *CONFUSION MATRIX / CLASSIFICATION REPORT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f747d31f-518d-4a41-946b-27d31239963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[17511  1489]\n",
      " [ 1866 17134]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     19000\n",
      "           1       0.92      0.90      0.91     19000\n",
      "\n",
      "    accuracy                           0.91     38000\n",
      "   macro avg       0.91      0.91      0.91     38000\n",
      "weighted avg       0.91      0.91      0.91     38000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the BERT model\n",
    "loaded_albert_model =  AlbertForSequenceClassification.from_pretrained('/data/nmamit-interns/grp3/new/albert_model')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "loaded_albert_tokenizer = AlbertTokenizer.from_pretrained('/data/nmamit-interns/grp3/new/albert_tokenizer')\n",
    "\n",
    "# Load your test data\n",
    "test_texts = df_test['text'].tolist()  \n",
    "test_labels = df_test['target'].tolist()  \n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "loaded_albert_model.to(device)\n",
    "\n",
    "# Function to get predictions in batches\n",
    "def get_predictions_in_batches(model, tokenizer, texts, batch_size=32):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_logits = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        encodings = tokenizer(batch_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "        encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        all_logits.extend(logits.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_logits)\n",
    "\n",
    "# Get predictions\n",
    "predictions, logits = get_predictions_in_batches(loaded_albert_model, loaded_albert_tokenizer, test_texts)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e7c14e-836a-4d88-86e6-5cce8de02cfe",
   "metadata": {},
   "source": [
    "### *ROC and AUC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cef5932-992b-4de6-abe0-17a36eb68bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABE8klEQVR4nO3dd3gVZfbA8e9JDxBCCaI0ASmhCAhIEUGkSLX9LFgWV1dXAoINFRcb9rqgSJNFF9eGHZQiigUQFQWp0kRqlF4CJKSf3x8zhEtIbi4hNzc3OZ/nuc+dPmcmuXNm3pl5X1FVjDHGmPyEBDoAY4wxJZslCmOMMV5ZojDGGOOVJQpjjDFeWaIwxhjjlSUKY4wxXlmiMKdERH4Tka6BjqOkEJGRIjIlQOueKiJPBWLdRU1EbhSRLws5r/1P+pkliiAmIltE5KiIHBGRne6Bo4I/16mqzVT1O3+u4xgRiRSRZ0Vkm7udv4vI/SIixbH+POLpKiKJnsNU9RlVvc1P6xMRuVNEVotIsogkisiHInKuP9ZXWCIySkTePp1lqOo7qnqJD+s6KTkW5/9kWWWJIvhdqqoVgFbAecC/AhvOqRORsHxGfQh0B/oCMcBA4HbgFT/EICJS0n4PrwB3AXcCVYBGwHSgX1GvyMvfwO8CuW7jI1W1T5B+gC1AD4/+F4BZHv0dgB+Ag8AKoKvHuCrAf4G/gAPAdI9x/YHl7nw/AC1yrxOoARwFqniMOw/YC4S7/f8A1rrLnwuc7TGtAncAvwOb89i27kAqUDvX8PZAFtDA7f8OeBb4GUgCZuSKyds++A54GljkbksD4BY35sPAJmCQO215d5ps4Ij7qQGMAt52p6nrbtffgW3uvnjIY33RwJvu/lgLPAAk5vO3behuZzsvf/+pwHhglhvvYuAcj/GvANuBQ8BSoLPHuFHAR8Db7vjbgHbAj+6+2gGMAyI85mkGfAXsB3YBI4HeQDqQ4e6TFe60scDr7nL+BJ4CQt1xN7v7fIy7rKfcYd+748Udt9v9m64EmuOcJGS46zsCfJ77dwCEunH94e6TpeT6H7JPIY41gQ7APqfxxzvxB1ILWAW84vbXBPbhnI2HAD3d/mru+FnA+0BlIBy4yB3e2v2Btnd/dH931xOZxzq/Af7pEc+LwCS3+wpgI9AECAMeBn7wmFbdg04VIDqPbXsOmJ/Pdm/l+AH8O/dA1BznYP4xxw/cBe2D73AO6M3cGMNxztbPcQ9WFwEpQGt3+q7kOrCTd6L4D05SaAmkAU08t8nd57VwDoD5JYoEYGsBf/+pOAfadm787wDTPMb/DajqjhsO7ASiPOLOcP9OIW68bXASa5i7LWuBu93pY3AO+sOBKLe/fe594LHu6cBr7t/kDJxEfuxvdjOQCQxz1xXNiYmiF84BvpL7d2gCnOWxzU95+R3cj/M7aOzO2xKoGujfarB/Ah6AfU7jj+f8QI7gnDkp8DVQyR03Angr1/RzcQ78Z+GcGVfOY5kTgSdzDVvP8UTi+aO8DfjG7Racs9cubv8c4FaPZYTgHHTPdvsV6OZl26Z4HvRyjfsJ90wd52D/nMe4pjhnnKHe9oHHvE8UsI+nA3e53V3xLVHU8hj/M3Cd270J6OUx7rbcy/MY9xDwUwGxTQWmePT3BdZ5mf4A0NIj7gUFLP9u4FO3+3pgWT7T5ewDt786ToKM9hh2PfCt230zsC3XMm7meKLoBmzASVoheWyzt0SxHrj8dH9b9jnxU9LKZM2pu0JVY3AOYvFAnDv8bOAaETl47ANciJMkagP7VfVAHss7Gxiea77aOMUsuX0EdBSRGkAXnIPkQo/lvOKxjP04yaSmx/zbvWzXXjfWvJzljs9rOVtxrgzi8L4P8oxBRPqIyE8ist+dvi/H96mvdnp0pwDHHjCokWt93rZ/H/lvvy/rQkSGi8haEUlytyWWE7cl97Y3EpGZ7oMRh4BnPKavjVOc44uzcf4GOzz2+2s4VxZ5rtuTqn6DU+w1HtglIpNFpKKP6z6VOI2PLFGUEqo6H+ds6yV30Hacs+lKHp/yqvqcO66KiFTKY1HbgadzzVdOVd/LY50HgS+Ba4EbgPfUPa1zlzMo13KiVfUHz0V42aR5QHsRqe05UETa4RwMvvEY7DlNHZwilb0F7IOTYhCRSJyiq5eA6qpaCZiNk+AKitcXO3CKnPKKO7evgVoi0rYwKxKRzjhXVNfiXDlWwinv93xiLPf2TATWAQ1VtSJOWf+x6bfjFMnlJfdytuNcUcR57PeKqtrMyzwnLlB1rKq2wSkWbIRTpFTgfAXEaQrJEkXp8jLQU0Ra4dykvFREeolIqIhEuY931lLVHThFQxNEpLKIhItIF3cZ/wESRKS9+yRQeRHpJyIx+azzXeAm4Cq3+5hJwL9EpBmAiMSKyDW+boiqzsM5WH4sIs3cbeiAUw4/UVV/95j8byLSVETKAU8AH6lqlrd9kM9qI4BIYA+QKSJ9AM9HNncBVUUk1tftyOUDnH1SWURqAkPzm9DdvgnAe27MEW7814nIgz6sKwbnPsAeIExEHgUKOiuPwbmxfURE4oHBHuNmAmeKyN3uY8sxItLeHbcLqHvsqTH3/+tL4N8iUlFEQkTkHBG5yIe4EZHz3f+/cCAZ56GGLI911fcy+xTgSRFp6P7/thCRqr6s1+TPEkUpoqp7gP8Bj6jqduBynLPCPThnWvdz/G8+EOfMex3Ozeu73WUsAf6Jc+l/AOeG9M1eVvsZzhM6u1R1hUcsnwLPA9PcYozVQJ9T3KSrgG+BL3DuxbyN8yTNsFzTvYVzNbUT50brnW4MBe2DE6jqYXfeD3C2/QZ3+46NXwe8B2xyi1TyKo7z5gkgEdiMc8X0Ec6Zd37u5HgRzEGcIpUrgc99WNdcnJOBDTjFcal4L+oCuA9nmw/jnDC8f2yEu296Apfi7OffgYvd0R+63/tE5Fe3+yacxLsGZ19+hG9FaeAktP+4823FKYY7dqX8OtDU3f/T85h3NM7f70ucpPc6zs1ycxrkeEmBMcFHRL7DuZEakLejT4eIDMa50e3TmbYxgWJXFMYUExE5S0Q6uUUxjXEeNf000HEZUxB7I9KY4hOB8/RPPZyipGk49yGMKdGs6MkYY4xXVvRkjDHGq6AreoqLi9O6desGOgxjjAkqS5cu3auq1Qozb9Alirp167JkyZJAh2GMMUFFRLYWdl4rejLGGOOVJQpjjDFeWaIwxhjjlSUKY4wxXlmiMMYY45UlCmOMMV75LVGIyBsisltEVuczXkRkrIhsFJGVItLaX7EYY4wpPH++RzEVp4rk/+Uzvg9O9dQNcdpnnuh+G2NKMlVAQbM9ut1+8ujPPb1mQnbm8eHOQk9cVs53PuOOzZfnPLnmzT08MwVCI3Ntzwkb6Nu43G0oFXY5XteRe3zhlpOens3p8FuiUNUFIlLXyySXA/9zW0T7SUQqichZbqMnxpQcqpCdAZmpzkEmOxM0C7Kz3INf1on96YcAcQ6IWRnHD4zJuyC8nDNtVoazzOxMSPoDouOcYVlpsH8tRFcDEY91ZbrLd5eVlXZ8fWQ73znxHIvJozvzqLus7OMfcs2Dx7j0wxAakSsZnN7BxgTGKwvbM2Xx6RXYBPLN7Jqc2JBKojvspEQhIrcDtwPUqVOnWIIzJYiqc2BMPwTpRyAr3T1QpkNGitud4QxPPwxpSc5BLisV9q2Fcmc4B8rdyyGmJmSmwf51zjRh0c582RmQ/Bcc3Qflz3KWmZXuLCMjhdNvBTUIZaV7Hy8hgDgJDXH6j3Xn7hc5Pn1ImPM5Nh2cON1J35w47IRuL/Pmns9z+J4VUL2N58bk2jYpgnG5xhd23Gkup+WRiqz5/AxORyATRe4tgnx+jao6GZgM0LZt2zL4iw0yWRmQcQQykp2DbEYypB2EQ1ucA0RGsnNATz/sdO/8BUJCnTPWzFQ3IRx2ulP3FX/8h7acPCwkDEKjAHVijqkNEurELSFO97F+VTi4Ec5s5x4Uw48fHPevh+qt3WHhx8cf3gZx5zpFIqGRkLIbKtUHcecLCXW7Qz2WGe6x7pCTu4/FRoibFKOOjyPkxOk8+3OGh52YDE5IDKak2r49iZkzNzB48PkAdL0KNt50gPr1Hy/0MgOZKBI5sXH5WsBfAYrFeFJ1zqxT9zsHrLSDkLTZOYBKKBzdA4e3Q8ouiIiFvxZBxbrHE0F2pn/iiqrixFS5sXPgC41wDqph5ZzukHDnO/2QM7zi2c7BPWUnVG3uXD2kJ0HsOc5BMzvDKfIJjTw+LwIRMe4B211+eDn3DNiYkiszM5uxYxfz6KPfkpycQfPmZ9C589kA1KtX+bSWHcj//s+AoSIyDecmdpLdn/CT9CPOGWvqQTi02TnoZ2c5RS3ph51EkH7EOcDuWVHQ0vJ27Cw8O9M58wwr51xVVDrHOUBHVnYOwMk74cy2zvjIShBe3vkOjXDO0sPLudNXcr5DI52DemhEUewJY0qlxYsTGTRoJitW7ALgqquaUL/+6SUHT35LFCLyHtAViBORROAxIBxAVScBs4G+wEYgBbjFX7GUCakHYO8qp+x9/QdwONEtd9/hlM8XhoTAGee5Z91Rzk3RmFpwRhvnoB8S6hzQoypDeAXnO6Kic3C34glj/O7AgaOMHPk1r722FFWoW7cS48b1oV+/RkW6Hn8+9XR9AeMVuMNf6y+V0pJgx2LnqZhdSyFlD+z+1Ske8kZCnYN8aCTU7uoU31Q8G2pd5BzoI2Lc7wrO0zbR1SA8uhg2yBhzOh5/fD6TJi0lLCyE++7ryCOPXES5cuFFvh4reC2pUg84xUA7FsPat52kkLKr4PkaD4BKDZwinRoXQGx9qFDDvWFpjAl2mZnZhIU570o//HAXNm8+yNNPd6N589N7sskbSxQlQUYy7FnpfLZ/51wlHNiQ97Rnnu88HVOpAZQ/0+mOruqU79sNV2NKrdTUTJ5//numT1/P4sW3ERERSlxcOWbMuM7v67YjSyBkpjlPCq19F7Z/49xczi0kHKo2dZ71PrMd1OwEVeItGRhTBn399SYGD57F77/vB2Du3I1cemnjYlu/HXWKQ8ZR2LUEts6Dn57If7r4G5xn7Gtc4NxEDosqvhiNMSXOrl1HGD78S955ZxUATZrEMXFiPy66qG6xxmGJwl/SkmDjdFjzFmz7Ou9pGl8HdS6GBldCuUK1eW6MKaXefnslw4bN4eDBVKKiwnj00S4MH34BERHFf7/REkVR0mxIXAgrJsIfM5w3iz01vxXq9YHaF0N0lcDEaIwJCtnZysGDqfTu3YDx4/sW6XsRp8oSRVE4/CeseRNWTHLeWD6mZmdodBXU6wuVGwYuPmNMiXfkSDo//ridnj3PAWDgwBbUqBFD9+71kAC/l2SJ4nQk74JFD8Oq18mppqpcdWj2d+fqoUrRvvRijCmdpk9fx7Bhc9izJ5nVq4fQoEEVRIQePeoHOjTAEkXhrXsf5vzteL1G51wG5/4T6vd1K08zxhjvtm49yJ13fsFnn60HoG3bGqSl+amutNNgieJU7V4B34+EzbOd/jNaQ6cnoH6/wMZljAkaGRlZvPzyT4waNZ+UlAxiYiJ45pnuDB7cltDQkneiaYnCV7tXwPf/gs1fAOpUh9H5OWh9l9VrZIw5JXfeOYdJk5YCcO21zRgzphc1asQEOKr8WaIoSPph+P4hWDaOnPsQzf8B7Uc6NaMaY8wpuvvuDsyfv5XRo3vRu3eDQIdTIEsU3qz/EL6906kaG6DZzXDBE1CxttfZjDHmGFXl7bdXMnv2Rt599/8QERo3jmP16iGEhARHaYQlirwc2g7zBsHmOU5/5YbQayrUvCCgYRljgsv69XsZPHgW3367BXAeee3b13lUPliSBFiiONnmOTDzuuOtpLW9Dzo+ag3nGGN8dvRoBs8++z3PP7+I9PQsqlaN5t//voQ+fUp+MVNeLFEck34EfnoKlrzktN1Quytc8rrTbrExxvho3rxNJCTM5I8/DgBw663n8fzzPahatVyAIys8SxQAf8yEr/55/F5Em3ugy4vWhoMx5pT98MN2/vjjAM2aVWPSpP5ceGGdQId02sp2otj4GSwfB1u/cvqrxEOPic7VhDHG+CArK5uNG/fTuHEcACNGdCIurhy33dY6IBX4+UPZTBRZ6TD7b7DhQ6dfQqDNcLjwaQgt+mYEjTGl07JlO0hImMWmTQdYv34oVapEExkZxpAh5wc6tCJV9hJFRjJ80g8S5zttSbe9D1rf6TQXaowxPjh8OI1HH/2WsWN/JjtbqVkzhj/+2E+VKjUDHZpflL1EseBBJ0lEVoIrZkCtLoGOyBgTJFSVTz5Zy113fcGffx4mJES4554OPP54V2JiIgMdnt+UrUSx+QvnngTA5Z9akjDGnJK77/6CsWN/BuD882vw2mv9Oe+8swIclf+VvNqn/CV5J3z5T6e72S12w9oYc8quvLIJsbGRjB/flx9/vLVMJAkoK1cUmg2fXQ1HEiGmNnQfF+iIjDFB4Pvvt/Htt5t55JGLAOjatS7btt1DxYqlt5gpL2UjUax6A/5a5NyXGLAAwoP3xRdjjP/t25fCiBHzeP31ZQB0716fCy5w6ngra0kCykKiSEuCHx5xuru8CLF1AxqOMabkUlX+978V3HffV+zdm0J4eAgPPngh5513ZqBDC6jSnygWPercn6gSD81vCXQ0xpgSau3aPQwePIv587cCcPHFdZkwoR/x8XEBjizwSnei2LcOlo11untMsio5jDH5Gj36R+bP30q1auUYPboXN954LmKNkgGlPVHMG+R8178Ual8U2FiMMSVOUlIqsbFRADz7bA/Kl4/g0UcvokqV6ABHVrKU3sdjt8yFxAVOd+dnAxuLMaZE+euvwwwY8BEdOrxOenoWAHFx5Xj55d6WJPJQOhNFZip85V5NXPg0xDULbDzGmBIhKyubV19dTHz8OD744De2bUvi1193BDqsEq90Fj192h8ObYXY+k5lf8aYMm/p0r8YNGgmS5c6ieGyyxrz6qt9qFMnNsCRlXx+vaIQkd4isl5ENorIg3mMjxWRz0VkhYj8JiKn/1hS+uHjRU5dXoCwsvfMszHmRKNGfUe7dlNYunQHtWtXZPr0AcyYcZ0lCR/57YpCREKB8UBPIBH4RUQ+U9U1HpPdAaxR1UtFpBqwXkTeUdX0Qq944b8gOwMq1oVGV53GFhhjSov69SsjAsOHd2TUqK5UqGBNG58KfxY9tQM2quomABGZBlwOeCYKBWLEeQatArAfyCz0GlWdm9gAzf9R6MUYY4Lbpk0H+OWXPxkwoDkAAwe2oH37mjmNC5lT489EURPY7tGfCLTPNc044DPgLyAGGKCq2bkXJCK3A7cD1KnjpVnBfb/BwY0QFgWt7zqt4I0xwSc9PYuXXvqBJ59cgKrSpk0NGjSogohYkjgN/rxHkdebKpqrvxewHKgBtALGiUjFk2ZSnayqbVW1bbVq1fJf49p3nO96/SDypMUYY0qxBQu20qrVJB566BtSUzO5+uqmZbJeJn/w5xVFIlDbo78WzpWDp1uA51RVgY0ishmIB34u1Bp3L3e+63Qr1OzGmOCzd28K99//FVOnLgegYcMqTJzYj+7d6wc2sFLEn4niF6ChiNQD/gSuA27INc02oDuwUESqA42BTYVaW2Yq7PjR6a5ticKYsiIhYSYff7yWyMhQRo7szAMPdCIqqnQ++R8oftubqpopIkOBuUAo8Iaq/iYiCe74ScCTwFQRWYVTVDVCVfcWaoU7Fjs1xVZuDFUaF81GGGNKpOxsJSTEKd1++uluHD2aycsv96Jhw6oBjqx08mvaVdXZwOxcwyZ5dP8FXFIkK9s0y/mu3hqsIi9jSqWUlAyefHI+y5fvYvbsG3JuUs+albuwwhSl0nN9ttO9rXHm+YGNwxjjF7NmbWDo0Dls2XIQEfj55z9p375WoMMqE0pHoji6DxLnO90NrgxsLMaYIpWYeIi77vqCTz5ZC0DLltWZNKm/JYliVDoSxfZvne+zOloLdsaUIhMm/MKIEfM4ciSd8uXDefLJixk2rD1hYaWzPtOSqnQkig0fO981OwU2DmNMkdq7N4UjR9K58sp4XnmlN7VrW91MgVA6EkXGYec7tl5g4zDGnJaDB1NZt24vHTo4xUojRnSiXbua9O7dIMCRlW2l4/rt2BNPNS8MbBzGmEJRVaZNW02TJuO57LL32L//KACRkWGWJEqA4E8UhxOPd1eJD1wcxphC2bhxP717v8P113/Mzp1HaNiwKklJqYEOy3gI/qKn36Y632f3hFCrOtiYYJGWlskLLyzi6acXkpaWReXKUbzwQk/+8Y/zcl6mMyWDz4lCRMqrarI/gymUAxucb7uaMCaoDBjwETNmrAfgppta8uKLPTnjjPIBjsrkpcCiJxG5QETWAGvd/pYiMsHvkflqzVvOt70/YUxQufvuDsTHx/HNNzfx5ptXWJIowXy5RzEGpzrwfQCqugLo4s+gfKYKYeWc7rhzAxuLMSZf2dnKlCm/Mnz43JxhXbvWZfXqwVx8sT2tWNL5VPSkqtvlxPqTsvwTzilK3gmZKRAWDdFWGZgxJdGqVbtISJjFDz847ZjddFNLWrY8E4DQ0OB/nqYs8CVRbBeRCwAVkQjgTtxiqIA71uxp1aZWEaAxJUxycjqPPz6f0aN/JCtLOfPMCrz8ci9atKge6NDMKfIlUSQAr+A0bZoIfAkM8WdQPvvze+e7hr2RbUxJ8vnn6xk6dA7btiUhAnfccT5PP92N2NioQIdmCsGXRNFYVW/0HCAinYBF/gnpFOxa6nzX6BjYOIwxJ5g+fR3btiVx3nln8tpr/Tn//JqBDsmcBl8SxatAax+GFS9VOLjR6a7TPaChGFPWZWZm8+efhzj77EoAPP98T8477ywSEtpaBX6lQL6JQkQ6AhcA1UTkXo9RFXFarAusQ1sg4whExzkfY0xA/PRTIgkJM0lLy2LFigQiIkKJiyvH0KHtAh2aKSLeUn0EUAEnmcR4fA4BV/s/tALsXuZ8V29jN7KNCYADB44yePBMLrjgdVas2EVqaiZbthwMdFjGD/K9olDV+cB8EZmqqluLMSbf7F3tfFeyCsOMKU6qynvvreaee+aye3cyYWEh3H//BTz8cBfKlQsPdHjGD3y5R5EiIi8CzYCcRxZUtZvfovLFjsXOd0ydgIZhTFlz442f8N57zola5851mDixH82anRHgqIw/+XKX6R1gHVAPeBzYAvzix5h8k5XufJerFtg4jCljevduQNWq0bzxxmV8993NliTKAF+uKKqq6usicpdHcdR8fwdWoMPOW55UbxPYOIwp5ebN28Qff+xn0KC2AAwc2IL+/RtRpUp0gCMzxcWXRJHhfu8QkX7AX0DgWzU/4NQ6SYXAh2JMabRr1xHuvfdL3n13FZGRofToUZ9zzqmCiFiSKGN8SRRPiUgsMBzn/YmKwN3+DKpAGUePd0dVDlwcxpRC2dnK5MlLefDBeSQlpREVFcajj3ax9qrLsAITharOdDuTgIsh583swEnZ5XyHl7dHY40pQitW7GTQoJksXvwnAH36NGDcuL7Ur28nZGWZtxfuQoFrcep4+kJVV4tIf2AkEA2cVzwh5iF5p/Mt9sanMUXpgQfmsXjxn9SoEcMrr/TmqquaIHYyVuZ5u6J4HagN/AyMFZGtQEfgQVWdXgyx5W/b1863Vd1hzGlRVVJSMihf3mlGeOzY3kyatITHH7+YihUjAxydKSm8JYq2QAtVzRaRKGAv0EBVdxZPaF4k7wh0BMYEva1bDzJs2BySkzOYN28gIkLjxnGMGdM70KGZEsZbokhX1WwAVU0VkQ0lIkkAZGc639VaBTQMY4JRRkYWY8b8xOOPzyclJYOYmAh+/30/jRpZ418mb94SRbyIrHS7BTjH7RdAVbWF36PLT+IC57ta4EIwJhgtWrSNhIRZrF69G4ABA5oxenQvatSICXBkpiTzliiaFFsUpyrErbw2omJg4zAmiAwbNptx45xKFerXr8z48X3p3dvqSjMF81YpYMmrCPAYp0QMyluTisb4qlq18oSHhzBiRCdGjuxMdLRV4Gd849fnS0Wkt4isF5GNIvJgPtN0FZHlIvKbz1WD7FvjfIfZ26HG5Gfdur18+eUfOf0jRnRi5crBPPlkN0sS5pT4LVG472GMB/oATYHrRaRprmkqAROAy1S1GXCNTwsPcS+EwsoVWbzGlBZHj2bwyCPf0KLFRP72t0/Yv9+pySAyMoz4eGvky5w6X6rwQESigTqquv4Ult0O2Kiqm9xlTAMuB9Z4THMD8ImqbgNQ1d0+LfnYU09RVU4hHGNKvy+//IMhQ2bxxx8HALjsssZWeYE5bQVeUYjIpcBy4Au3v5WIfObDsmsC2z36E91hnhoBlUXkOxFZKiI3FbhUzTreHWYvBBkDsGPHYa677iN69XqbP/44QLNm1Vi48BamTLmMypWtiNacHl+uKEbhXB18B6Cqy0Wkrg/z5XUeo3msvw3QHadakB9F5CdV3XDCgkRuB24HqF/nLHfOKIwxjv/7vw/46adEoqPDGDWqK/fc04Hw8MA3bW9KB1/uUWSqalIhlp2IUwXIMbVwqijPPc0XqpqsqnuBBUDL3AtS1cmq2lZV21aOreAMDLWrCVO2qR4/73ruue7079+INWvu4IEHOlmSMEXKl0SxWkRuAEJFpKGIvAr84MN8vwANRaSeiEQA1wG5i6xmAJ1FJExEygHtgbVel5rtFj2Vs0djTdl0+HAa99zzBYMGzcwZdtFFdfn88+upW7dS4AIzpZYviWIYTnvZacC7ONWN313QTKqaCQwF5uIc/D9Q1d9EJEFEEtxp1uLc+1iJU/ngFFVd7XXB2W47SjUv9CF0Y0oPVeXjj9fQpMl4Xn55Mf/973K2bDkY6LBMGeDLPYrGqvoQ8NCpLlxVZwOzcw2blKv/ReBF3xfqvmwXbW1lm7Jj8+YDDB06h9mzfwegXbuaTJrUz64gTLHwJVGMFpGzgA+Baar6m59j8i4zxfm2l+1MGaCqvPDCIh5/fD5Hj2YSGxvJs8925/bb2xAaau2xmOLhSwt3F4vImTiNGE0WkYrA+6r6lN+jy4u4N+kyj3qfzphSQETYsGEfR49mcv31zRk9uhdnnlkh0GGZMkY8n5wocGKRc4EHgAGqGuG3qLxo26CSLhmcBJd9DA3/LxAhGONXe/emsHPnEZo3PyOnf9myHfTseU6AIzPBTESWqmrbwszrywt3TURklIisBsbhPPFUqzArKxLH7lFEWEPvpnRRVaZOXU58/DiuueZD0tOdJ/zi4spZkjAB5cs9iv8C7wGXqGru9yCK37FEYe9RmFJk7do9JCTMYsECp9Lmli3P5MCBo1SvbsVMJvB8uUfRoTgC8VlGsvNt1XeYUiAlJYOnn17Aiy/+QEZGNtWqlWP06F7ceOO5iFXSZEqIfBOFiHygqteKyCpOrHojsC3chUYCaSA+1WdoTImlqnTr9iaLF/8JwKBBbXj22e5WN5Mpcbwdbe9yv/sXRyC+c3NWpLVuZ4KbiDBkyPmkpGTw2mv96dixdsEzGRMA+d7MVtUdbucQVd3q+QGGFE94eQbmfIcE5KErYwotKyubV19dzOjRP+YMGziwBUuX3m5JwpRovryx0zOPYX2KOhCfHavCI9QShQkeS5b8Rfv2U7jzzi8YOfJr/vrrMOBcVVgFfqak83aPYjDOlUN9EVnpMSoGWOTvwApkicIEgaSkVB5++BvGj/8FVahduyKvvtqHGjViAh2aMT7zdo/iXWAO8Czg2d71YVXd79eofBFePtARGJMvVeXDD9dw991fsGPHEUJDhXvu6cBjj3WlQgU7yTHBxVuiUFXdIiJ35B4hIlUCnixCrHF4U7K99tpSduw4QocOtZg0qR8tW54Z6JCMKZSCrij6A0txHjXyfKhbgfp+jMu70EisIWBT0qSlZXLwYCrVq1dARJgwoS/ffbeFf/6zDSEh9v9qgle+iUJV+7vf9YovHB9lpQU6AmNOMH/+FhISZlGjRgzz5g1ERGjcOI7GjeMCHZoxp82Xup46iUh5t/tvIjJaROr4PzSvUQV29ca49uxJ5uabp9O165usW7eX7duT2LUrOdBhGVOkfHk8diKQIiItcWqO3Qq85deoChJb8i5yTNmSna28/vqvxMeP5803VxAZGcrjj3dl5crBVg24KXV8qQcjU1VVRC4HXlHV10Xk7/4OzCt7NNYEkKrSq9fbzJu3CYAePeozYUJfGjasGuDIjPEPXxLFYRH5FzAQ6CwioUBgHzk6tDWgqzdlm4jQuXMdVq3axZgxvbjuuuZWgZ8p1QpsuMht3e4G4BdVXejen+iqqv8rjgBza1tbdMnTLeCmFYFYvSmjZs3aQEZGNldcEQ84TzgdPZpJpUpRAY7MGN+cTsNFvlQzvlNE3gHOF5H+wM+BShI5oqoEdPWm7EhMPMRdd33BJ5+sJS6uHF26nE2VKtFERoYRGWk1GJuywZennq4FfgauwWk3e7GIXO3vwLyyCgGNn2VmZjNmzI80aTKeTz5ZS/ny4YwceSEVK1o7KKbs8eWU6CHgfFXdDSAi1YB5wEf+DMyrUHsr2/jPzz//yaBBM1m+fCcAV14Zzyuv9KZ2bWt+15RNviSKkGNJwrUP3x6r9Z99awO6elN6ZWcrt9wygzVr9lCnTizjxvXh0ksbBzosYwLKl0TxhYjMxWk3G2AAMNt/IfmgeqHuxxiTJ1UlLS2LqKgwQkKE8eP7MmfO7zz66EWUL2/FnMb4cjP7fhH5P+BCnFeiJ6vqp36PzBsJ7AWNKT02btzPkCGzqF27Iq+/fjkAXbvWpWvXuoENzJgSxFt7FA2Bl4BzgFXAfar6Z3EF5pUlCnOa0tIyef75RTzzzELS0rKoUiWaF15IoWrVcoEOzZgSx9sR9w1gJnAVTg2yrxZLRL4IsRbBTOF9881mWrSYxGOPfUdaWhZ//3tL1q27w5KEMfnwVvQUo6r/cbvXi8ivxRGQT+yKwhRCVlY2t9wyg7fechpsbNy4KpMm9bdiJmMK4C1RRInIeRyvqjXas19VA5g4LFGYUxcaGkJYWAhRUWE8/HBn7rvvAntpzhgf5FuFh4h862U+VdVu/gnJu7a1RZe8fhtc8p+CJzZl3qpVu0hNzeT882sCsG9fCgcPpnLOOfZ2vylb/FKFh6peXPiQ/MyKnkwBkpPTGTXqO8aM+YmGDauyYkUCERGhVK1azu5FGHOKgvO62xKF8eKzz9YzbNgctm1LQgR69KhHRkYWERH2EIQxheHXI66I9BaR9SKyUUQe9DLd+SKS5XMdUmI/eHOybduSuOKKaVx++TS2bUuideuz+Pnnf/Lqq33txTljToPfrijcdivGAz2BROAXEflMVdfkMd3zwFyfF56ZWoSRmtIgKyubrl2nsnnzQWJiInjqqW4MGXI+YWF29WnM6SowUYjTIsuNQH1VfcJtj+JMVf25gFnbARtVdZO7nGnA5cCaXNMNAz4Gzvc56vTDPk9qSjdVRUQIDQ1h1KiufP75Bl5+uRc1a1YMdGjGlBq+nG5NADoC17v9h3GuFApSE9ju0Z/oDsshIjWBK4FJ3hYkIreLyBIRWQJYm9mGAweOkpAwk2eeWZgzbODAFnz44TWWJIwpYr4UPbVX1dYisgxAVQ+IiC8Fvnm1DZn7WdyXgRGqmuWtKUlVnQxMBufxWLuZXXapKu++u4p77/2S3buTiYmJYOjQdsTGRllzpMb4iS+JIsO9j6CQ0x5Ftg/zJQK1PfprAX/lmqYtMM39gccBfUUkU1Wne12yJYoyacOGfQwZMouvv94MQOfOdZg4sR+xsdYcqTH+5EuiGAt8CpwhIk8DVwMP+zDfL0BDEakH/Alch9P2dg5VzSlDEpGpwMwCkwTYU09lTGZmNk89tYBnn/2e9PQsqlaN5sUXe3Lzza3sKsKYYuBLNePviMhSoDtOcdIVqlpgy0GqmikiQ3GeZgoF3lDV30QkwR3v9b6EV3ZFUaaEhgoLF24jPT2Lf/yjFc8/35O4OHtpzpjikm8VHjkTOE85nURVt/klogK0rS265IMnoOMjgVi9KSa7dh0hNTWTs8+uBMDvv+9jx44jdOlydmADMyZI+aUKDw+zcO5PCBAF1APWA80Ks8IiYdWMl1rZ2crkyUt58MF5tG1bg6++GoiI0LBhVRo2rBro8Iwpk3wpejrXs19EWgOD/BaRT6zoqTRavnwnCQkzWbzYaR8rIiKUI0fSiYmJDHBkxpRtp/xmtqr+KiK+vxznD3aPolQ5fDiNxx77jldeWUx2tlKjRgyvvNKbq65qYjerjSkBfHkz+16P3hCgNbDHbxH5whJFqZGenkXr1pPZuHE/ISHCXXe154knLqZiRbuKMKak8OWKIsajOxPnnsXH/gnHR8m5X8cwwSoiIpSBA1vw+ecbmDSpH23a1Ah0SMaYXLwmCvdFuwqqen8xxeObilaFR7DKyMhizJifqFMnluuuaw7Agw9eyEMPdSY01K4UjSmJ8k0UIhLmvgvRujgD8okVPQWlRYu2kZAwi9Wrd1OtWjn6929EhQoR1k6EMSWctyuKn3HuRywXkc+AD4HkYyNV9RM/x5Y/SxRBZf/+o4wY8RVTpiwDoH79ykyY0JcKFayNCGOCgS/3KKoA+4BuHH+fQoEAJgp7EiYYqCpvvbWS4cO/ZO/eFMLDQxgxohMjR3YmOjo80OEZY3zkLVGc4T7xtJrjCeIY769z+50limCQkZHNs89+z969KVx00dlMnNiPJk2qBTosY8wp8pYoQoEK+FZdePGyoqcS6+jRDNLTs4iNjSIiIpTJk/uzadMBbrqppb0TYUyQ8pYodqjqE8UWySmxA05JNHfuRoYMmU3Xrmfz+uuXA9C589l07mz1MxkTzLwlipJ7NLYz0xJlx47D3HPPXN5//zcAypcPJyUlg3Ll7D6EMaWBtzKc7sUWxamyoqcSISsrm3HjfiY+fjzvv/8b0dFhPP98D5Yuvd2ShDGlSL5XFKq6vzgDOTV2RRFoqamZdOnyX375xXlLvn//Rrz6ah/q1q0U2MCMMUXulCsFLBGs6CngoqLCaN78DHbsOMLYsb254op4u1ltTCkVpInCip6Km6ryySdrqV69Ahde6LRlNXp0L0JDxaoBN6aUC85EYUVPxWrz5gMMHTqH2bN/Jz4+juXLBxEZGUalSlGBDs0YUwyCM1FYEUexSE/P4t///oEnn1zA0aOZxMZGctdd7QkLsys6Y8qS4EwU1sKd3y1cuJWEhFmsWeM0PXLDDefy739fwplnVghwZMaY4hacicKuKPzq6NEMrr76Q3bvTqZBgypMmNCXnj3PCXRYxpgACc5EYfcoipyqkpWlhIWFEB0dzujRl7Bhwz7+9a/OREUF6b+JMaZIBOcRwJ56KlJr1uwhIWEmPXvW55FHLgLgxhtbBDgqY0xJEZxHXCt6KhIpKRmMHPk1LVtOYuHCbUyZsoy0tMxAh2WMKWGC84oi9WCgIwh6c+b8zh13zGbz5oMADBrUhmef7U5kZHD+Sxhj/Cc4jwrlzgh0BEErOTmdm2+ewUcfrQGgRYvqTJrUj44dawc4MmNMSRWcicKKngqtXLlw9u8/Svny4Tz+eFfuuquDvRdhjPEqOBOFPfV0SpYs+YtKlaJo0KAKIsKUKZcSGhpCnTqxgQ7NGBME7FSyFEtKSmXYsNm0a/cfEhJmouo0TFivXmVLEsYYnwXnFYUVPXmlqnzwwW/cffdcdu48Qmio0Lr1WWRmZhMeHhro8IwxQSY4E4XJ1x9/7OeOO2Yzd+4fAHTsWItJk/rTokX1AEdmjAlWQZoo7IoiL4cPp9G27X84eDCVSpWieP75Htx2W2tCQmx/GWMKz6+JQkR6A68AocAUVX0u1/gbgRFu7xFgsKqu8GdMpVlMTCT33NOBjRv389JLl3DGGeUDHZIxphTwW6IQkVBgPNATSAR+EZHPVHWNx2SbgYtU9YCI9AEmA+19WLgfIg4+e/Ykc//9X9G9ez0GDmwJwCOPdLGW5owxRcqfTz21Azaq6iZVTQemAZd7TqCqP6jqAbf3J6CWH+MpNbKzlSlTfqVx43G8+eYKHnroGzIysgAsSRhjipw/E0VNYLtHf6I7LD+3AnPyGiEit4vIEhFZ4g4pohCDz+rVu+nS5b/885+fc+BAKj161Ofrr2+yp5mMMX7jz3sUeR3NNc8JRS7GSRQX5jVeVSfjFEvRtrbkuYzS7ujRDEaN+o7Ro38iMzOb6tXLM2ZML667rrldRRhj/MqfiSIR8KxAqBbwV+6JRKQFMAXoo6r7fFpyGTwwhoQIn322gaysbIYMacvTT3e3NquNMcXCn4niF6ChiNQD/gSuA27wnEBE6gCfAANVdYPviy4biSIx8RDlyoVTpUo0kZFhTJ3q3OJp395u5Rhjio/f7lGoaiYwFJgLrAU+UNXfRCRBRBLcyR4FqgITRGT58XsQZVtmZjZjxvxIkybjuf/+L3OGt29fy5KEMabY+fU9ClWdDczONWySR/dtwG2nvuTSe0WxeHEigwbNZMWKXQAkJaWRmZltNbwaYwImSN/MLn0OHkxl5MivmTRpCapw9tmxjBvXl/79GwU6NGNMGReciaKU3cw+cOAoTZtOYOfOI4SFhTB8eEceeaQL5ctHBDo0Y4wJ0kRRylSuHE2fPg3YsGEfEyf249xzrQI/Y0zJEaSJIrivKNLSMnn++UVcdNHZXHRRXQDGjetLVFSYVeBnjClxgjRRBK9vvtnM4MGz2LBhH02axLFq1WBCQ0MoVy480KEZY0yegjNRBOE9it27kxk+/EvefnslAPHxcUyY0I/QUHuayRhTsgVnoggixyrwGzFiHgcPphIVFcbDD3fm/vs7ERFh9TMZY0q+IE0UwXNFkZSUykMPfcPBg6n06nUO48f35ZxzqgQ6LGOM8VmQJoqSLTk5nbCwECIjw6hcOZpJk/qRlaVcc01Tq8DPGBN0grOAvAQfbD/7bD1Nm07ghRcW5Qy76qqmXHttM0sSxpigFJyJogTati2JK66YxuWXT2PbtiTmzv2D7OwyWSO6MaaUCdJEUXLOzDMysnjppR9o0mQ8M2asJyYmglde6c38+TfbOxHGmFLB7lGchr17U+je/X+sXOlU4HfNNU0ZM6YXNWtWDHBkxhhTdIIzUZSQsv6qVaOJiytHvXqVGDeuL337Ngx0SKYEycjIIDExkdTU1ECHYsqQqKgoatWqRXh40b3EG5yJIkBUlXfeWUW7djVp1KgqIsLbb19JbGyUvVltTpKYmEhMTAx169a1BxlMsVBV9u3bR2JiIvXq1Suy5do9Ch+tX7+XHj3eYuDATxkyZBaqzo3qs86KsSRh8pSamkrVqlUtSZhiIyJUrVq1yK9i7YqiAKmpmTz77EKee24R6elZVK0azd/+1iLQYZkgYUnCFDd//M8FaaIonh/fvHmbGDx4Fhs37gfgH/9oxQsv9KRq1XLFsn5jjCkJgrToyf927TpC//7vsnHjfpo2rcaCBTfz+uuXW5IwQSU0NJRWrVrRvHlzLr30Ug4ePJgz7rfffqNbt240atSIhg0b8uSTT+YUqQLMmTOHtm3b0qRJE+Lj47nvvvsCsAXeLVu2jNtuK0RrysUkLS2NAQMG0KBBA9q3b8+WLVvynO7999+nRYsWNGvWjAceeCBn+D333EOrVq1o1aoVjRo1olKlSgDs2bOH3r17F8MWuFQ1qD5taqGa+L36Q1ZWtmZnZ+f0P//89/rssws1LS3TL+szpduaNWsCHYKWL18+p/umm27Sp556SlVVU1JStH79+jp37lxVVU1OTtbevXvruHHjVFV11apVWr9+fV27dq2qqmZkZOj48eOLNLaMjIzTXsbVV1+ty5cvL9Z1norx48froEGDVFX1vffe02uvvfakafbu3au1a9fW3bt3q6rzd5o3b95J040dO1ZvueWWnP6bb75Zv/8+72NhXv97wBIt5HE3SIueit7y5TtJSJjJHXecz8CBLQF44IFOAY7KlBr/9lNx6XDf3/7v2LEjK1c61dy/++67dOrUiUsuuQSAcuXKMW7cOLp27codd9zBCy+8wEMPPUR8fDwAYWFhDBky5KRlHjlyhGHDhrFkyRJEhMcee4yrrrqKChUqcOTIEQA++ugjZs6cydSpU7n55pupUqUKy5Yto1WrVnz66acsX74850y5QYMGLFq0iJCQEBISEti2bRsAL7/8Mp06nfh7PHz4MCtXrqRlS+f3+vPPP3P33Xdz9OhRoqOj+e9//0vjxo2ZOnUqs2bNIjU1leTkZD7//HOGDRvGqlWryMzMZNSoUVx++eVs2bKFgQMHkpycDMC4ceO44IILfN6/eZkxYwajRo0C4Oqrr2bo0KGo6gn3ETZt2kSjRo2oVq0aAD169ODjjz+me/fuJyzrvffe4/HHH8/pv+KKK3jnnXdO2i/+EKSJouh+dIcPp/HYY9/xyiuLyc5W0tKy+NvfWthNSFOqZGVl8fXXX3PrrbcCTrFTmzZtTpjmnHPO4ciRIxw6dIjVq1czfPjwApf75JNPEhsby6pVqwA4cOBAgfNs2LCBefPmERoaSnZ2Np9++im33HILixcvpm7dulSvXp0bbriBe+65hwsvvJBt27bRq1cv1q5de8JylixZQvPmzXP64+PjWbBgAWFhYcybN4+RI0fy8ccfA/Djjz+ycuVKqlSpwsiRI+nWrRtvvPEGBw8epF27dvTo0YMzzjiDr776iqioKH7//Xeuv/56lixZclL8nTt35vDhwycNf+mll+jRo8cJw/78809q164NOMk2NjaWffv2ERcXlzNNgwYNWLduHVu2bKFWrVpMnz6d9PT0E5azdetWNm/eTLdu3XKGtW3blocffrjA/V0UgjRRnD5VZfr0ddx55xckJh4iJES46672PPHExZYkTNE7hTP/onT06FFatWrFli1baNOmDT179gQ46azW06n8/8+bN49p06bl9FeuXLnAea655hpCQ522WAYMGMATTzzBLbfcwrRp0xgwYEDOctesWZMzz6FDhzh8+DAxMTE5w3bs2JFzFg6QlJTE3//+d37//XdEhIyMjJxxPXv2pEoVp3r/L7/8ks8++4yXXnoJcB5j3rZtGzVq1GDo0KEsX76c0NBQNmzYkGf8CxcuLHAbj1E9+e+ee/9WrlyZiRMnMmDAAEJCQrjgggvYtGnTCdNMmzaNq6++Ome/AZxxxhn89ddfPsdyOoIzUZzmgXzv3hRuuWUGM2c6/wht29bgtdf607r1WUURnTElRnR0NMuXLycpKYn+/fszfvx47rzzTpo1a8aCBQtOmHbTpk1UqFCBmJgYmjVrxtKlS3OKdfKTX8LxHJb7mf7y5cvndHfs2JGNGzeyZ88epk+fnnOGnJ2dzY8//kh0dLTXbfNc9iOPPMLFF1/Mp59+ypYtW+jatWue61RVPv74Yxo3bnzC8kaNGkX16tVZsWIF2dnZREVF5bneU7miqFWrFtu3b6dWrVpkZmaSlJSUk7A8XXrppVx66aUATJ48+YSEAE6iGD9+/AnDUlNTve6folQmn3qKiYlg48b9VKwYybhxffjpp1stSZhSLTY2lrFjx/LSSy+RkZHBjTfeyPfff8+8efMA58rjzjvvzHni5v777+eZZ57JOavOzs5m9OjRJy33kksuYdy4cTn9x4qeqlevztq1a3OKlvIjIlx55ZXce++9NGnShKpVq+a53OXLl580b5MmTdi4cWNOf1JSEjVr1gRg6tSp+a6zV69evPrqqzln+8uWLcuZ/6yzziIkJIS33nqLrKysPOdfuHAhy5cvP+mTO0kAXHbZZbz55puAc6+mW7dueSbW3bt3A87+mzBhwglPcq1fv54DBw7QsWPHE+bZsGHDCUVv/hSkieLUrygWLdrGvn0pAERGhjFt2lWsW3cHd9zRztqtNmXCeeedR8uWLZk2bRrR0dHMmDGDp556isaNG3Puuedy/vnnM3ToUABatGjByy+/zPXXX0+TJk1o3rw5O3bsOGmZDz/8MAcOHKB58+a0bNmSb7/9FoDnnnuO/v37061bN846y/tJ2IABA3j77bdzip0Axo4dy5IlS2jRogVNmzZl0qRJJ80XHx9PUlJSztn9Aw88wL/+9S86deqU70EenCuPjIwMWrRoQfPmzXnkkUcAGDJkCG+++SYdOnRgw4YNJ1yFFNatt97Kvn37aNCgAaNHj+a5557LGdeqVauc7rvuuoumTZvSqVMnHnzwQRo1apQz7r333uO66647KcF8++239OvX77Rj9IXkVYZWkrWtLbpk8Y9Qo4NP0+/bl8KDD85jypRl3HrreUyZcpmfIzTGsXbtWpo0aRLoMEq1MWPGEBMTU6LfpfCXLl26MGPGjDzvC+X1vyciS1W1bWHWFZyn0j7co1BV3nxzOfHx45kyZRnh4SHUqBGT580lY0xwGjx4MJGRkYEOo9jt2bOHe++916eHB4pCcN7MLsC6dXtJSJjJ/PlbAejatS4TJ/YjPj6ugDmNMcEkKiqKgQMHBjqMYletWjWuuOKKYltfkCaK/K8oEhMP0bLlJNLTs4iLK8e//30JAwfaexEmMLw9hmqMP/ij1CRIE0X+atWqyMCBLQgJEZ57rgdVqhTP42PG5BYVFcW+ffusqnFTbNRtjyK/R3sLKzgThcePbseOw9xzz1wSEtrStWtdACZPvtTaqzYBV6tWLRITE9mzZ0+gQzFlyLEW7opScCYKICsrm4kTl/DQQ99w6FAaGzfu55df/omIWJIwJUJ4eHiRtjJmTKD49aknEektIutFZKOIPJjHeBGRse74lSLS2pfl/rryEB06vM6wYXM4dCiNSy9txMcfX2uX98YY4wd+u6IQkVBgPNATSAR+EZHPVHWNx2R9gIbupz0w0f3O1/aDFTm/z/dkZzv3I159tQ+XX97YkoQxxviJP68o2gEbVXWTqqYD04DLc01zOfA/t7r0n4BKIuL1Nc79KdGICPfe24G1a+/giiviLUkYY4wf+fMeRU1gu0d/IidfLeQ1TU3ghLoCROR24Ha3Nw0eWz16NORR9UxZEwfsDXQQJYTti+NsXxxn++K4xgVPkjd/Joq8TvNzP+DryzSo6mRgMoCILCnsa+ilje2L42xfHGf74jjbF8eJyMmNa/jIn0VPiUBtj/5aQO7K032ZxhhjTAD5M1H8AjQUkXoiEgFcB3yWa5rPgJvcp586AEmqenIVlcYYYwLGb0VPqpopIkOBuUAo8Iaq/iYiCe74ScBsoC+wEUgBbvFh0ZP9FHIwsn1xnO2L42xfHGf74rhC74ugq2bcGGNM8QrOasaNMcYUG0sUxhhjvCqxicJf1X8EIx/2xY3uPlgpIj+ISMtAxFkcCtoXHtOdLyJZInJ1ccZXnHzZFyLSVUSWi8hvIjK/uGMsLj78RmJF5HMRWeHuC1/uhwYdEXlDRHaLyOp8xhfuuKmqJe6Dc/P7D6A+EAGsAJrmmqYvMAfnXYwOwOJAxx3AfXEBUNnt7lOW94XHdN/gPCxxdaDjDuD/RSVgDVDH7T8j0HEHcF+MBJ53u6sB+4GIQMfuh33RBWgNrM5nfKGOmyX1isIv1X8EqQL3har+oKoH3N6fcN5HKY18+b8AGAZ8DOwuzuCKmS/74gbgE1XdBqCqpXV/+LIvFIgRp76fCjiJIrN4w/Q/VV2As235KdRxs6Qmivyq9jjVaUqDU93OW3HOGEqjAveFiNQErgQmFWNcgeDL/0UjoLKIfCciS0XkpmKLrnj5si/GAU1wXuhdBdylqtnFE16JUqjjZkltj6LIqv8oBXzeThG5GCdRXOjXiALHl33xMjBCVbNKeWWRvuyLMKAN0B2IBn4UkZ9UdYO/gytmvuyLXsByoBtwDvCViCxU1UN+jq2kKdRxs6QmCqv+4ziftlNEWgBTgD6quq+YYituvuyLtsA0N0nEAX1FJFNVpxdLhMXH19/IXlVNBpJFZAHQEihticKXfXEL8Jw6BfUbRWQzEA/8XDwhlhiFOm6W1KInq/7juAL3hYjUAT4BBpbCs0VPBe4LVa2nqnVVtS7wETCkFCYJ8O03MgPoLCJhIlIOp/bmtcUcZ3HwZV9sw7myQkSq49SkuqlYoywZCnXcLJFXFOq/6j+Cjo/74lGgKjDBPZPO1FJYY6aP+6JM8GVfqOpaEfkCWAlkA1NUNc/HJoOZj/8XTwJTRWQVTvHLCFUtddWPi8h7QFcgTkQSgceAcDi946ZV4WGMMcarklr0ZIwxpoSwRGGMMcYrSxTGGGO8skRhjDHGK0sUxhhjvLJEYUokt+bX5R6ful6mPVIE65sqIpvddf0qIh0LsYwpItLU7R6Za9wPpxuju5xj+2W1WxtqpQKmbyUifYti3absssdjTYkkIkdUtUJRT+tlGVOBmar6kYhcArykqi1OY3mnHVNByxWRN4ENqvq0l+lvBtqq6tCijsWUHXZFYYKCiFQQka/ds/1VInJSrbEicpaILPA44+7sDr9ERH505/1QRAo6gC8AGrjz3usua7WI3O0OKy8is9y2DVaLyAB3+Hci0lZEngOi3Tjecccdcb/f9zzDd69krhKRUBF5UUR+EaedgEE+7JYfcSt0E5F24rRFssz9buy+pfwEMMCNZYAb+xvuepbltR+NOUmg60+3j33y+gBZOJW4LQc+xalFoKI7Lg7nzdJjV8RH3O/hwENudygQ4067ACjvDh8BPJrH+qbitl0BXAMsxqlQbxVQHqdq6t+A84CrgP94zBvrfn+Hc/aeE5PHNMdivBJ40+2OwKnJMxq4HXjYHR4JLAHq5RHnEY/t+xDo7fZXBMLc7h7Ax273zcA4j/mfAf7mdlfCqfepfKD/3vYp2Z8SWYWHMcBRVW11rEdEwoFnRKQLTnUUNYHqwE6PeX4B3nCnna6qy0XkIqApsMit3iQC50w8Ly+KyMPAHpxaeLsDn6pTqR4i8gnQGfgCeElEnscprlp4Cts1BxgrIpFAb2CBqh51i7tayPEW+WKBhsDmXPNHi8hyoC6wFPjKY/o3RaQhTm2g4fms/xLgMhG5z+2PAupQOuuAMkXEEoUJFjfitEzWRlUzRGQLzkEuh6oucBNJP+AtEXkROAB8parX+7CO+1X1o2M9ItIjr4lUdYOItMGpM+dZEflSVZ/wZSNUNVVEvsOp9noA8N6x1QHDVHVuAYs4qqqtRCQWmAncAYzFqcvoW1W90r3x/10+8wtwlaqu9yVeY8DuUZjgEQvsdpPExcDZuScQkbPdaf4DvI7TJORPQCcROXbPoZyINPJxnQuAK9x5yuMUGy0UkRpAiqq+Dbzkrie3DPfKJi/TcCpj64xTkR3u9+Bj84hII3edeVLVJOBO4D53nljgT3f0zR6THsYpgjtmLjBM3MsrETkvv3UYc4wlChMs3gHaisgSnKuLdXlM0xVYLiLLcO4jvKKqe3AOnO+JyEqcxBHvywpV9Vecexc/49yzmKKqy4BzgZ/dIqCHgKfymH0ysPLYzexcvsRp23ieOk13gtOWyBrgVxFZDbxGAVf8biwrcKrVfgHn6mYRzv2LY74Fmh67mY1z5RHuxrba7TfGK3s81hhjjFd2RWGMMcYrSxTGGGO8skRhjDHGK0sUxhhjvLJEYYwxxitLFMYYY7yyRGGMMcar/wcJZQnI44t5egAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate ROC curve and AUC\n",
    "if len(np.unique(test_labels)) == 2:\n",
    "    fpr, tpr, _ = roc_curve(test_labels, logits[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"ROC curve is only applicable for binary classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d8cf23-6456-4c7d-8a6f-befeae64a689",
   "metadata": {},
   "source": [
    "### **PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8757931-58c3-4a75-b586-bda63cfe9af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Function to predict a single sample\n",
    "def predict_single_sample(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load tokenizer and model (using the provided variable names)\n",
    "    tokenizer = loaded_albert_tokenizer\n",
    "    model = loaded_albert_model.to(device)\n",
    "    \n",
    "    model.eval()  # Setting the model to evaluation mode\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    prediction = torch.argmax(logits, dim=-1).item()\n",
    "    return \"1\" if prediction == 1 else \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f439b547-11ef-40a6-ad71-04384bd04f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: contrary to other reviews have zero complaints about the service or the prices have been getting tire service here for the past years now and compared to my experience with places like pep boys these guys are experienced and know what they re doing nalso this is one place that do not feel like am being taken advantage of just because of my gender other auto mechanics have been notorious for capitalizing on my ignorance of cars and have sucked my bank account dry but here my service and road coverage has all been well explained and let up to me to decide nand they just renovated the waiting room it looks lot better than it did in previous years\n",
      "Actual prediction:1\n",
      "Example prediction : 0\n"
     ]
    }
   ],
   "source": [
    " # Example usage for a single test sample\n",
    "example_text = df_test['text'].iloc[0]\n",
    "example_target = df_test['target'].iloc[0]\n",
    "prediction = predict_single_sample(example_text)\n",
    "print(f\"Input text: {example_text}\")\n",
    "print(f\"Actual prediction:{example_target}\")\n",
    "print(f\"Example prediction : {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faacb15b-d308-4c52-854c-e9b26d29ecc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38ace4e5-606a-4aa4-9b66-78dad4b9b073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2247e7b2cb451597308ef0697cc1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d3c411e2c4406fb0b7da728e701cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc683d4a3b034e31aeb06e6a5ddf3af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/shrishask/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No valid checkpoint found in output directory (/data/nmamit-interns/grp3/new/result/alberta1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2683253/3607536818.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Train ALBERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0malbert_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Evaluate ALBERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1898\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_last_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresume_from_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No valid checkpoint found in output directory ({args.output_dir})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresume_from_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No valid checkpoint found in output directory (/data/nmamit-interns/grp3/new/result/alberta1)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "# Function to tokenize the dataset using the provided tokenizer\n",
    "def tokenize(batch, tokenizer):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Tokenizer for ALBERT\n",
    "albert_tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "\n",
    "# Tokenize using ALBERT tokenizer\n",
    "tokenized_train_dataset_albert = train_dataset.map(lambda x: tokenize(x, albert_tokenizer), batched=True)\n",
    "tokenized_val_dataset_albert = val_dataset.map(lambda x: tokenize(x, albert_tokenizer), batched=True)\n",
    "tokenized_test_dataset_albert = test_dataset.map(lambda x: tokenize(x, albert_tokenizer), batched=True)\n",
    "\n",
    "# Data collator for ALBERT\n",
    "data_collator_albert = DataCollatorWithPadding(tokenizer=albert_tokenizer)\n",
    "\n",
    "# Model for ALBERT\n",
    "albert_model = AlbertForSequenceClassification.from_pretrained('albert-base-v2')\n",
    "\n",
    "# Training arguments for ALBERT with limited checkpointing\n",
    "albert_training_args = TrainingArguments(\n",
    "    output_dir='/data/nmamit-interns/grp3/new/result/alberta1',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type='linear',\n",
    ")\n",
    "\n",
    "# Trainer for ALBERT\n",
    "albert_trainer = Trainer(\n",
    "    model=albert_model,\n",
    "    args=albert_training_args,\n",
    "    train_dataset=tokenized_train_dataset_albert,\n",
    "    eval_dataset=tokenized_val_dataset_albert,\n",
    "    data_collator=data_collator_albert,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train ALBERT \n",
    "albert_trainer.train()\n",
    "\n",
    "# Evaluate ALBERT\n",
    "albert_results = albert_trainer.evaluate(tokenized_test_dataset_albert)\n",
    "print(\"ALBERT Results:\", albert_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b38eda7-048e-4b8d-bfaf-7169eeca5e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/shrishask/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during training: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 53.44 MiB is free. Process 1347921 has 24.94 GiB memory in use. Process 1366560 has 7.83 GiB memory in use. Process 1564409 has 7.72 GiB memory in use. Process 2064778 has 28.71 GiB memory in use. Process 2594307 has 8.91 GiB memory in use. Including non-PyTorch memory, this process has 928.00 MiB memory in use. Of the allocated memory 406.48 MiB is allocated by PyTorch, and 21.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 5.44 MiB is free. Process 1347921 has 24.94 GiB memory in use. Process 1366560 has 7.83 GiB memory in use. Process 1564409 has 7.72 GiB memory in use. Process 2064778 has 28.71 GiB memory in use. Process 2594307 has 8.91 GiB memory in use. Including non-PyTorch memory, this process has 976.00 MiB memory in use. Of the allocated memory 459.22 MiB is allocated by PyTorch, and 16.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2683253/1682858693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0malbert_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1933\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2267\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3306\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3307\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3337\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3338\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3339\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         outputs = self.albert(\n\u001b[0m\u001b[1;32m   1060\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    718\u001b[0m         )\n\u001b[0;32m--> 719\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             layer_group_output = self.albert_layer_groups[group_idx](\n\u001b[0m\u001b[1;32m    469\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbert_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbert_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    382\u001b[0m     ) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 53.44 MiB is free. Process 1347921 has 24.94 GiB memory in use. Process 1366560 has 7.83 GiB memory in use. Process 1564409 has 7.72 GiB memory in use. Process 2064778 has 28.71 GiB memory in use. Process 2594307 has 8.91 GiB memory in use. Including non-PyTorch memory, this process has 928.00 MiB memory in use. Of the allocated memory 406.48 MiB is allocated by PyTorch, and 21.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2683253/1682858693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RuntimeError during training: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0malbert_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Evaluate ALBERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1933\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m                 if (\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3306\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3307\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3309\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3336\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3337\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3338\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3339\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3340\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         outputs = self.albert(\n\u001b[0m\u001b[1;32m   1060\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         )\n\u001b[0;32m--> 719\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mgroup_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             layer_group_output = self.albert_layer_groups[group_idx](\n\u001b[0m\u001b[1;32m    469\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbert_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbert_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     ) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         ffn_output = apply_chunking_to_forward(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 5.44 MiB is free. Process 1347921 has 24.94 GiB memory in use. Process 1366560 has 7.83 GiB memory in use. Process 1564409 has 7.72 GiB memory in use. Process 2064778 has 28.71 GiB memory in use. Process 2594307 has 8.91 GiB memory in use. Including non-PyTorch memory, this process has 976.00 MiB memory in use. Of the allocated memory 459.22 MiB is allocated by PyTorch, and 16.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AlbertForSequenceClassification, DataCollatorWithPadding\n",
    "import torch\n",
    "\n",
    "# Data collator for ALBERT\n",
    "data_collator_albert = DataCollatorWithPadding(tokenizer=albert_tokenizer)\n",
    "\n",
    "# Model for ALBERT\n",
    "albert_model = AlbertForSequenceClassification.from_pretrained('albert-base-v2')\n",
    "\n",
    "# Training arguments for ALBERT with gradient accumulation and mixed precision\n",
    "albert_training_args = TrainingArguments(\n",
    "    output_dir='/data/nmamit-interns/grp3/new/result/alberta1',\n",
    "    num_train_epochs=3,  # Keep epochs as is\n",
    "    per_device_train_batch_size=8,  # Keep batch size as is\n",
    "    per_device_eval_batch_size=16,  # Keep batch size as is\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type='linear',\n",
    ")\n",
    "\n",
    "# Trainer for ALBERT\n",
    "albert_trainer = Trainer(\n",
    "    model=albert_model,\n",
    "    args=albert_training_args,\n",
    "    train_dataset=tokenized_train_dataset_albert,\n",
    "    eval_dataset=tokenized_val_dataset_albert,\n",
    "    data_collator=data_collator_albert,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Free up CUDA memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Train ALBERT \n",
    "try:\n",
    "    albert_trainer.train()\n",
    "except RuntimeError as e:\n",
    "    print(f\"RuntimeError during training: {e}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    albert_trainer.train()\n",
    "\n",
    "# Evaluate ALBERT\n",
    "albert_results = albert_trainer.evaluate(tokenized_test_dataset_albert)\n",
    "print(\"ALBERT Results:\", albert_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0145d9-fa87-41d4-a23d-182224bb3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_from_checkpoint=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c25a7-7f13-4ee3-924e-3a94aa21732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the BERT model\n",
    "loaded_albert_model =  AlbertForSequenceClassification.from_pretrained('/data/nmamit-interns/grp3/new/albert_model')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "loaded_albert_tokenizer = AlbertTokenizer.from_pretrained('/data/nmamit-interns/grp3/new/albert_tokenizer')\n",
    "\n",
    "# Load your test data\n",
    "test_texts = df_test['text'].tolist()  \n",
    "test_labels = df_test['target'].tolist()  \n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "loaded_albert_model.to(device)\n",
    "\n",
    "# Function to get predictions in batches\n",
    "def get_predictions_in_batches(model, tokenizer, texts, batch_size=32):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_logits = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        encodings = tokenizer(batch_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "        encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encodings)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        all_logits.extend(logits.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_logits)\n",
    "\n",
    "# Get predictions\n",
    "predictions, logits = get_predictions_in_batches(loaded_albert_model, loaded_albert_tokenizer, test_texts)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9823b87-2e0e-4477-80d3-8900c81f256e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
